
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>9. Python machine learning &#8212; Python 数据科学</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/exercise.css?v=982b99e0" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/myfile.css?v=13fa32ad" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'statistics2';</script>
    <script src="_static/myfile.js?v=16a49f19"></script>
    <script src="_static/.ipynb_checkpoints/myfile-checkpoint.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="10. Python Object Oriented Programming" href="introduction-to-class.html" />
    <link rel="prev" title="8. Python statistics" href="statistics1.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Python 数据科学 - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Python 数据科学 - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Preface
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Python Basics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="A-first-look-of-Python.html">1. Getting started with Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="basic-data-type.html">2. Data types in Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="print-read-files.html">3. Output, read and write files</a></li>
<li class="toctree-l1"><a class="reference internal" href="introduction-to-numpy.html">4. Introduction to Numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="introduction-to-pandas.html">5. Introduction to Pandas</a></li>
<li class="toctree-l1"><a class="reference internal" href="define-function.html">6. Define functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="draw-pictures.html">7. Draw graphs</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Python Advanced</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="statistics1.html">8. Python statistics</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">9. Python machine learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="introduction-to-class.html">10. Python Object Oriented Programming</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/RobinChen121/book-Python-Data-Science-en/main?urlpath=lab/tree/data-science/statistics2.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Binder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Binder logo" src="_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/RobinChen121/book-Python-Data-Science-en" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/RobinChen121/book-Python-Data-Science-en/issues/new?title=Issue%20on%20page%20%2Fstatistics2.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/statistics2.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Python machine learning</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression">9.1. Linear regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#standardize-data">9.2. Standardize Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#principle-component-analysis-pca">9.3. Principle component analysis (PCA)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering">9.4. Clustering</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#artificial-neural-network">9.5. Artificial neural network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">9.6. Exercises</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="python-machine-learning">
<h1><span class="section-number">9. </span>Python machine learning<a class="headerlink" href="#python-machine-learning" title="Link to this heading">#</a></h1>
<hr>
<p>In this chapter, we explain how to perform some machine leanrning methods using Python. Rather than delving into the theoretical and computational details of those methods, we aim to provide intuitive, visual explanations that are easy to understand.</p>
<p>One key machine leanring library in Python is <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>, which focuses on some classical machine lenarning methods such as linear regression, supoport vector machine, random forest, clustring, and so on.</p>
<p>Install it using <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span></code>:</p>
<div class="highlight-dos notranslate"><div class="highlight"><pre><span></span>pip install scikit-learn
</pre></div>
</div>
<p>When we use this library in Python, its name is <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>.</p>
<p>Another widely used marchine learning library is <code class="docutils literal notranslate"><span class="pre">PyTorch</span></code>, which is deep learning framework and build some deep learning networks like RNN, CNN, Transformer, and so on.</p>
<section id="linear-regression">
<h2><span class="section-number">9.1. </span>Linear regression<a class="headerlink" href="#linear-regression" title="Link to this heading">#</a></h2>
<hr><p>linear regression is a model that estimates the relationship between a scalar <code class="docutils literal notranslate"><span class="pre">response</span></code> (dependent variable) and one or more <code class="docutils literal notranslate"><span class="pre">explanatory</span> <span class="pre">variables</span></code> (regressor or independent variable).</p>
<p>Linear regression is widely used in biological and social sciences to describe possible relationships between variables. It ranks as <strong>one of the most important tools</strong> used in these disciplines.</p>
<p>For example, for a seaborn dataset “car_crashes”, which contains data on car crashes in different U.S. states.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">crashes</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;car_crashes&#39;</span><span class="p">)</span>
<span class="n">crashes</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>  
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>total</th>
      <th>speeding</th>
      <th>alcohol</th>
      <th>not_distracted</th>
      <th>no_previous</th>
      <th>ins_premium</th>
      <th>ins_losses</th>
      <th>abbrev</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>18.8</td>
      <td>7.332</td>
      <td>5.640</td>
      <td>18.048</td>
      <td>15.040</td>
      <td>784.55</td>
      <td>145.08</td>
      <td>AL</td>
    </tr>
    <tr>
      <th>1</th>
      <td>18.1</td>
      <td>7.421</td>
      <td>4.525</td>
      <td>16.290</td>
      <td>17.014</td>
      <td>1053.48</td>
      <td>133.93</td>
      <td>AK</td>
    </tr>
    <tr>
      <th>2</th>
      <td>18.6</td>
      <td>6.510</td>
      <td>5.208</td>
      <td>15.624</td>
      <td>17.856</td>
      <td>899.47</td>
      <td>110.35</td>
      <td>AZ</td>
    </tr>
    <tr>
      <th>3</th>
      <td>22.4</td>
      <td>4.032</td>
      <td>5.824</td>
      <td>21.056</td>
      <td>21.280</td>
      <td>827.34</td>
      <td>142.39</td>
      <td>AR</td>
    </tr>
    <tr>
      <th>4</th>
      <td>12.0</td>
      <td>4.200</td>
      <td>3.360</td>
      <td>10.920</td>
      <td>10.680</td>
      <td>878.41</td>
      <td>165.63</td>
      <td>CA</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Descriptions for each column are below:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Variable Name</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">total</span></code></p></td>
<td><p>Total number of car crash deaths per 10,000 people in each state</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">speeding</span></code></p></td>
<td><p>Proportion of deaths due to speeding (as a fraction of <code class="docutils literal notranslate"><span class="pre">total</span></code>)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">alcohol</span></code></p></td>
<td><p>Proportion of deaths involving alcohol (as a fraction of <code class="docutils literal notranslate"><span class="pre">total</span></code>)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">not_distracted</span></code></p></td>
<td><p>Proportion of deaths not caused by distraction</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">no_previous</span></code></p></td>
<td><p>Proportion of drivers involved in fatal crashes with no prior violations</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">ins_premium</span></code></p></td>
<td><p>Alternative column for insurance premium</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">ins_losses</span></code></p></td>
<td><p>Average insurance losses per driver (in US dollars)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">abbrev</span></code></p></td>
<td><p>Two-letter abbreviation of the US state</p></td>
</tr>
</tbody>
</table>
</div>
<p>A scatter plot for the speeding and total number of crashes is given below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">regplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">crashes</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;speeding&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;total&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Axes: xlabel=&#39;speeding&#39;, ylabel=&#39;total&#39;&gt;
</pre></div>
</div>
<img alt="_images/c97789107855731030c5e0dcfcd6157a03b20f454d990e59927123ef688ff7ab.png" src="_images/c97789107855731030c5e0dcfcd6157a03b20f454d990e59927123ef688ff7ab.png" />
</div>
</div>
<p>We may assume there is a linear relationship between the amount of total crashes and the speeding, i.e.,</p>
<div class="math notranslate nohighlight" id="equation-eq-single-variable">
<span class="eqno">(9.1)<a class="headerlink" href="#equation-eq-single-variable" title="Link to this equation">#</a></span>\[\text{total}=\beta_0+\beta_1\text{ speeding}\]</div>
<p>Geometrically, linear regression involves finding <strong>the best-fitting line through a set of points</strong>, represented by a linear equation as shown above, where <span class="math notranslate nohighlight">\(\beta_0\)</span> is called the <code class="docutils literal notranslate"><span class="pre">intercept</span></code>.</p>
<p>The most common way to comute the linear regreesion model is by the ordinary least square method, for which we can use the function <code class="docutils literal notranslate"><span class="pre">OLS()</span></code> from the library <code class="docutils literal notranslate"><span class="pre">Statsmodels</span></code>.</p>
<p>Using the <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code> library to perform regression typically involves the following steps:</p>
<ul class="simple">
<li><p>Construct the regression model using the function <code class="docutils literal notranslate"><span class="pre">OLS()</span></code> and <code class="docutils literal notranslate"><span class="pre">fit()</span></code>.</p></li>
<li><p>Output the regression results using the <code class="docutils literal notranslate"><span class="pre">summary()</span></code> function.</p></li>
<li><p>Obtain predicted values using the <code class="docutils literal notranslate"><span class="pre">predict()</span></code> function. This step can be omitted if not for prediction.</p></li>
</ul>
<p>In the following code, we build a linear model for the equation <a class="reference internal" href="#equation-eq-single-variable">(9.1)</a> using <code class="docutils literal notranslate"><span class="pre">statsmodels.formula.api</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">sm</span>

<span class="c1"># the linear model is definded by strings the in the formula</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s2">&quot;total ~ speeding&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">crashes</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># model summary</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  total   R-squared:                       0.374
Model:                            OLS   Adj. R-squared:                  0.361
Method:                 Least Squares   F-statistic:                     29.27
Date:                Thu, 05 Feb 2026   Prob (F-statistic):           1.87e-06
Time:                        17:23:58   Log-Likelihood:                -132.15
No. Observations:                  51   AIC:                             268.3
Df Residuals:                      49   BIC:                             272.2
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      9.5459      1.243      7.680      0.000       7.048      12.044
speeding       1.2493      0.231      5.411      0.000       0.785       1.713
==============================================================================
Omnibus:                        2.847   Durbin-Watson:                   2.008
Prob(Omnibus):                  0.241   Jarque-Bera (JB):                2.681
Skew:                           0.542   Prob(JB):                        0.262
Kurtosis:                       2.709   Cond. No.                         14.9
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</pre></div>
</div>
</div>
</div>
<p>There are a lot of information in the output table, but we usually concern several key informations:</p>
<ul>
<li><p>Values of coefficicent <span class="math notranslate nohighlight">\(\beta_0, \beta_1, \dots\)</span></p>
<ul>
<li><p>They are given in the column “coef”. From them, we can get the fitted model. For this example, it is:</p>
<div class="math notranslate nohighlight">
\[
    \text{tip}=9.5459 +1.2493 \text{ total}\_\text{bill}
    \]</div>
</li>
</ul>
</li>
<li><p>p-values of the independent variables.</p>
<ul class="simple">
<li><p>The p-values are given in the column “P&gt;|t|”. If the p-value of an independe variable is less than 0.05, it means there is <strong>linear relationship</strong> between the independent variable and the dependent variable at 95% confidence level. For this example, the p-values are all 0.000.</p></li>
</ul>
</li>
<li><p><span class="math notranslate nohighlight">\(R^2\)</span></p>
<ul class="simple">
<li><p>It is given by the value on the right of “R-squred: “ at the top right of the table. It measures the proportion of variability in the dependent variable explained by the model, with a range between 0 and 1. <strong>The closer it is to 1, the better the model fit</strong>. For this example, it is 0.374.</p></li>
</ul>
</li>
</ul>
<p>In regression analysis, there is no universal threshold for what constitutes a “good” R² value, as it heavily depends on the <strong>field of study and research context</strong>. However, here are some general guidelines:</p>
<ul class="simple">
<li><p>R² &gt; 0.7: Often considered <strong>strong</strong> in social sciences or fields with high noise.</p></li>
<li><p>R² = 0.3–0.7: <strong>Moderate</strong> explanatory power (common in economics, biology, etc.).</p></li>
<li><p>R² &lt; 0.3: <strong>Weak</strong> fit, but may still be meaningful in noisy domains (e.g., psychology, climate studies).</p></li>
<li><p>R² ≈ 0: Model explains almost none of the variability.</p></li>
</ul>
<p>The general syntax for the function <code class="docutils literal notranslate"><span class="pre">ols()</span></code> is given below.</p>
<table>
    <tr style="border-top:solid; border-bottom:solid">
        <th colspan=2 style="text-align:center">statsmodels.formula.api.ols(formula, data)</th>
    </tr>
    <tr>
        <td style="text-align:left">formula</td>
        <td style="text-align:left">Usually a string, the formula specifying the model.</td>
    </tr>
    <tr style="text-align:left; border-bottom:solid" >
        <td style="text-align:left">data</td>
        <td style="text-align:left">Usually a DataFrame or dict, the data for the model</td>
    </tr>
</table>
<br /><p>The general syntax for the formula is below:</p>
<blockquote>
<div><p>y ~ x1 + x2 + x1:x2 + C(x3)</p>
</div></blockquote>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">y</span></code> is the dependent (response) variable</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">x1</span></code>, <code class="docutils literal notranslate"><span class="pre">x2</span></code>, <code class="docutils literal notranslate"><span class="pre">x3</span></code> are independent (regressor) variables</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">C(x3)</span></code> means x3 is catorgorical variable</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">~</span></code> separates the dependent variable from the predictors</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">+</span></code> adds independent variables</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-1</span></code> removes the intercept (by default it’s included)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">x1:x2</span></code> adds an <strong>interaction term</strong> only, which equals x1*x2</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">x1*x2</span></code> adds both main terms and the interaction, which equals x1 + x2 + x1*x2</p></li>
</ul>
<ul class="simple">
<li><p>Normally in regression, we assume that variables affect the outcome independently. But sometimes, the <strong>combined effect</strong> of two variables is more (or less) than just adding their individual effects — that’s where <code class="docutils literal notranslate"><span class="pre">interaction</span> <span class="pre">terms</span></code> come in.</p></li>
</ul>
<p>For example, we can apply a linear regression between the amount of total crashes, the speeding and the alcohol:</p>
<div class="math notranslate nohighlight">
\[
\text{total}=\beta_0+\beta_1\text{ speeding}+\beta_2\text{ alcohol}
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">crashes</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;car_crashes&#39;</span><span class="p">)</span>

<span class="c1"># the linear model is definded by strings the in the formula</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s2">&quot;total ~ speeding + alcohol&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">crashes</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># model summary</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  total   R-squared:                       0.730
Model:                            OLS   Adj. R-squared:                  0.719
Method:                 Least Squares   F-statistic:                     64.87
Date:                Thu, 05 Feb 2026   Prob (F-statistic):           2.27e-14
Time:                        17:23:58   Log-Likelihood:                -110.71
No. Observations:                  51   AIC:                             227.4
Df Residuals:                      48   BIC:                             233.2
Df Model:                           2                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      5.6807      0.957      5.934      0.000       3.756       7.606
speeding       0.1502      0.206      0.728      0.470      -0.265       0.565
alcohol        1.9152      0.241      7.954      0.000       1.431       2.399
==============================================================================
Omnibus:                        2.495   Durbin-Watson:                   1.809
Prob(Omnibus):                  0.287   Jarque-Bera (JB):                2.045
Skew:                           0.490   Prob(JB):                        0.360
Kurtosis:                       2.978   Cond. No.                         23.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</pre></div>
</div>
</div>
</div>
<p>Or, if we consider the interaction of speeding and alcohol (drivers with alcohol tend to driving with highe speed):</p>
<div class="math notranslate nohighlight">
\[
\text{total}=\beta_0+\beta_1\text{ speeding}+\beta_2\text{ alcohol}+\beta_3\text{ alcohol*speeding}
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">crashes</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;car_crashes&#39;</span><span class="p">)</span>

<span class="c1"># the linear model is definded by strings the in the formula</span>
<span class="c1"># the below code equals: model = smf.ols(formula=&quot;total ~ alcohol*speeding&quot;, data=crashes).fit()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s2">&quot;total ~ speeding + alcohol + alcohol:speeding&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">crashes</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># model summary</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  total   R-squared:                       0.790
Model:                            OLS   Adj. R-squared:                  0.777
Method:                 Least Squares   F-statistic:                     58.91
Date:                Thu, 05 Feb 2026   Prob (F-statistic):           5.91e-16
Time:                        17:23:58   Log-Likelihood:                -104.31
No. Observations:                  51   AIC:                             216.6
Df Residuals:                      47   BIC:                             224.3
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
====================================================================================
                       coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -1.8936      2.236     -0.847      0.401      -6.393       2.605
speeding             1.5561      0.426      3.657      0.001       0.700       2.412
alcohol              3.5368      0.492      7.191      0.000       2.547       4.526
alcohol:speeding    -0.2761      0.075     -3.664      0.001      -0.428      -0.125
==============================================================================
Omnibus:                        3.087   Durbin-Watson:                   1.807
Prob(Omnibus):                  0.214   Jarque-Bera (JB):                2.360
Skew:                           0.520   Prob(JB):                        0.307
Kurtosis:                       3.168   Cond. No.                         284.
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</pre></div>
</div>
</div>
</div>
<p>For the catogorical variable, we use the dataset “tips” as an example to fit the following equation:</p>
<div class="math notranslate nohighlight">
\[
\text{tip}=\beta_0+\beta_1\text{ total}\_\text{bill}+\beta_2\text{ day}
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">tips</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;tips&#39;</span><span class="p">)</span>

<span class="c1"># the linear model is definded by strings the in the formula</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s2">&quot;tip ~ total_bill + C(day)&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">tips</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># model summary</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                    tip   R-squared:                       0.459
Model:                            OLS   Adj. R-squared:                  0.450
Method:                 Least Squares   F-statistic:                     50.67
Date:                Thu, 05 Feb 2026   Prob (F-statistic):           7.52e-31
Time:                        17:23:58   Log-Likelihood:                -350.03
No. Observations:                 244   AIC:                             710.1
Df Residuals:                     239   BIC:                             727.5
Df Model:                           4                                         
Covariance Type:            nonrobust                                         
=================================================================================
                    coef    std err          t      P&gt;|t|      [0.025      0.975]
---------------------------------------------------------------------------------
Intercept         0.9205      0.186      4.943      0.000       0.554       1.287
C(day)[T.Fri]     0.0189      0.269      0.070      0.944      -0.511       0.549
C(day)[T.Sat]    -0.0671      0.172     -0.391      0.697      -0.406       0.271
C(day)[T.Sun]     0.0935      0.178      0.526      0.599      -0.257       0.444
total_bill        0.1047      0.008     13.915      0.000       0.090       0.119
==============================================================================
Omnibus:                       20.916   Durbin-Watson:                   2.149
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               38.821
Skew:                           0.463   Prob(JB):                     3.72e-09
Kurtosis:                       4.721   Cond. No.                         103.
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Linear regression can also be performed using non-formula-based modeling, non-OLS methods or other libraries, which are omitted here due to space limitations.</p>
</div>
</section>
<section id="standardize-data">
<h2><span class="section-number">9.2. </span>Standardize Data<a class="headerlink" href="#standardize-data" title="Link to this heading">#</a></h2>
<hr><p><code class="docutils literal notranslate"><span class="pre">Standardization</span></code> is a process of transforming the data to make it more suitable for some statistical analysis or machine learning.</p>
<p>The main reasons include:</p>
<ul class="simple">
<li><p>To remove the effect of different units and scales</p>
<ul>
<li><p>Variables may have different units (e.g., dollars, percentages, counts).</p></li>
<li><p>Without standardization, variables with larger scales may dominate the model (especially in regression or distance-based models like KNN, SVM).</p></li>
</ul>
</li>
<li><p>To compare variable importance</p>
<ul>
<li><p>In regression, standardized coefficients allow you to compare which variable has a stronger effect on the outcome. Standarization is usually operational for OLS regression, but suggested for non-OLS regreesino such as Ridge/Lasso/Elastic Net regression.</p></li>
</ul>
</li>
<li><p>To improve model performance</p>
<ul>
<li><p>Many machine learning models (e.g., gradient descent-based, PCA, K-means) work better when input features are on similar scales.</p></li>
</ul>
</li>
<li><p>To meet assumptions of some statistical tests</p>
<ul>
<li><p>Some models assume variables are normally distributed or centered around 0, especially in multivariate analysis.</p></li>
</ul>
</li>
</ul>
<p>There are two common methods for standardizing data: z-score standardization and min-max standardization</p>
<ol class="arabic simple">
<li><p><strong>Z-score Standardization</strong> (<code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code>)</p></li>
</ol>
<p>Transforms data to have mean (<span class="math notranslate nohighlight">\(\mu\)</span>) = 0 and standard deviation (<span class="math notranslate nohighlight">\(\sigma\)</span>) = 1.</p>
<div class="math notranslate nohighlight">
\[
z = \frac{x - \mu}{\sigma}
\]</div>
<p>In python, it is easy to standardize the data with the method <code class="docutils literal notranslate"><span class="pre">fit_transform(</span> <span class="pre">)</span></code> from <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">crashes</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;car_crashes&#39;</span><span class="p">)</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">crash_standard</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">crashes</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># standard</span>
<span class="nb">print</span><span class="p">(</span><span class="n">crash_standard</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">10</span><span class="p">])</span> <span class="c1"># print the first 10 rows</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[ 0.56593556  1.2126951  -0.21131068  0.60853209  0.80725756  0.94325764
  -0.02289992]
 [ 0.68844283  0.75670887  0.18761539  0.45935701  1.03314134  0.0708756
  -0.98177845]
 [ 1.61949811 -0.48361373  0.54740815  1.67605228  1.95169961 -0.33770122
   0.32112519]
 [-0.92865317 -0.39952407 -0.8917629  -0.594276   -0.89196792 -0.04841772
   1.26617765]
 [-0.5366299   0.01692    -0.63009543 -0.63369765 -0.29104195 -0.2914793
   0.22027622]
 [-1.22267063 -0.01511416 -0.5833691  -0.9356316  -1.38129335  1.02964051
   1.32270187]
 [ 0.10040792  0.57951992 -0.01564416  0.1166575   0.54542553  1.42128062
   0.6907692 ]
 [-2.42324191 -1.49769509 -1.92383077 -1.71868879 -2.17430102  2.19175919
   0.06330968]
 [ 0.51693265 -0.62025945  0.17768604  0.64840171  0.7568227   1.54737129
   0.39391538]]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>For the input parmater X in the method <code class="docutils literal notranslate"><span class="pre">fit_transform(X)</span></code>, X is an array-like of shape (n_samples, n_features).</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p><strong>Min-Max Normalization</strong> (0-1 Scaling)</p></li>
</ol>
<p>This method scales data to the <strong>[0, 1]</strong> range.</p>
<div class="math notranslate nohighlight">
\[
x' = \frac{x - \min(x)}{\max(x) - \min(x)}
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">crashes</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;car_crashes&#39;</span><span class="p">)</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">crash_standard</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">crashes</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># min-max</span>
<span class="nb">print</span><span class="p">(</span><span class="n">crash_standard</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">10</span><span class="p">])</span> <span class="c1"># print the first 10 rows</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[0.67777778 0.73504832 0.34718769 0.66344003 0.72262679 0.62393111
  0.45684192]
 [0.70555556 0.61608775 0.42806394 0.63303046 0.77737321 0.39042695
  0.24636258]
 [0.91666667 0.29250457 0.50100651 0.88105566 1.         0.28106617
  0.5323574 ]
 [0.33888889 0.31444241 0.20923623 0.41824574 0.31079324 0.35849657
  0.73980184]
 [0.42777778 0.42308697 0.26228538 0.41020958 0.45643693 0.29343805
  0.51022048]
 [0.27222222 0.41472969 0.27175844 0.34865988 0.19219766 0.64705258
  0.75220923]
 [0.57222222 0.56986158 0.38685613 0.56317063 0.65916775 0.75188004
  0.61349638]
 [0.         0.02794463 0.         0.18903246 0.         0.95810844
  0.47576542]
 [0.66666667 0.25685558 0.42605092 0.67156751 0.71040312 0.78562981
  0.54833527]]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>There is no negative values after standarization for this method.</p></li>
<li><p>Inverse standardization can be through the method <code class="docutils literal notranslate"><span class="pre">inverse_transform()</span></code>.</p></li>
</ul>
</section>
<section id="principle-component-analysis-pca">
<h2><span class="section-number">9.3. </span>Principle component analysis (PCA)<a class="headerlink" href="#principle-component-analysis-pca" title="Link to this heading">#</a></h2>
<hr><p>Principal component analysis (PCA) is a <strong>dimensionality reduction</strong> to simplify a large data set into a smaller set, while preserving their most important structures.</p>
<p>It represent a transformation of the original variables into a new set of uncorrelated variables through linear combinations. This transformation is structured such that the leading components account for the <strong>maximal possible information (reflected by the data variance)</strong> in the data, effectively compressing the key information into fewer dimensions.</p>
<ul class="simple">
<li><p>For example, there are 10 variables in the original data set. We can use PCA to reduce the number of variables to 3 and keep 85% of the original information.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;iris&quot;</span><span class="p">)</span>
<span class="n">data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal_length</th>
      <th>sepal_width</th>
      <th>petal_length</th>
      <th>petal_width</th>
      <th>species</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>145</th>
      <td>6.7</td>
      <td>3.0</td>
      <td>5.2</td>
      <td>2.3</td>
      <td>virginica</td>
    </tr>
    <tr>
      <th>146</th>
      <td>6.3</td>
      <td>2.5</td>
      <td>5.0</td>
      <td>1.9</td>
      <td>virginica</td>
    </tr>
    <tr>
      <th>147</th>
      <td>6.5</td>
      <td>3.0</td>
      <td>5.2</td>
      <td>2.0</td>
      <td>virginica</td>
    </tr>
    <tr>
      <th>148</th>
      <td>6.2</td>
      <td>3.4</td>
      <td>5.4</td>
      <td>2.3</td>
      <td>virginica</td>
    </tr>
    <tr>
      <th>149</th>
      <td>5.9</td>
      <td>3.0</td>
      <td>5.1</td>
      <td>1.8</td>
      <td>virginica</td>
    </tr>
  </tbody>
</table>
<p>150 rows × 5 columns</p>
</div></div></div>
</div>
<p>There are 4 variables in addition to the last categorical variable. We use the class <code class="docutils literal notranslate"><span class="pre">PCA</span></code> from the libraray <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> for reducing to 2 varaibles.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">iris_standard</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># the number of principal components</span>
<span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">iris_standard</span><span class="p">)</span>  <span class="c1"># fit the data by PCA</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;explained variance of each principal component: </span><span class="si">{</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>  <span class="c1"># output the explained variance ratio</span>

<span class="n">principal_components</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">iris_standard</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;principal components shown the first 10 rows:</span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">principal_components</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>explained variance of each principal component: [0.72962445 0.22850762]
principal components shown the first 10 rows:
 [[-2.26470281  0.4800266 ]
 [-2.08096115 -0.67413356]
 [-2.36422905 -0.34190802]
 [-2.29938422 -0.59739451]
 [-2.38984217  0.64683538]
 [-2.07563095  1.48917752]
 [-2.44402884  0.0476442 ]
 [-2.23284716  0.22314807]
 [-2.33464048 -1.11532768]
 [-2.18432817 -0.46901356]]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>It is recommended to standarizing the data before applying PCA.</p></li>
<li><p>Specify the number of principal components through the parameter <code class="docutils literal notranslate"><span class="pre">n_components</span></code> in <code class="docutils literal notranslate"><span class="pre">PCA(</span> <span class="pre">)</span></code>.</p></li>
<li><p>Fit the data by PCA through the method <code class="docutils literal notranslate"><span class="pre">fit(</span> <span class="pre">)</span></code>.</p></li>
<li><p>Usually, the cumulated explained variance ratio of the specified principal components should be greather equal than 85%.</p>
<ul>
<li><p>In this example, the cumluated explained variance ratiso is 0.729 + 0.228 = 0.954 &gt; 0.85.</p></li>
</ul>
</li>
<li><p>Get the principal components (the values of the reduced variables) by the method <code class="docutils literal notranslate"><span class="pre">fit_transform(</span> <span class="pre">)</span></code>.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>PCA is generally used as an intermediate step in data analysis. It is often applied for dimensionality reduction before further tasks such as clustering, classification, or visualization.</p>
</div>
<p>主成分分析的求解一般采用特征根分解，即求解原始数据<strong>协方差矩阵或相关系数矩阵</strong>最大特征根对应的特征向量，即为第一主成分，第二主成分为第二大特征根对应的特征向量，其他的主成分可以依次得出。主成分贡献率为对应特征根占所有特征根加和的比例。</p>
<p>采用 python 主成分分析时，常用的包为 sklearn，其他一些包也能做（例如 matplotlib.mlab.PCA）。需要注意的是</p>
<ul class="simple">
<li><p>最好对原始数据进行标准化</p></li>
<li><p>sklearn 计算主成分时使用的是协方差矩阵，而不是相关系数矩阵</p></li>
</ul>
<p>sklearn 中的标准化函数有：</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>函数</p></th>
<th class="head text-left"><p>描述</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>scale(X, axis=0, *)</p></td>
<td class="text-left"><p>对数据 X 进行 z 标准化，参数 axis 调整对列或对行标准化</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>StandardScaler()</p></td>
<td class="text-left"><p>z 标准化，列标准化</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>MinMaxScaler()</p></td>
<td class="text-left"><p>最大最小标准化，列标准化</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>MaxAbsScaler()</p></td>
<td class="text-left"><p>最大绝对值标准化，列标准化</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>… …</p></td>
<td class="text-left"><p></p></td>
</tr>
</tbody>
</table>
</div>
<p>举例，下面一个统计数据：</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>食品</p></th>
<th class="head"><p>衣着</p></th>
<th class="head"><p>居住</p></th>
<th class="head"><p>家庭设备</p></th>
<th class="head"><p>交通通讯</p></th>
<th class="head"><p>文教娱乐</p></th>
<th class="head"><p>医疗保健</p></th>
<th class="head"><p>其他</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>北  京</p></td>
<td><p>1736</p></td>
<td><p>379</p></td>
<td><p>854</p></td>
<td><p>327</p></td>
<td><p>615</p></td>
<td><p>797</p></td>
<td><p>504</p></td>
<td><p>103</p></td>
</tr>
<tr class="row-odd"><td><p>天  津</p></td>
<td><p>1171</p></td>
<td><p>257</p></td>
<td><p>614</p></td>
<td><p>117</p></td>
<td><p>328</p></td>
<td><p>329</p></td>
<td><p>179</p></td>
<td><p>40</p></td>
</tr>
<tr class="row-even"><td><p>河  北</p></td>
<td><p>888</p></td>
<td><p>156</p></td>
<td><p>399</p></td>
<td><p>101</p></td>
<td><p>222</p></td>
<td><p>226</p></td>
<td><p>135</p></td>
<td><p>39</p></td>
</tr>
<tr class="row-odd"><td><p>山  西</p></td>
<td><p>830</p></td>
<td><p>202</p></td>
<td><p>201</p></td>
<td><p>69</p></td>
<td><p>160</p></td>
<td><p>280</p></td>
<td><p>103</p></td>
<td><p>33</p></td>
</tr>
<tr class="row-even"><td><p>内蒙古</p></td>
<td><p>1054</p></td>
<td><p>150</p></td>
<td><p>335</p></td>
<td><p>84</p></td>
<td><p>293</p></td>
<td><p>309</p></td>
<td><p>176</p></td>
<td><p>44</p></td>
</tr>
<tr class="row-odd"><td><p>辽  宁</p></td>
<td><p>1127</p></td>
<td><p>221</p></td>
<td><p>378</p></td>
<td><p>100</p></td>
<td><p>301</p></td>
<td><p>377</p></td>
<td><p>234</p></td>
<td><p>68</p></td>
</tr>
<tr class="row-even"><td><p>吉  林</p></td>
<td><p>1003</p></td>
<td><p>168</p></td>
<td><p>257</p></td>
<td><p>82</p></td>
<td><p>285</p></td>
<td><p>261</p></td>
<td><p>194</p></td>
<td><p>56</p></td>
</tr>
<tr class="row-odd"><td><p>黑龙江</p></td>
<td><p>924</p></td>
<td><p>184</p></td>
<td><p>527</p></td>
<td><p>74</p></td>
<td><p>257</p></td>
<td><p>277</p></td>
<td><p>254</p></td>
<td><p>49</p></td>
</tr>
<tr class="row-even"><td><p>上  海</p></td>
<td><p>2684</p></td>
<td><p>366</p></td>
<td><p>1320</p></td>
<td><p>458</p></td>
<td><p>748</p></td>
<td><p>937</p></td>
<td><p>562</p></td>
<td><p>204</p></td>
</tr>
<tr class="row-odd"><td><p>江  苏</p></td>
<td><p>1569</p></td>
<td><p>191</p></td>
<td><p>512</p></td>
<td><p>168</p></td>
<td><p>364</p></td>
<td><p>479</p></td>
<td><p>199</p></td>
<td><p>85</p></td>
</tr>
<tr class="row-even"><td><p>浙  江</p></td>
<td><p>2061</p></td>
<td><p>319</p></td>
<td><p>914</p></td>
<td><p>260</p></td>
<td><p>618</p></td>
<td><p>723</p></td>
<td><p>416</p></td>
<td><p>121</p></td>
</tr>
<tr class="row-odd"><td><p>安  徽</p></td>
<td><p>1000</p></td>
<td><p>117</p></td>
<td><p>345</p></td>
<td><p>106</p></td>
<td><p>197</p></td>
<td><p>257</p></td>
<td><p>134</p></td>
<td><p>41</p></td>
</tr>
<tr class="row-even"><td><p>福  建</p></td>
<td><p>1518</p></td>
<td><p>187</p></td>
<td><p>457</p></td>
<td><p>154</p></td>
<td><p>366</p></td>
<td><p>357</p></td>
<td><p>154</p></td>
<td><p>100</p></td>
</tr>
<tr class="row-odd"><td><p>江  西</p></td>
<td><p>1221</p></td>
<td><p>125</p></td>
<td><p>326</p></td>
<td><p>96</p></td>
<td><p>230</p></td>
<td><p>276</p></td>
<td><p>155</p></td>
<td><p>56</p></td>
</tr>
<tr class="row-even"><td><p>山  东</p></td>
<td><p>1088</p></td>
<td><p>160</p></td>
<td><p>446</p></td>
<td><p>137</p></td>
<td><p>294</p></td>
<td><p>377</p></td>
<td><p>188</p></td>
<td><p>46</p></td>
</tr>
<tr class="row-odd"><td><p>河  南</p></td>
<td><p>859</p></td>
<td><p>132</p></td>
<td><p>318</p></td>
<td><p>83</p></td>
<td><p>160</p></td>
<td><p>178</p></td>
<td><p>123</p></td>
<td><p>39</p></td>
</tr>
<tr class="row-even"><td><p>湖  北</p></td>
<td><p>1192</p></td>
<td><p>125</p></td>
<td><p>310</p></td>
<td><p>110</p></td>
<td><p>223</p></td>
<td><p>272</p></td>
<td><p>135</p></td>
<td><p>62</p></td>
</tr>
<tr class="row-odd"><td><p>湖  南</p></td>
<td><p>1433</p></td>
<td><p>128</p></td>
<td><p>307</p></td>
<td><p>114</p></td>
<td><p>219</p></td>
<td><p>329</p></td>
<td><p>168</p></td>
<td><p>58</p></td>
</tr>
<tr class="row-even"><td><p>广  东</p></td>
<td><p>1789</p></td>
<td><p>144</p></td>
<td><p>530</p></td>
<td><p>152</p></td>
<td><p>412</p></td>
<td><p>361</p></td>
<td><p>204</p></td>
<td><p>116</p></td>
</tr>
<tr class="row-odd"><td><p>广  西</p></td>
<td><p>1187</p></td>
<td><p>79</p></td>
<td><p>380</p></td>
<td><p>95</p></td>
<td><p>214</p></td>
<td><p>226</p></td>
<td><p>123</p></td>
<td><p>44</p></td>
</tr>
<tr class="row-even"><td><p>海  南</p></td>
<td><p>1135</p></td>
<td><p>66</p></td>
<td><p>146</p></td>
<td><p>92</p></td>
<td><p>178</p></td>
<td><p>199</p></td>
<td><p>93</p></td>
<td><p>60</p></td>
</tr>
<tr class="row-odd"><td><p>重  庆</p></td>
<td><p>1130</p></td>
<td><p>96</p></td>
<td><p>231</p></td>
<td><p>96</p></td>
<td><p>163</p></td>
<td><p>250</p></td>
<td><p>143</p></td>
<td><p>33</p></td>
</tr>
<tr class="row-even"><td><p>四  川</p></td>
<td><p>1244</p></td>
<td><p>116</p></td>
<td><p>234</p></td>
<td><p>102</p></td>
<td><p>172</p></td>
<td><p>225</p></td>
<td><p>144</p></td>
<td><p>36</p></td>
</tr>
<tr class="row-odd"><td><p>贵  州</p></td>
<td><p>820</p></td>
<td><p>80</p></td>
<td><p>236</p></td>
<td><p>62</p></td>
<td><p>99</p></td>
<td><p>161</p></td>
<td><p>72</p></td>
<td><p>24</p></td>
</tr>
<tr class="row-even"><td><p>云  南</p></td>
<td><p>976</p></td>
<td><p>80</p></td>
<td><p>226</p></td>
<td><p>67</p></td>
<td><p>100</p></td>
<td><p>183</p></td>
<td><p>122</p></td>
<td><p>35</p></td>
</tr>
<tr class="row-odd"><td><p>西  藏</p></td>
<td><p>1185</p></td>
<td><p>182</p></td>
<td><p>84</p></td>
<td><p>81</p></td>
<td><p>79</p></td>
<td><p>28</p></td>
<td><p>44</p></td>
<td><p>39</p></td>
</tr>
<tr class="row-even"><td><p>陕  西</p></td>
<td><p>813</p></td>
<td><p>124</p></td>
<td><p>212</p></td>
<td><p>84</p></td>
<td><p>163</p></td>
<td><p>297</p></td>
<td><p>166</p></td>
<td><p>38</p></td>
</tr>
<tr class="row-odd"><td><p>甘  肃</p></td>
<td><p>859</p></td>
<td><p>92</p></td>
<td><p>241</p></td>
<td><p>74</p></td>
<td><p>155</p></td>
<td><p>258</p></td>
<td><p>114</p></td>
<td><p>27</p></td>
</tr>
<tr class="row-even"><td><p>青  海</p></td>
<td><p>893</p></td>
<td><p>156</p></td>
<td><p>329</p></td>
<td><p>84</p></td>
<td><p>208</p></td>
<td><p>110</p></td>
<td><p>152</p></td>
<td><p>43</p></td>
</tr>
<tr class="row-odd"><td><p>宁  夏</p></td>
<td><p>923</p></td>
<td><p>143</p></td>
<td><p>346</p></td>
<td><p>77</p></td>
<td><p>178</p></td>
<td><p>178</p></td>
<td><p>199</p></td>
<td><p>51</p></td>
</tr>
<tr class="row-even"><td><p>新  疆</p></td>
<td><p>804</p></td>
<td><p>171</p></td>
<td><p>333</p></td>
<td><p>68</p></td>
<td><p>183</p></td>
<td><p>159</p></td>
<td><p>169</p></td>
<td><p>36</p></td>
</tr>
</tbody>
</table>
</div>
<p>主成分分析的 Python 代码为：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">scale</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># 下面前几行代码是为了运行 live code 而进行的设置，</span>
<span class="c1"># 与本章的教学内容无关</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;/home/jovyan&quot;</span><span class="p">:</span>
    <span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s2">&quot;data-science/&quot;</span><span class="p">)</span>

<span class="c1"># 正文</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s2">&quot;datas/data-pca.xlsx&quot;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># 读取数据</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">scale</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>  <span class="c1"># z标准化，标准化之后就自动根据协方差矩阵进行主成分分析了</span>
<span class="c1"># data2 = np.corrcoef(np.transpose(data)) # 没有必要单独计算协方差阵或相关系数阵</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>  <span class="c1"># 可以通过参数 n_components 调整主成分个数</span>
<span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;特征根：&quot;</span><span class="p">,</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_</span><span class="p">)</span>  <span class="c1"># 输出特征根</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;主成分：&quot;</span><span class="p">,</span> <span class="n">pca</span><span class="o">.</span><span class="n">components_</span><span class="p">)</span>  <span class="c1"># 输出主成分</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>特征根： [7.32679152 0.46898546 0.16208403]

主成分： [[ 0.34197826  0.32541509  0.36029958  0.36486138  0.3682146   0.36096996
   0.35616496  0.34854195]
 [-0.54451489  0.61527353  0.11520953 -0.11674732  0.03494752  0.07480108
   0.2943857  -0.4522824 ]
 [ 0.27960446  0.69192655 -0.19973533 -0.07235855 -0.02963776 -0.42452329
  -0.39881297  0.24037227]]
</pre></div>
</div>
</div>
</div>
</section>
<section id="clustering">
<h2><span class="section-number">9.4. </span>Clustering<a class="headerlink" href="#clustering" title="Link to this heading">#</a></h2>
<hr>
<p>Kmeans 是一种动态聚类方法，其基本思想是：首先随机选取 K 个点作为初始凝聚点，按照距离最近原则划分为 K 类；然后重新计算 K 个类的重心作为新的凝聚点，再按照距离最近原则重新分类；重复这一过程，直到重心不再变化为止。</p>
<p>对上面的例子，进行 Kmeans 聚类并画图的代码为：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>  <span class="c1"># 忽略掉使用默写函数的一些警告信息</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>

<span class="c1"># 下面前几行代码是为了运行 live code 而进行的设置，</span>
<span class="c1"># 与本章的教学内容无关</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;/home/jovyan&quot;</span><span class="p">:</span>
    <span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s2">&quot;data-science/&quot;</span><span class="p">)</span>

<span class="c1"># 正文</span>
<span class="c1"># 将上述数据放到 excel 里，并用 pandas 读取</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s2">&quot;datas/data-pca.xlsx&quot;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">scale_values</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>  <span class="c1"># 数据表转化预处理</span>

<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">scale_values</span><span class="p">)</span>  <span class="c1"># 分为 3 类, 参数 n_init= &#39;auto&#39; 设置初始聚类的运行次数</span>
<span class="nb">print</span><span class="p">(</span><span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span><span class="p">)</span>  <span class="c1"># 输出判别结果列表</span>

<span class="c1"># 具体输出判别结果</span>
<span class="n">cluster_1</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">cluster_2</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">cluster_3</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">cluster_1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="k">elif</span> <span class="n">j</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">cluster_2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">cluster_3</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;类别1&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cluster_1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;类别2&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cluster_2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;类别3&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cluster_3</span><span class="p">)</span>

<span class="c1"># draw pictures by tsne, or pca, 利用主成分降为 2 维，并画图显示分类结果</span>
<span class="c1"># from sklearn.manifold import TSNE</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">tsne</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">scale_values</span><span class="p">)</span>  <span class="c1"># tsne</span>
<span class="n">df2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">tsne</span><span class="p">)</span>
<span class="n">df2</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span>

<span class="n">df_1</span> <span class="o">=</span> <span class="n">df2</span><span class="p">[</span><span class="n">df2</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">df_2</span> <span class="o">=</span> <span class="n">df2</span><span class="p">[</span><span class="n">df2</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">df_3</span> <span class="o">=</span> <span class="n">df2</span><span class="p">[</span><span class="n">df2</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span><span class="p">]</span>

<span class="c1"># 画图</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_1</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">df_1</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;bo&quot;</span><span class="p">,</span> <span class="n">df_2</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">df_2</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;r*&quot;</span><span class="p">,</span> <span class="n">df_3</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">df_3</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;gD&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1 2 0 0 2 2 2 2 1 2 1 0 2 0 2 0 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0]
类别1
[&#39;河  北&#39;, &#39;山  西&#39;, &#39;安  徽&#39;, &#39;江  西&#39;, &#39;河  南&#39;, &#39;湖  北&#39;, &#39;广  西&#39;, &#39;海  南&#39;, &#39;重  庆&#39;, &#39;四  川&#39;, &#39;贵  州&#39;, &#39;云  南&#39;, &#39;西  藏&#39;, &#39;陕  西&#39;, &#39;甘  肃&#39;, &#39;青  海&#39;, &#39;宁  夏&#39;, &#39;新  疆&#39;]
类别2
[&#39;北  京&#39;, &#39;上  海&#39;, &#39;浙  江&#39;]
类别3
[&#39;天  津&#39;, &#39;内蒙古&#39;, &#39;辽  宁&#39;, &#39;吉  林&#39;, &#39;黑龙江&#39;, &#39;江  苏&#39;, &#39;福  建&#39;, &#39;山  东&#39;, &#39;湖  南&#39;, &#39;广  东&#39;]
</pre></div>
</div>
<img alt="_images/9cb2030cfcb30f296cdcf858ecf6ab05b2eb69ea91bd80205b2c996ccb50f849.png" src="_images/9cb2030cfcb30f296cdcf858ecf6ab05b2eb69ea91bd80205b2c996ccb50f849.png" />
</div>
</div>
</section>
<section id="artificial-neural-network">
<h2><span class="section-number">9.5. </span>Artificial neural network<a class="headerlink" href="#artificial-neural-network" title="Link to this heading">#</a></h2>
<hr>
<p>神经网络的目标是：找到一个能把一组输入最好地映射到其正确输出的函数。例如一个简单的分类任务，其中输入是动物的图像，正确的输出将是动物的名称。或者根据历史需求数据，预测未来一期的需求。神经网络的思想类似回归分析中经常用到的拟合，都用到了最小二乘的思想：数学意义上的决策目标是：选取一些参数（神经网络中每个输入的权重），使得拟合的输出与期望输出的误差平方和最小。</p>
<p>下面是一个神经网络示意图（输入层有一些神经元，隐含层有一些神经元，输出层有一些神经元），输入信息经过正向传播到输出，计算实际输出与期望输出的误差后，在反向传播误差；重复这个过程，在传播过程中，不断减少误差，直到误差减少到一定程度终止。</p>
<p><img alt="ann.png" src="_images/ann.png" /></p>
<p>用 BP 神经网络预测 sklearn 包中自带的乳腺癌数据例子：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 测试一下癌症数据</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>

<span class="n">cancer</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_breast_cancer</span><span class="p">()</span>
<span class="n">cancer_data</span> <span class="o">=</span> <span class="n">cancer</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">]</span>
<span class="n">cancer_target</span> <span class="o">=</span> <span class="n">cancer</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span>

<span class="c1"># 将数据集划分为训练集，测试集</span>
<span class="p">(</span>
    <span class="n">cancer_data_train</span><span class="p">,</span>
    <span class="n">cancer_data_test</span><span class="p">,</span>
    <span class="n">cancer_target_train</span><span class="p">,</span>
    <span class="n">cancer_target_test</span><span class="p">,</span>
<span class="p">)</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">cancer_data</span><span class="p">,</span> <span class="n">cancer_target</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="c1"># 数据标准化</span>
<span class="n">stdScaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cancer_data_train</span><span class="p">)</span>
<span class="n">cancer_trainStd</span> <span class="o">=</span> <span class="n">stdScaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">cancer_data_train</span><span class="p">)</span>
<span class="n">cancer_testStd</span> <span class="o">=</span> <span class="n">stdScaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">cancer_data_test</span><span class="p">)</span>

<span class="c1"># 建立 BP 模型</span>
<span class="n">bpnn</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span>
    <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>  <span class="c1"># 神经元隐含层的大小</span>
    <span class="n">max_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
    <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">45</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">bpnn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cancer_trainStd</span><span class="p">,</span> <span class="n">cancer_target_train</span><span class="p">)</span>

<span class="c1"># 预测</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">bpnn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">cancer_testStd</span><span class="p">)</span>  <span class="c1"># 返回预测结果</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;神经网络预测结果评价报告：</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">cancer_target_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>神经网络预测结果评价报告：
               precision    recall  f1-score   support

           0       1.00      0.92      0.96        50
           1       0.94      1.00      0.97        64

    accuracy                           0.96       114
   macro avg       0.97      0.96      0.96       114
weighted avg       0.97      0.96      0.96       114
</pre></div>
</div>
</div>
</div>
<p>其他常见的机器学习方法，例如随机森林，支持向量机，梯度提升等，都可以在<code class="docutils literal notranslate"><span class="pre">sklearn</span></code>库中找到相应的函数。</p>
</section>
<section id="exercises">
<h2><span class="section-number">9.6. </span>Exercises<a class="headerlink" href="#exercises" title="Link to this heading">#</a></h2>
<hr><div class="exercise admonition" id="regression">

<p class="admonition-title"><span class="caption-number">Exercise 9.1 </span></p>
<section id="exercise-content">
<p>使用python 中的<code class="docutils literal notranslate"><span class="pre">statsmodels</span></code>库或<code class="docutils literal notranslate"><span class="pre">sklearn</span></code>库，编程实现《统计学》或《计量经济学》课程上的一些数据分析习题。</p>
</section>
</div>
<script src="https://giscus.app/client.js"
        data-repo="robinchen121/book-Python-Data-Science"
        data-repo-id="R_kgDOKFdyOw"
        data-category="Announcements"
        data-category-id="DIC_kwDOKFdyO84CgWHi"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="bottom"
        data-theme="light"
        data-lang="en"
        crossorigin="anonymous"
        async>
</script></section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "RobinChen121/book-Python-Data-Science-en",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "conda-base-py"
        },
        kernelOptions: {
            name: "conda-base-py",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'conda-base-py'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="statistics1.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">8. </span>Python statistics</p>
      </div>
    </a>
    <a class="right-next"
       href="introduction-to-class.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">10. </span>Python Object Oriented Programming</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression">9.1. Linear regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#standardize-data">9.2. Standardize Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#principle-component-analysis-pca">9.3. Principle component analysis (PCA)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering">9.4. Clustering</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#artificial-neural-network">9.5. Artificial neural network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">9.6. Exercises</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Zhen Chen
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>