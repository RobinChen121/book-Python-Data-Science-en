{"version":"1","records":[{"hierarchy":{"lvl1":"Getting started with Python"},"type":"lvl1","url":"/a-first-look-of-python","position":0},{"hierarchy":{"lvl1":"Getting started with Python"},"content":"\n\n","type":"content","url":"/a-first-look-of-python","position":1},{"hierarchy":{"lvl1":"Getting started with Python","lvl2":"The origin of Python"},"type":"lvl2","url":"/a-first-look-of-python#the-origin-of-python","position":2},{"hierarchy":{"lvl1":"Getting started with Python","lvl2":"The origin of Python"},"content":"\n\nThe first version of Python released in 1991—earlier than the programming language Java. For much of its early existence, Python remained a niche language and did not gain widespread popularity. However, in recent years, the rise and proliferation of big data and artificial intelligence technologies have significantly boosted Python’s popularity. Thanks to its simplicity and strong scalability, Python aligns well with the needs of these emerging technologies, allowing it to surpass many other programming languages and rise rapidly in prominence.\n\nPython was named “Programming Language of the Year” by the well-known TIOBE index in 2010, 2018, 2020, 2021 and 2024. It has consistently ranked among the top three most popular programming languages in both annual and monthly rankings. A popular saying has even emerged online: Life is short, I use Python.\n\n\n\nPython was created by a Dutch programmer Guido van Rossum. During the Christmas holiday in 1989, he decided to develop a new scripting interpreter to pass the time. His goal was to create a successor to the ABC programming language, and thus Python was born.\n\nThe name “Python” was chosen not because of the snake, but because Guido van Rossum was a big fan of the BBC television show Monty Python’s Flying Circus. However, since “python” also means a large snake in English, many Python-related tools and books use a snake as their logo or icon.\n\nPython 2.0 was released on October 16, 2000, while Python 3.0 was released on December 3, 2008. Python 3 is not backward-compatible with Python 2 code. Currently, Python 3 is the dominant version, and all Python programs in this book are based on Python 3.\n\n","type":"content","url":"/a-first-look-of-python#the-origin-of-python","position":3},{"hierarchy":{"lvl1":"Getting started with Python","lvl2":"Features of Python"},"type":"lvl2","url":"/a-first-look-of-python#features-of-python","position":4},{"hierarchy":{"lvl1":"Getting started with Python","lvl2":"Features of Python"},"content":"\n\nPython is considered one of the most concise and flexible programming languages. Compared to languages like C, C++, and Java, Python can accomplish the same tasks with significantly less code.\n\nprint('hello, world!') # python code\n\nC codes:\n\n#include <stdio.h>\n\nint main() {\n    printf(\"Hello, World!\\n\");\n    return 0;\n}\n\nC++ codes:\n\n#include <iostream>\n\nint main() {\n    std::cout << \"Hello, World!\" << std::endl;\n    return 0;\n}\n\nJava codes:\n\npublic class HelloWorld {\n    public static void main(String[] args) {\n        System.out.println(\"Hello, World!\");\n    }\n}\n\nPython offers a rich set of libraries that help programmers easily implement various functionalities. It also provides multiple interfaces that allow seamless integration with other coding lanuages like C, C++, Java, R, Matlab to develop extension modules. For this reason, many people refer to Python as a “glue language.”\n\nSome common used libraries:\n\nmath — Python’s built-in library for mathematical functions\n\nrandom — Python’s built-in library for generating random numbers\n\nnumpy — Used for array and matrix operations\n\npandas — A key tool for handling tabular data and data analysis\n\nmatplotlib — A commonly used basic plotting library\n\nseaborn — An advanced visualization library (more beautiful, more focused on statistical graphs) based on matplotlib\n\nscipy — A library for scientific computing\n\nstatsmodels — A library for statistical modeling and analysis\n\nsklearn — A machine learning library\n\nPyTorch, TensorFlow — Deep learning libraries commonly used in natural language processing and computer vision\n\nBeautifulSoup, Selenium — Libraries for web scraping\n\nPython is a fully object-oriented language—functions, modules, numbers, and strings are all treated as objects. It fully supports inheritance, overloading, derivation, and multiple inheritance, and it also allows operator overloading.\n\nEverything is an object in Python programming, Python data types are classes and variables are instances (objects) of these classes.\n\nAn “object” is a data entity in computuer memory that has a unique identity (ID), a type, and a value.\n\nAn Python object can have many functions, in which we call the function “method”.\n\nPython is a cross-platform scripting language (a dynamic language where codes are intepreted during running). Compared to compiled languages like C/C++ and Java, its execution speed is slower. However, as computer processing power continues to increase, Python’s slower speed has gradually become a negligible drawback.\n\nFamous applications developed using Python include:\n\nYouTube — A video-sharing platform\n\nDropbox — A file-sharing service\n\nInstagram — A photo-sharing app\n\nDouban — A well-known Chinese platform for book, music, and movie reviews\n\nLearning programming is different from studying subjects like math or literacy — you don’t need to memorize code, but you must type a lot of code!\n\nRecommended Websites for Learning Python:\n\nChatGpt, Grok, Gemini, DeepSeek → Ask AI and get detailed answers\n\ngeeksforgeeks.org, \n\nw3schools.com  → Online learning websites for coding\n\nStackOverflow.com → A global Q&A platform for coding\n\nGoogle\n\n","type":"content","url":"/a-first-look-of-python#features-of-python","position":5},{"hierarchy":{"lvl1":"Getting started with Python","lvl2":"Python installation"},"type":"lvl2","url":"/a-first-look-of-python#python-installation","position":6},{"hierarchy":{"lvl1":"Getting started with Python","lvl2":"Python installation"},"content":"\n\nThere are generally several ways to use Python: one is to install Anaconda, and the other is to install Python along with the integrated development environment (IDE) like PyCharm or VS code.\n\nAnaconda includes a built-in IDE Spyder and a wide range of pre-installed popular librarys, such as NumPy, Pandas, Matplotlib, and Scikit-learn. It also supports other editors like Jupyter Notebook, IPython, and RStudio. For beginners who are just starting to learn Python, Spyder is highly recommended.\n\nThe specific installation steps will not be detailed here — please visit the official websites to download and install the required software.\n\n","type":"content","url":"/a-first-look-of-python#python-installation","position":7},{"hierarchy":{"lvl1":"Getting started with Python","lvl2":"Some basic uses of Python"},"type":"lvl2","url":"/a-first-look-of-python#some-basic-uses-of-python","position":8},{"hierarchy":{"lvl1":"Getting started with Python","lvl2":"Some basic uses of Python"},"content":"\n\n","type":"content","url":"/a-first-look-of-python#some-basic-uses-of-python","position":9},{"hierarchy":{"lvl1":"Getting started with Python","lvl3":"Naming and reserved words","lvl2":"Some basic uses of Python"},"type":"lvl3","url":"/a-first-look-of-python#naming-and-reserved-words","position":10},{"hierarchy":{"lvl1":"Getting started with Python","lvl3":"Naming and reserved words","lvl2":"Some basic uses of Python"},"content":"\n\nWhen writing programs, variables are often used to store data. In Python, a variable is assigned using an equals sign (=). For example:\n\nname = \"Tim Cook\" # name is string varaible\nprint(name)\n\nmark = 75 # mark is numeric varaible\nprint(mark)\n\nPython allows variable/function/class names only contain letters, digits and underscores (_). However:\n\nA name cannot begin with a number\n\nA name cannot contain spaces\n\nA variable name cannot start with a digit.\n\nNames are case-sensitive, meaning “name” and “Name” are treated as two different variables.\n\nName = \"Donald Trump\"\nprint(Name)\n\n_score = 55 # this is a valid naming\nprint(_score)\n\nThe principle of naming is that the name should clearly indicate the meaning of the variable/function/class, making it easier to debug and for others to read your code. Sometimes, a variable name may consist of multiple words. In such cases, you can:\n\nUse underscores (_) to separate words (suggested), e.g., “average_score”\n\nCapitalize the first letter of each word, e.g., “AverageScore”\n\nThe second style is also known as Camel Case Naming, because the capital letters resemble the humps of a camel (Camel Case Naming is usually used for naming a class in Python).\n\naverage_score = 87\nprint(average_score)\n\ntips\n\nWhen typing a variable, function, method name, you can use the Tab key to get suggestions or enable auto-completion in the editor.\n\nReserved words, also known as keywords, are identifiers that are predefined and reserved by the programming language. When writing code, programmers cannot use reserved words as variable names.\n\nThere are 33 keywords in Python：\n\n\n\n\n\n\n\n\n\nand\n\nelif\n\nimport\n\nraise\n\nas\n\nelse\n\nin\n\nreturn\n\nassert\n\nexcept\n\nis\n\ntry\n\nbreak\n\nfinally\n\nlambda\n\nwhile\n\nclass\n\nfor\n\nnonlocal\n\nwith\n\ncontinue\n\nfrom\n\nnot\n\nyield\n\ndef\n\nglobal\n\nor\n\nTrue\n\ndel\n\nif\n\npass\n\nFalse\n\n\n\n\n\n\n\nNone\n\nInvalid example:\n\n1name = \"chen\"  # starts with a digit\nclass = 10       # 'class' is a reserved keyword\nuser-name = \"Donald\"  # contains a hyphen\n\n","type":"content","url":"/a-first-look-of-python#naming-and-reserved-words","position":11},{"hierarchy":{"lvl1":"Getting started with Python","lvl3":"Multiple assignments, swapping, deleting","lvl2":"Some basic uses of Python"},"type":"lvl3","url":"/a-first-look-of-python#multiple-assignments-swapping-deleting","position":12},{"hierarchy":{"lvl1":"Getting started with Python","lvl3":"Multiple assignments, swapping, deleting","lvl2":"Some basic uses of Python"},"content":"\n\nPython allows assigning the same value to multiple variables in a single line:\n\na = b = c = 50 # assign same values for 3 variables\nprint(a, b, c)\n\nWe can assign different values to multiple variables simultaneously:\n\nx, y, z = 1, 2, \"Python\"\nprint(x, y, z)\n\nSwapping two variables is easy in Python:\n\na, b = 6, 8\na, b = b, a\nprint(a, b)\n\nDeleting a variable from the computer memory can be done by using the keyword del:\n\na = 3\ndel a\n\n","type":"content","url":"/a-first-look-of-python#multiple-assignments-swapping-deleting","position":13},{"hierarchy":{"lvl1":"Getting started with Python","lvl3":"Operators","lvl2":"Some basic uses of Python"},"type":"lvl3","url":"/a-first-look-of-python#operators","position":14},{"hierarchy":{"lvl1":"Getting started with Python","lvl3":"Operators","lvl2":"Some basic uses of Python"},"content":"\n\nOperators are used to perform operations on values and variables. The operators of Python are given by the following table.\n\nOperators\n\nType\n\n+ - * / % // **\n\nArithmatic operator\n\n> >= < <= == !=\n\nRelationship operator\n\nand or not\n\nLogical operator\n\n= += *= /=\n\nAssignment operator\n\nin not in\n\nMembership operator\n\n# Variables\na = 10\nb = 3\n\n# Addition\nprint(\"Addition:\", a + b)  \n\n# Subtraction\nprint(\"Subtraction:\", a - b) \n\n# Multiplication\nprint(\"Multiplication:\", a * b)  \n\n# Division\nprint(\"Division:\", a / b) \n\n# Floor Division\nprint(\"Floor Division:\", a // b)  \n\n# Modulus\nprint(\"Modulus:\", a % b) \n\n# Exponentiation\nprint(\"Exponentiation:\", a ** b)\n\nCombining with ( ) for some complex mathematical expressions\n\na + (b - 1) ** 2 / 10\n\na = 10\nb = 20\n\nprint(a > b)\nprint(a < b)\nprint(a == b)\nprint(a != b)\nprint(a >= b)\nprint(a <= b)\n\na = True\nb = False\nprint(a and b)\nprint(a or b)\nprint(not a)\n\na = 10\nb = 5\nprint(b)\nb += a # equals b = a + b\nprint(b)\nb -= a # equals b = a - b\nprint(b)\nb *= a # equals b = a * b\nprint(b)\n\nin and not in are the membership operators that test whether a value or variable is in a sequence.\n\nx = 14\ny = 30\nlist = [10, 20, 30, 40]\n\nx in list\n\ny in list\n\nx not in list\n\n","type":"content","url":"/a-first-look-of-python#operators","position":15},{"hierarchy":{"lvl1":"Getting started with Python","lvl3":"Print and Input","lvl2":"Some basic uses of Python"},"type":"lvl3","url":"/a-first-look-of-python#print-and-input","position":16},{"hierarchy":{"lvl1":"Getting started with Python","lvl3":"Print and Input","lvl2":"Some basic uses of Python"},"content":"\n\nPrinting output in Python is straightforward with the print() function.\n\nprint(\"my university\") # output a string\n\n# output multiple variables\nname = \"Alice\"\nage = 20\ncity = \"London\"\nprint(name, age, city)\n\ninput() function is used to take user input. It returns the form of a string by default.\n\nname = input(\"please input your name：\") # take user input to the variable \"name\"\n\nprint(name) # output the name\n\n","type":"content","url":"/a-first-look-of-python#print-and-input","position":17},{"hierarchy":{"lvl1":"Getting started with Python","lvl3":"Comments and line breaking","lvl2":"Some basic uses of Python"},"type":"lvl3","url":"/a-first-look-of-python#comments-and-line-breaking","position":18},{"hierarchy":{"lvl1":"Getting started with Python","lvl3":"Comments and line breaking","lvl2":"Some basic uses of Python"},"content":"\n\nWhen writing programs, it’s often necessary to add comments in the code to explain or annotate certain parts, indicate the author or date, and improve the readability of the program. Comments are not executed by the computer. In Python, there are two ways to add comments:\n\nSingle-line comments: Use # followed by the comment text\n\nMulti-line comments: Use two sets of triple single quotes (''') or triple double quotes (\"\"\"), with the comment content placed between them\n\nprint(\"hello\") # this is a single line comment\n\n\"\"\"\nThis is \na multi line comment\n\"\"\"\nprint(\"hello\")\n\ntips\n\nMany code editors provide shortcut keys for commenting code. For example, in Spyder, use Ctrl + 1, and in Jupyter Notebook, use Ctrl + /.\n\nWhen debugging a program, comments are sometimes used to temporarily disable parts of the code that are not relevant to the debugging process, making it easier to test and troubleshoot.\n\nSometimes, when a line of code is too long and needs to be split across multiple lines, you can use the backslash (\\) at the end of the line to indicate line continuation:\n\nprint('these codes are \\\ntoo long.') # line breaking\n\nNote\n\nIn multi-line code, a backslash \\ must not be immediately followed by a comment.\n\n","type":"content","url":"/a-first-look-of-python#comments-and-line-breaking","position":19},{"hierarchy":{"lvl1":"Getting started with Python","lvl2":"Install and use libraries"},"type":"lvl2","url":"/a-first-look-of-python#install-and-use-libraries","position":20},{"hierarchy":{"lvl1":"Getting started with Python","lvl2":"Install and use libraries"},"content":"\n\npip is Python’s built-in library management tool. It allows you to search for, download, install, and uninstall Python librarys. When you install Python, pip is installed automatically. The basic syntax is:\n\n\n\npip syntax\n\ninstall library\n\npip install [library_name]\n\nuninstall library\n\npip uninstall [library_name]\n\n\n\npip install [library_name] -U\n\nupdate library\n\npip install -U [library_name]\n\n\n\nor pip install [library_name] --upgrade\n\nshow librarires list\n\npip list\n\nshow outdated libraries\n\npip list --outdated\n\nsearch a library\n\npip search [library_name]\n\nNote\n\npip install [library_name] -U equals pip install -U [library_name]\n\npip install [library_name] --upgrade equals pip install --upgrade [library_name]\n\nAnaconda also allows you to install packages from the Anaconda repository using its built-in tool, Conda. The syntax is similar to that of pip, with the main difference being that you replace pip with conda in the command.\n\nFor example，install a Yahoo finace library yfinance, input the following in the command line window：\n\npip install yfinance\n\nThen, the library yfinance is automatically downloaded and installed.\n\nWhen using libraries，first using import to import the library.\n\nimport numpy\n\nNote\n\nWhen importing the library，the name of the library is lower cased.\n\nSometimes, the keyword as is also used to abbreviate the package name:\n\nimport numpy as np\n\nThen, when using methods from NumPy in your code, we can simply use np instead of numpy.\n\nnp.log10(200) # use the method log10 from numpy\n\n\nSometimes，using the keyword from to import specific methods from a library. In this situation, there is no need to put the name of library in front of the method.\n\nfrom numpy import sqrt # import the method sqrt from the numpy library\n\nsqrt (200) # no need to put the name of the library in front of the method\n\nUse * to import all the methods in a library.\n\nfrom numpy import *\n\nIn this way, all methods from the library can be used directly without needing to prefix them with the library name.\n\nsqrt(16) \n\nAt the end of each chapter, this book introduces some of Python’s standard libraries. These built-in libraries, which require no additional installation, provide many commonly used functionalities such as file operations, mathematical computations, network communication, data processing, and more.\n\n","type":"content","url":"/a-first-look-of-python#install-and-use-libraries","position":21},{"hierarchy":{"lvl1":"Getting started with Python","lvl2":"math library"},"type":"lvl2","url":"/a-first-look-of-python#math-library","position":22},{"hierarchy":{"lvl1":"Getting started with Python","lvl2":"math library"},"content":"\n\nmath is a built-in Python library containing mathematical methods, providing 4 mathematical constants and 44 mathematical methods. These methods include: math constants, number representation methods, power and logarithmic methods, trigonometric methods and special methods.\n\nMath constants:\n\nConstants\n\nMeaning\n\nmath.pi\n\n\\pi\n\nmath.e\n\nEuler’s numbe\n\nmath.inf\n\ninfinity \\infty，minus infinity -math.inf\n\nmath.nan\n\nNon-numeric value\n\nSome numerical representation methods:\n\nMethod\n\nMeaning\n\nceil(x)\n\nReturn the smallest integer not less than x\n\nfloor(x)\n\nReturn the smallest integer less than x\n\nfactorial(x)\n\nReturn the factorial of integer x\n\nimport math\n\nmath.ceil(2.3)\n\nSome power and logarithmic methods:\n\nMethod\n\nMeaning\n\nexp(x)\n\nreturn e raised to the power of x: e^x\n\nsqrt(x)\n\nreturn the squre roort of x: \\sqrt x\n\nlog(x)\n\nreturn the natural logarithm of x: \\ln(x)\n\nmath.exp(2)\n\nmath.log(10)\n\nSome trigonometric methods:\n\nmethod\n\nmeaning\n\nsin(x)\n\nReturn the sine of angle x in radians\n\ncos(x)\n\nReturn the cosine of angle x in radians\n\nmath.sin(math.pi/2)\n\n","type":"content","url":"/a-first-look-of-python#math-library","position":23},{"hierarchy":{"lvl1":"Getting started with Python","lvl2":"Exercises"},"type":"lvl2","url":"/a-first-look-of-python#exercises","position":24},{"hierarchy":{"lvl1":"Getting started with Python","lvl2":"Exercises"},"content":"\n\nInput the following codes in your Python editor and run.# draw circles\n\nimport turtle\n\nturtle.pensize(2)\nturtle.circle(20)\nturtle.circle(40)\nturtle.circle(60)\nturtle.circle(80)\nturtle.done()\n\nDefine a variable in Python. Which of the following statement is correct?\n\nA.    int a = 5\n\nB.    var a = 5\n\nC.    a = 5\n\nD.    $a = 5\n\nSolution to \n\nExercise 2\n\nC\n\nWhat is the correct way to comment a single line in Python?\n\nA.    # This is a comment\n\nB.    -- This is a comment\n\nC.    /* This is a comment */\n\nD.     // This is a comment\n\nSolution to \n\nExercise 3\n\nA\n\nWhich of the following is a valid variable name in Python?\n\nA.    1abc\n\nB.    abc_1\n\nC.    abc-1\n\nD.    global\n\nSolution to \n\nExercise 4\n\nB\n\nWhat is the output of the following code?x = 5\ny = 2\nprint(x % y)\n\nA.    0\n\nB.    1\n\nC.    2.5\n\nD.    2\n\nSolution to \n\nExercise 5\n\nB\n\nHow do you swap the values of two variables in Python without using a third variable?\n\nA.    x + y; y = x; x = y\n\nB.    x = y, y =x\n\nC.    temp = x; x = y; y = temp\n\nD.    x, y = y, x\n\nSolution to \n\nExercise 6\n\nD\n\nWhat is the output of code:x = 5\ny = 1\ny += x\ny *= 2\nprint(y)\n\nA.    3\n\nB.    6\n\nC.    10\n\nD.    12\n\nSolution to \n\nExercise 7\n\nD\n\nwhich of the following statement is the correct way to install the library “pandas”?\n\nA.    pandas install\n\nB.    pip install pandas\n\nC.    install pandas\n\nD.    import pandas\n\nSolution to \n\nExercise 8\n\nB\n\nwhich of the following statement is the correct way to uninstall the library “seaborn”?\n\nA.    pip  uninstall seaborn\n\nB.    seaborn uninstall\n\nC.    uninstall seaborn\n\nD.    export seabron\n\nSolution to \n\nExercise 9\n\nA\n\nIf you want to use the library “pandas”, which of the following statement is wrong?\n\nA.    import pandas\n\nB.    import pandas as pd\n\nC.    from pandas import *\n\nD.    use pandas\n\nSolution to \n\nExercise 10\n\nD\n\nWhat is the correct file extension for Python files?\n\nA.    .python\n\nB.    .txt\n\nC.    .py\n\nD.    .doc\n\nSolution to \n\nExercise 11\n\nC\n\nIn Python, a = 5 is the same as A = 5?\n\nA.    True\n\nB.    False\n\nSolution to \n\nExercise 12\n\nB\n\nWrite the following math formulas in Python and get the results.\n\nx=\\frac{3^2+4-5*6}{5}\n\ny= (4^{3.5}+6)*(16\\mod{4})\n\nSolution to \n\nExercise 13x = (3**2 + 4 - 5 * 6) / 5\nprint(x)\n\ny = (4**3.5 + 6) * (16 % 4)\nprint(y)\n\nUse input to get two values and compute the sum of the two values.\n\nSolution to \n\nExercise 14# user input\nnum1 = input('input the first value：')\nnum2 = input('input the second value：')\n \n# sum\nsum = float(num1) + float(num2)\n \n# 显示计算结果\nprint(sum)\n\n\n\n Toogle google translation \n\n","type":"content","url":"/a-first-look-of-python#exercises","position":25},{"hierarchy":{"lvl1":"Data types in Python"},"type":"lvl1","url":"/basic-data-type","position":0},{"hierarchy":{"lvl1":"Data types in Python"},"content":"\n\nPython data types are the classification or categorization of data items. Different data types can be performed on different operations.\n\nThe following is chart about the built-in data types in Python:\n\nflowchart TD\n    A[Python Data Types] --> B[Numeric]\n\n    subgraph B [Numeric]\n        B1[Integer]\n        B2[Float]\n    end\n    \n    A --> C[Dictionary]\n    A --> D[Boolean]\n    A --> E[Set]\n    A --> F[Sequence]\n\n    \n\n    subgraph F [Sequence]\n        F1[List]\n        F2[Tuple]\n        F3[String]\n    end\n\n","type":"content","url":"/basic-data-type","position":1},{"hierarchy":{"lvl1":"Data types in Python","lvl2":"Numeric: integer and float"},"type":"lvl2","url":"/basic-data-type#numeric-integer-and-float","position":2},{"hierarchy":{"lvl1":"Data types in Python","lvl2":"Numeric: integer and float"},"content":"\n\na = 1\na\n\nb = 2.2\nb\n\nUnlike some other programming languages, Python does not require explicit variable type declarations. It can automatically infer numeric types. For example, in the code above, since a has no decimal point, Python treats it as an integer (int), while b contains a decimal point, so Python interprets it as a floating-point number (float).\n\nWe can use the Python keyword type to get the type of a variable.\n\ntype(a)\n\ntype(b)\n\nType casting refers to converting one data type into another. Python provides several built-in methods to facilitate casting including int(), float() and str().\n\nfloat(a)  # cast an integer variable to float\n\nint(b)  # cast a float variable to integer\n\nstr(a)\n\nWhen integers and floating-point numbers are mixed in an operation, the result will be automatically converted to a floating-point number.\n\n","type":"content","url":"/basic-data-type#numeric-integer-and-float","position":3},{"hierarchy":{"lvl1":"Data types in Python","lvl2":"String"},"type":"lvl2","url":"/basic-data-type#string","position":4},{"hierarchy":{"lvl1":"Data types in Python","lvl2":"String"},"content":"\n\nA string is a sequence of characters. We can use either single quotes ' ' or double quotes \"\" \"\" to express a string.\n\nname = 'chen'\nname\n\ncity = \"London\"\ncity\n\nWe can concatenate strings directly using the plus operator +:\n\nname + city\n\nAnother common concatenation method is using the join() method: str.join(sequence), which joins elements in the sequence with specified characters to produce a new string. For example:\n\n\",\".join([\"chen\", \"zhang\", \"li\"])  # concatenating 3 strings with comma\n\n\"-\".join([\"2020\", \"05\", \"13\"])  # concatenating 3 strings with dash\n\n\" \".join([\"Brunel\", \"University\"]) # concatenating 2 strings with space\n\nIf concatnating same strings, we can use the muliplication operator *：\n\nname = \"John\"\nname * 3\n\nwe can access individual elements of a sequence using indexing. The elements in a sequence are indexed starting from 0, and -1 from end.\n\nThe first element is at position 0, the second at 1, and so on. Negative indices are also supported, where -1 refers to the last element, -2 to the second last, and so forth.\n\nname[0]  # 0 is the first index\n\nname[-1]\n\nname[-2]\n\nThe syntax for slicing in a sequence is sequence[start:end], where start is the starting index (included) and end is the stopping index (excluded).\n\nname[0:3]  # get the first to the third characters\n\nname[1:] # get all the characters from the frist index to end\n\nTo check whether a character or substring exists in a sequence, you can use the in or not in operators:\n\n\"c\" not in name\n\n\"Bei\" in city\n\ninput multi-line string using triple quotes \"\"\" \"\"\" or ''' '''.\n\nstr_multi = ''' this is \na multi line\nstring'''\n\nprint(str_multi)\n\nCast other data types to string can be done by using the method str:\n\nstr(123)\n\nstr([1, 2, 3])\n\nSome widely used methods for string operations:\n\nMethod\n\nMeaning\n\nstr.capitalize()\n\nCapitalize the first character in the string ‘str’\n\nstr.upper()\n\nConvert all the characters in the string ‘str’ to uppercase\n\nstr.lower()\n\nConvert all the characters in the string ‘str’ to lowercase\n\nlen(str)\n\nlength of the sequence ‘str’\n\nstr.isnumeric()\n\nTo check if a string ‘str’ contains only numeric characters\n\nstr.isdigit()\n\nTo check if a string ‘str’ contains only digits (0-9)\n\nstr.isalpha()\n\nTo check if all characters in a string ‘str’ are alphabetic (letters)\n\nstr.replace(old, new])\n\nReturn a copy of the string  ‘str’ where the substring ‘old’ is replaced by the substring ‘new’\n\nstr.strip([chars])\n\nReturn a copy of the string  ‘str’ with leading and trailing characters removed specified in the ‘chars’ argument.\n\nstr.split(sep=None)\n\nReturns a list of substrings by splitting the string ‘str’ of the specified separator ‘sep’\n\nNote\n\nThere may be more arguments in those methods. Interested readers may refer to relevant resources for further details.\n\nstr1 = \"python data science\"\nstr1.split()\n\nstr1 = \"python Data Science\"\nstr1.lower()\n\nstr1.capitalize()\n\nstr1 = \" Brunel University London \"\nstr1.strip(' ')\n\nstr1.replace(\"University\", \"School\")\n\n","type":"content","url":"/basic-data-type#string","position":5},{"hierarchy":{"lvl1":"Data types in Python","lvl2":"List"},"type":"lvl2","url":"/basic-data-type#list","position":6},{"hierarchy":{"lvl1":"Data types in Python","lvl2":"List"},"content":"\n\nA Python list is a dynamic sized array (automatically grows and shrinks). We can store all types of elements (including another list) in a list. List is shown by square brackets[ ]and elements are seperated by commas.\n\nlist1 = [34, 10, 25] # a list of numerics\nlist1\n\nlist2 = [\"chen\", \"zhang\", \"wang\"] # a list of strings\nlist2\n\nlist3 = [10, \"wang\", 33] # a list of mixed type of items\nlist3\n\nThe indexing and slicing of a list is same with a string.\n\nlist2[1]  # the second element of list2\n\nlist1[0:2]  # the elements indexed by 0 to 1\n\nlist1[0:]  # the elements indexed by 0 to the end\n\nStep size can ge given in slicing with the 3rd argument value\n\nlist3 = [4, 7, 8, 9, 10]\nlist3[1:4:2]  # the elements indexed by 1 to 3 with step size 2\n\nlist2[-2]  # the second last element in list2\n\nUsing two colons followed by -1 indicates reverse order\n\nlist1[::-1]  # using two colons followed by -1 indicates reverse order\n\nTo change the value of some elements in a sequence, we can diretly assign values using indexing.\n\nlist = [21, 16, 30]\nlist[1] = 10  # change the value of the second element in list\nlist\n\nTo delete some element in a sequence, we can use del along with indexing：\n\nlist = [34, 46, 23]\ndel list[1]\nlist\n\nFor lists, the operators +, *, in, and not in method identically to their string counterparts. Below are examples:\n\nlist = [13, 23]\nlist = list + [21, 65]\nlist\n\nlist * 2\n\n12 in list\n\n12 not in list\n\nA 2D list is created by nesting one-dimensional lists within square brackets.\n\na = [[1, 2, 3], [4, 5]]\na\n\nTo visit the element in a 2D list, using two sets of squre brackets with index:\n\na[1][0]\n\nAdding elements into a list by append(), insert() or extend().\n\nlist = [34, 46, 23]\nlist.append(3)  # append one element at the end of a list\nlist\n\nlist.insert(1, 10)  # insert an element 10 into the index 1 of the list\nlist\n\nlist.extend([4, 5, 6])  # extend the list with some other sequence elements in the end\nlist\n\nUse the for loop to iterate all the values in a list.\n\nlist = [3, 5, 8]\nfor i in list:\n    print(i)\n\nSome other methods：\n\nMethod\n\nMeaning\n\nmax(list)\n\nReturn the maximum in a list ‘list’\n\nmin(list)\n\nReturn the minimum in a list ‘list’\n\nlist(sequence)\n\nTransform another suquence ‘sequence’ to a list type\n\nsequence.count(element)\n\nCount the occurance of an element ‘element’ in a sequence ‘sequence’\n\nlist.reverse()\n\nReverse the list ‘list’\n\nlist.pop(index)\n\nRemove one element in a list with given index ‘index’\n\nlist.remove(element)\n\nRemove all elments in a list ‘list’ whose contents are same as element ‘element’\n\nlist.clear()\n\nClear all the elements in a list ‘list’\n\na = [1, 2, 3]\na.pop(-1)\nprint(a)\n\na.reverse()\na\n\nstr1 = 'chench'\nstr1.count('c')\n\n\n","type":"content","url":"/basic-data-type#list","position":7},{"hierarchy":{"lvl1":"Data types in Python","lvl2":"Dictionary"},"type":"lvl2","url":"/basic-data-type#dictionary","position":8},{"hierarchy":{"lvl1":"Data types in Python","lvl2":"Dictionary"},"content":"\n\nA Python dictionary is a data type that stores the value in {key: value} pairs. Values can be of any data type and can be duplicated, while keys can't be repeated and must be immutable.\n\ndict = {\"name\": \"chen\", \"score\": 95} # create a dict\ndict\n\nTo acess the value in a dict, put the corresponding key in the square bracket [ ] for the dict or use the method get():\n\ndict[\"name\"]\n\ndict.get(\"name\")\n\nTo add one item in the dict, we can use the square bracket [ ] with the new key and value：\n\ndict[\"major\"] = \"economy\"\ndict\n\nTo revise the value in a dict，assign a new value with the corresponding key：\n\ndict[\"name\"] = \"wang\"\ndict[\"mark\"] = 80\ndict\n\nTo delete one pair key-value, using del:\n\ndel dict[\"name\"]\ndict\n\nNote\n\nSince key is immutable, numeric, string and tulic can be the key, but list can not be the key in the dict.\n\nOther methods for operating a dict:\n\nMethod\n\nMeaning\n\nlen(dict)\n\nReturn the number of items in a dict ‘dict’\n\ndict.clear()\n\nRemove all the items in the dict ‘dict’\n\ndict.get(key, default=None)\n\nReturn the corresponding value for the given ‘key’ in the dict ‘dict’;\n\n\n\nif no corresponding value, return the given default value\n\ndict.values()\n\nReturn a list for all the values in the dict ‘dict’\n\ndict.keys()\n\nReturn a list for all the keys in the dict ‘dict’\n\ndict.items()\n\nReturn a list for all the items in the dict ‘dict’\n\ndict.popitem(key=None)\n\nRemove an item by the given ‘key’;\n\n\n\nif no key is given, remove the last item\n\ndict.popitem()\ndict\n\nUse the for loop together with the method values() or items() for iteration\n\nd = {1: 'John', 2: 'Male', 'age':22}\n\n# Iterate over keys\nfor key in d: # or for key in d.keys():\n    print(key)\n\n# Iterate over values\nfor value in d.values():\n    print(value)\n\n# Iterate over key-value pairs\nfor key, value in d.items():\n    print(f\"{key}: {value}\")\n\n","type":"content","url":"/basic-data-type#dictionary","position":9},{"hierarchy":{"lvl1":"Data types in Python","lvl2":"Tuple"},"type":"lvl2","url":"/basic-data-type#tuple","position":10},{"hierarchy":{"lvl1":"Data types in Python","lvl2":"Tuple"},"content":"\n\nA tuple in Python is very similar to a list, the difference is that a tuple is immutable, meaning the elements in a tuple can’t be changed after creation.\n\nTuples are created using parentheses ( ) with elements separated by commas. Accessing, slicing follows the same syntax as lists:\n\ntup = (13, \"zh\", 20)\ntup[1]\n\ntup[0:2]\n\ntup[0:]\n\nUse del to delete the tup， 也可以用运算符 +、*、in、not in：\n\ntup = (13, \"zh\", 20)\ndel tup  # fully delete the tuple 'tup'\n\nOperator +, *, in,not in can still be used:\n\ntup = (23, 45, 21)\ntup = tup + (32, 21)\ntup\n\ntup * 2\n\n25 in tup\n\n25 not in tup\n\n","type":"content","url":"/basic-data-type#tuple","position":11},{"hierarchy":{"lvl1":"Data types in Python","lvl2":"Boolean"},"type":"lvl2","url":"/basic-data-type#boolean","position":12},{"hierarchy":{"lvl1":"Data types in Python","lvl2":"Boolean"},"content":"\n\nIn Python, Boolean values (Bool) are typically produced through logical comparisons, and there are only two possible outcomes: True or False.\n\n10 > 3\n\n3 == 4\n\nWhen making logical comparisions, two equal signs == indicate equality, while a single equal sign = signifies value assignment.\n\na = 3  # one euqal sign assigns the value 3 to a\na == 4  # two equal signs judging whether the value of a equals 4\n\nIntegers and floats can be used as Boolean values with the bool() method.\n\nAny number with a value of zero (0 or 0.0) is considered False while any non-zero number (positive or negative) is considered True.\n\nEmpty list/dict/tuple/string, i.e., [], {}, (), '', are considered False.\n\nbool('')\n\nbool(0.0)\n\nLogical operations involving multiple conditions—namely “and”, “or”, and “not”—are represented in Python by the keywords and, or, and not, respectively.\n\n10 > 3 and 3 > 2\n\n10 > 3 and 3 > 4\n\n10 > 3 or 3 > 4\n\nnot 3 > 4\n\n","type":"content","url":"/basic-data-type#boolean","position":13},{"hierarchy":{"lvl1":"Data types in Python","lvl2":"Set*"},"type":"lvl2","url":"/basic-data-type#set","position":14},{"hierarchy":{"lvl1":"Data types in Python","lvl2":"Set*"},"content":"\n\nA set is an unordered sequence of unique elements, typically created using curly braces { }.\n\n* means this section may not be delivered in the class.\n\nNote\n\nTo create an empty set, you must use set() instead of { }, because { } defaults to creating an empty dictionary.\n\nset1 = {34, 23, \"chen\"}\nset1\n\nset2 = {12, \"34\", 10}\nset2\n\nSet operators are：\n\nOperator\n\nMeaning\n\n-\n\nRemove the elements that are common to both sets from the left set\n\n|\n\nThe union of two sets\n\n&\n\nThe intersetion of two sets\n\n^\n\nElements that are not the intersection of the two sets\n\nset1 = {34, 12, \"chen\"}\nset2 = {12, \"wang\", 10}\nset1 - set2\n\nset1 | set2\n\nset1 & set2\n\nset1 ^ set2\n\nTo manipulate elements in a set:\n\nUse the add() method to insert a single element\n\nUse the update() method to add multiple elements (can be from a list, tuple, or dictionary)\n\nUse the remove() method to delete a specific element\n\nCheck if an element exists in a set using in or not in operators:\n\nset = {13, 45, 67}\nset.add(10)\nset\n\nset.remove(10)\nset\n\nset.update([80, 44])\nset\n\n44 in set\n\n44 not in set\n\n","type":"content","url":"/basic-data-type#set","position":15},{"hierarchy":{"lvl1":"Data types in Python","lvl2":"random library"},"type":"lvl2","url":"/basic-data-type#random-library","position":16},{"hierarchy":{"lvl1":"Data types in Python","lvl2":"random library"},"content":"\n\nRandom numbers are widely used in simulations. Python’s built-in random module can generate common pseudorandom numbers (note that all computer-generated random numbers are pseudorandom, true random numbers cannot be artificially produced).\n\nCommonly used methods in random:\n\nMethod\n\nDescription\n\nseed(a=None)\n\nInitialize the random number seed (defaults to current system time)\n\nrandom()\n\nGenerate a float in the range [0.0, 1.0) (left inclusive)\n\nrandint(a, b)\n\nGenerate a random integer between [a, b] (both inclusive)\n\nuniform(a, b)\n\nGenerate a random float between [a, b] (both inclusive)\n\nshuffle(seq)\n\nShuffle the elements of sequence seq in place (returns None)\n\nsample(seq, k)\n\nReturn a list of k unique elements randomly selected from sequence seq\n\nThe random number seed can be specified using the seed() method. As long as the seed remains the same, the sequence of generated random numbers will also be identical.\n\nimport random\n\nrandom.random()  # the generated numbers are different every time running the code when not setting the seed\n\nrandom.seed(100)\nrandom.random()  # if setting the seed, the generated numbers are identical every time running the code\n\n","type":"content","url":"/basic-data-type#random-library","position":17},{"hierarchy":{"lvl1":"Data types in Python","lvl2":"Excercises"},"type":"lvl2","url":"/basic-data-type#excercises","position":18},{"hierarchy":{"lvl1":"Data types in Python","lvl2":"Excercises"},"content":"\n\nWhat type of number is 5.2 in Python?\n\nA.    string\n\nB.    integer\n\nC.    complex\n\nD.    float\n\nSolution to \n\nExercise 2\n\nD\n\nWhat does bool(0) return?\n\nA.    True\n\nB.    False\n\nSolution to \n\nExercise 2\n\nB\n\nWhat will be the result of the following code:print(int(35.88))\n\nA.    36\n\nB.    35.8\n\nC.    35\n\nD.    35.88\n\nSolution to \n\nExercise 3\n\nC\n\nWhat data type is the object below?arr = [1, \"brunel\", 0]\n\nA.    bool\n\nB.    str\n\nC.    list\n\nD.    dict\n\nSolution to \n\nExercise 4\n\nC\n\nWhat is the output of the following code?x = 'Welcome'\nprint(x[3:5])\n\nA.    co\n\nB.    com\n\nC.    lcom\n\nD.    lc\n\nSolution to \n\nExercise 5\n\nA\n\nWhat is the output of the following code?tup = (1, 2, 3) \nprint(2 * tup) \n\nA.    (1, 2, 3, 1, 2, 3)\n\nB.    (1, 2, 3, 4, 5, 6)\n\nC.    (2, 4, 6)\n\nD.    (1, 2, 3)\n\nSolution to \n\nExercise 6\n\nA\n\nHow to convert the string ‘10’ to a float?\n\nA.    int(10)\n\nB.    float(10)\n\nC.    float 10\n\nD.    str(10)\n\nSolution to \n\nExercise 7\n\nB\n\nWhat is a correct syntax to print a string ‘txt’ in upper case letters?\n\nA.    ‘txt’.toupper()\n\nB.    ‘txt’.to_upper()\n\nC.    ‘txt’.upper()\n\nD.    ‘txt’.capital()\n\nSolution to \n\nExercise 8\n\nC\n\nHow to return the string without any whitespace at the beginning or the end for the string txt = ’ United Kingdom '?\n\nA.    ‘txt’.space()\n\nB.    ‘txt’.strip()\n\nC.    ‘txt’.pop()\n\nD.    ‘txt’.split()\n\nSolution to \n\nExercise 9\n\nC\n\nWhat is the output of the following codes?a = 'Hello'\nb = 'World'\nprint(a + b)\n\nA.    HelloWorld\n\nB.    Hello World\n\nC.    a + b\n\nD.    ‘Hello’‘World’\n\nSolution to \n\nExercise 10\n\nA\n\nWhat is the output of the follwing code?arr = [\"uk\",\"brunel\", 100]\nprint(arr[1][2])\n\nA.    100\n\nB.    brunel\n\nC.    k\n\nD.    u\n\nSolution to \n\nExercise 11\n\nD\n\nWhat is the output of the following code?d = {1: 'us', 2: 'uk', 3: 'china', 4: 20}\nprint(len(d))\n\nA.    8\n\nB.    20\n\nC.    6\n\nD.    4\n\nSolution to \n\nExercise 12\n\nD\n\nA dictionary cannot have two keys with the same name.\n\nA.    True\n\nB.    False\n\nSolution to \n\nExercise 13\n\nA\n\nWhich of the following is considered a “True” value in Python?\n\nA.    2\n\nB.    ‘’\n\nC.    {}\n\nD.    []\n\nSolution to \n\nExercise 14\n\nA\n\nHow to access the value of year from the followinng dict?car =\t{\n  \"brand\": \"Tesla\",\n  \"year\": 2013\n}\n\nA.    car[‘year’]\n\nB.    car.get(‘year’)\n\nC.    car[2013]\n\nD.     A or B\n\nSolution to \n\nExercise 15\n\nD\n\nHow to remove the pair key-value “year”: 2013 from the followinng dict?car =\t{\n  \"brand\": \"Tesla\",\n  \"year\": 2013\n}\n\nA.    car.clear()\n\nB.    car.get(‘year’)\n\nC.    car.pop(‘year’)\n\nD.    car.remove(‘year’)\n\nSolution to \n\nExercise 16\n\nC\n\nHow to change the ‘type’ from ‘apple’ to ‘banana’ for the following dict?dict = {'type' : 'apple', 'name' : 'red2'}\n\nA.    dict[‘type’] = ‘banana’\n\nB.    dict(‘type’) = ‘banana’\n\nC.    dict{‘type’} = ‘banana’\n\nD.     dict[‘name’] = ‘banana’\n\nSolution to \n\nExercise 17\n\nA\n\nWhat is a correct syntax to add the value ‘Hello World’, to 3 variables in one statement?\n\nA.    x, y, z = ‘Hello World’\n\nB.    x | y | z = ‘Hello World’\n\nC.    x & y & z = ‘Hello World’\n\nD.    x = y = z = ‘Hello World’\n\nSolution to \n\nExercise 18\n\nD\n\nWhat is the output of the following codes?a = {i: i * i for i in range(4)} \nprint (a) \n\nA.    {1, 2, 3, 4}\n\nB.    {0, 1, 2, 3}\n\nC.    {0: 0, 1: 1, 2: 2, 3: 3}\n\nD.     {0: 0, 1: 1, 2: 4, 3: 9}\n\nSolution to \n\nExercise 19\n\nD\n\nHow to loop trough all the values of the followinng dict?car =\t{\n  \"brand\": \"Tesla\",\n  \"year\": 2013\n}\n\nSolution to \n\nExercise 20for y in car.values():\n    print(y)\n\nHow to loop trough all the keys and values of the followinng dict?car =\t{\n  \"brand\": \"Tesla\",\n  \"year\": 2013,\n  \"price\": 30000\n}\n\nSolution to \n\nExercise 21for y, z in car.items():\n  print(y, z)\n\nRanomly sample 3 chracters from the string ‘abcedefg’. (tips: use the method in the library ‘random’)\n\nSolution to \n\nExercise 22import random\n\nrandom.sample('abcedefg', 3)\n\n\n\n Toogle google translation \n\n","type":"content","url":"/basic-data-type#excercises","position":19},{"hierarchy":{"lvl1":"Define functions"},"type":"lvl1","url":"/define-function","position":0},{"hierarchy":{"lvl1":"Define functions"},"content":"\n\nPython Functions is a block of statements that return the specific task. It is very import in coding since we can define a function to achive personalized needs.\n\nWhen writing functions in Python, the frequently used statements are conditional statements if, and loop statements such as for or while.\n\nBefore we introduce how to self define functions, let us learn some useful buit-in functions of Python.\n\n","type":"content","url":"/define-function","position":1},{"hierarchy":{"lvl1":"Define functions","lvl2":"Some built-in functions"},"type":"lvl2","url":"/define-function#some-built-in-functions","position":2},{"hierarchy":{"lvl1":"Define functions","lvl2":"Some built-in functions"},"content":"\n\nSome commonly used built-in functions are:\n\nFunction\n\nDescription\n\nsum\n\nCalculates the sum of an iterable (e.g., sequence, set)\n\nmax\n\nReturns the maximum value in an iterable\n\nmin\n\nReturns the minimum value in an iterable\n\nabs\n\nReturns the absolute value of a number\n\nround\n\nRounds a number to the nearest integer (or specified decimal places)\n\nrange\n\nGenerates a sequence of integers, commonly used in for loops\n\nsorted\n\nSorts an iterable in ascending order by default\n\nround(3.1415926, 2)  # round to a float with 2 decimals\n\nround(3.1415926)  # round to an integer\n\nIn Python, range is directly treated as an iterable data type representing a sequence of integers. It includes the end value (required, exclusive), start value (optional, inclusive), and step size (optional). You can convert a range object into a list using list().\n\nrange(10)  # an integer sequence from 0 to 9, step size is 1 by default\n\nlist(range(10)) # convert the range to a list\n\nrange(2, 10)  # an integer sequence from 2 to 10\n\nlist(range(2, 10, 2))  # an integer list from 2 to 10, step size 2\n\nrange is frequently used in the for-loop statement.\n\nfor i in range(10):\n    print(i, end=' ')\n\nAnother helpful function in the for-loop statement is eumerate(), in which its argument is an iterable and can return an enumerate object that has a counter for each element.\n\na = [20, 30, 40, 50]\nfor item, i in enumerate(a):\n    print(item, i)\n\nThe sorted() function sorts an iterable object, with ascending order as the default.\n\narr = [23, 54, 12, 37]\nsorted(arr) \n\nsorted(arr, reverse=True)  # change the 'reverse' argument to sort in descending order\n\n","type":"content","url":"/define-function#some-built-in-functions","position":3},{"hierarchy":{"lvl1":"Define functions","lvl2":"if statement"},"type":"lvl2","url":"/define-function#if-statement","position":4},{"hierarchy":{"lvl1":"Define functions","lvl2":"if statement"},"content":"\n\nThe syntax for the if statement is:\n\n\n\nif condition1:\n\n      statement_block_1\n\nelif condition2:\n\n      statement_block_2\n\nelse:\n\n      statement_block_3\n\nThe if block first checks “Condition 1”—if true, runs “statement_block_1”; otherwise, it evaluates “Condition 2”. When “Condition 2” holds, “statement_block_2” runs; if neither condition is met, “statement_block_3” executes.\n\nFor example:\n\nwage = 5000\nif wage <= 2000:\n    print(\"poor\")\nelif wage <= 4000:\n    print(\"middle\")\nelse:\n    print(\"rich\")\n\nThere can be other if statement inside one if statement. For example:\n\nwage = 1000\nif wage <= 2000:\n    print(\"poor\")\n    if wage < 1000:\n        print(\"very poor\")\n    if wage <= 500:\n        print(\"super poor\")\nelse:\n    print(\"not poor\")\n\nNote\n\nThere can be no elif block or else block inside the if block.\n\nUnlike many other programming languages, Python uses indentation to define code blocks instead of semicolons ; or curly braces {}.\n\nindentation affects the scope of commands inside a block.\n\n\n\na = 10\nif a > 10:\n    a = 25\n    print(\"Value of a is greater than 10\") # this line is not implemented\nwhile a < 20:\n    print(a)\n    a = a + 2\nprint(a + 100)\n\nIn the above code, the if block has consistent indentation, and the while block also maintains uniform indentation. This formatting enhances program readability and clearly defines the scope of different commands.\n\nThe statement print(\"Value of a is greater than 10\") aligns with a = 25, meaning both belong to the if block and execute only when the if condition is met.\n\nIf print(\"Value of a is greater than 10\") were aligned with a = 10 instead, it would no longer be part of the if block—instead, it would execute outside the if statement, regardless of the condition.\n\na = 10\nif a > 10:\n    a = 25\nprint(\"Value of a is greater than 10\") # this line is out of the if block and thus not affected by the if block\nwhile a < 20:\n    print(a)\n    a = a + 2\nprint(a + 100)\n\n","type":"content","url":"/define-function#if-statement","position":5},{"hierarchy":{"lvl1":"Define functions","lvl2":"Loop statement"},"type":"lvl2","url":"/define-function#loop-statement","position":6},{"hierarchy":{"lvl1":"Define functions","lvl2":"Loop statement"},"content":"\n\nThere are two loop statements: for and while.\n\n","type":"content","url":"/define-function#loop-statement","position":7},{"hierarchy":{"lvl1":"Define functions","lvl3":"for loop","lvl2":"Loop statement"},"type":"lvl3","url":"/define-function#for-loop","position":8},{"hierarchy":{"lvl1":"Define functions","lvl3":"for loop","lvl2":"Loop statement"},"content":"A for loop can iterate over iterable objects, such as lists, tuples, sets, dictionaries, or strings.\nThe syntax of a for loop is as follows:\n\n\n\nfor variable in iterable:\n\n      statements\n\nThe purpose of a for loop is to iterate through all elements in a iterable object and execute one or more statements.\n\nFor example:\n\nfor i in range(3):\n    print(i)\n\nThe above codes print every element in the range(3).\n\nIf the variable in the for loop is not used in the statements, we can replace the variable with _.\n\nfor _ in range(3):\n    print(\"Hello, World!\")\n\n","type":"content","url":"/define-function#for-loop","position":9},{"hierarchy":{"lvl1":"Define functions","lvl3":"while loop","lvl2":"Loop statement"},"type":"lvl3","url":"/define-function#while-loop","position":10},{"hierarchy":{"lvl1":"Define functions","lvl3":"while loop","lvl2":"Loop statement"},"content":"\n\nThey syntax for while loop is:\n\n\n\nwhile  condition:\n\n        statements\n\nIn the while loop, if the condition is met, the commands within the while loop will continue to execute indefinitely.\n\nFor example:\n\na = 1\nwhile a < 4:\n    print(a)\n    a = a + 1\n\nIn the above codes: if a is less than 4, print a and add a by 1; repeat this process until a equals 4.\n\nThe for loop and while loop are often used in combination with the break or continue statements. The break statement exits the loop entirely, while the continue statement skips the remaining code in the current iteration and proceeds to the next cycle.\n\nfor i in range(3):\n    if i == 1:\n        break\n    print(i)\nprint(\"loop is over\")\n\nIn the above codes, the break statement makes the program jump out the for loop when i equals 1.\n\nIf replacing break with continue:\n\nfor i in range(3):\n    if i == 1:\n        continue\n    print(i)\nprint(\"loop is over\")\n\nIn the above codes, when i equals 1, the continue statement skips the current iteration and proceeds with the remaining loops.\n\nExamples about break and continue in the while loop:\n\na = 1\nwhile a < 5:\n    a = a + 1\n    if a == 3:\n        break\n    print(a)\nprint(\"loop is over\")\n\na = 1\nwhile a < 5:\n    a = a + 1\n    if a == 3:\n        continue\n    print(a)\nprint(\"loop is over\")\n\nNote\n\nBoth for loops and while loops can be followed by an else statement. The else block executes only if the loop completes normally (i.e., without encountering a break).\n\n","type":"content","url":"/define-function#while-loop","position":11},{"hierarchy":{"lvl1":"Define functions","lvl2":"Self-defined functions"},"type":"lvl2","url":"/define-function#self-defined-functions","position":12},{"hierarchy":{"lvl1":"Define functions","lvl2":"Self-defined functions"},"content":"\n\nPython uses the keyword def to define a function. They syntax is:\n\n\n\ndef   function_name(parameters):\n\n         statements\n\nThe following codes define a summation function.\n\ndef add(x1, x2):\n    z = x1 + x2\n    return z\n\nThere are severy features for a self-defined function in Python.\n\nFeature\n\nDescription\n\ndef\n\nA self-defined function starts with keyword def\n\n( )\n\nFunction parameters are inside the parentheses\n\n:\n\nA colon after the right parenthesis of the parameters\n\nreturn\n\nThe return values of the fuction follows after the keyword return\n\nA Python function can return one or multiple values, or no return values. The following code returns multiple values—both the sum of the two arguments and the original arguments themselves.\n\ndef add(x1, x2):\n    z = x1 + x2\n    return z, x1, x2\n\nWhen calling a function, specify the function name and pass in the required arguments, for example:\n\nArguments are the actual values passed to the function when it is called. They replace the parameters during execution.\n\ndef add(x1, x2):\n    z = x1 + x2\n    return z\n\n\nx1 = 10\nx2 = 6\nprint(add(x1, x2))\n\nIf you don’t need to use a particular return value, you can assign it to an underscore _ as a convention to indicate unused variables.\n\ndef add(x1, x2):\n    z = x1 + x2\n    return z, x1, x2\n\n\nx1 = 10\nx2 = 6\nsums, _, b = add(x1, x2)  # use _ to represent the second value\nprint(sums)\nprint(b)\n\nIn the code above, an underscore _ is used to ignore the second return value, while the other return values are assigned to new variables.\n\nA function can also be defined without input parameters, meaning the parentheses can be left empty. For example, the following code prints the message ``Hello, world!‘’.\n\ndef hello():\n    print(\"Hello, world!\")\n\n\nhello()\n\nYou can use triple quote ''' ''' or triple quotes \"\"\" \"\"\" to add function documentation (docstring). For example:\n\ndef hello():\n    \"\"\"This is a hello function.\"\"\"\n    print(\"Hello, world!\")\n\n\nhello()\n\nIn some Python IDEs like Spyder or PyCharm, hovering the mouse over a function or class name will automatically display its documentation (docstring), significantly improving code readability.\n\n","type":"content","url":"/define-function#self-defined-functions","position":13},{"hierarchy":{"lvl1":"Define functions","lvl3":"Parameter Passing Types in Functions","lvl2":"Self-defined functions"},"type":"lvl3","url":"/define-function#parameter-passing-types-in-functions","position":14},{"hierarchy":{"lvl1":"Define functions","lvl3":"Parameter Passing Types in Functions","lvl2":"Self-defined functions"},"content":"\n\nFunction parameters in Python are categorized by mutability into two groups:\n\n• Immutable objects: numeric, strings, tuples\n\n• Mutable objects: lists, dicts, sets\n\nArguments are the actual values passed to the function when it is called. They replace the parameters during execution.\n\nFor immutable types, the original value of the parameter remains unchanged after being passed to a function. For example:\n\ndef changeNum(a): # this parameter a is valid only inside the scope of the function\n    a = 10\n\n\na = 2 # this variable is outside the scope of the function\nchangeNum(a)\nprint(a)  #  the value a is still 2\n\nIn the above code, since a numeric type is passed, the original value of the parameter remains unchanged after the function call. The same behavior applies to string and tuple types when passed as arguments.\n\nNote\n\nFor the parameters in a function, if they are immutable objects, they are local variables and only valid inside the function body. So they are different with the same-name variables outside the function defintion block.\n\nWe can use the keyword global to declare a variable inside a function refer to a variable in the global (module-level) scope rather than creating a local variable.\n\nThe global variable can not be the parameter of a function.\n\ndef changeNum(): \n    global a # declare a global variable\n    a = 10\n\n\na = 2 # this variable is outside the scope of the function\nchangeNum()\nprint(a)  #  the value a is changed\n\nWhen mutable objects (e.g., lists, dictionaries) are passed to a function, their original values can be altered if modified inside the function. This happens because Python passes them by object reference. For example:\n\ndef changeList(mylist):\n    mylist.extend([1, 2, 3])\n    return mylist\n\n\nlistTry = [10, 20, 30]\nchangeList(listTry)\nprint(listTry)  \n\n","type":"content","url":"/define-function#parameter-passing-types-in-functions","position":15},{"hierarchy":{"lvl1":"Define functions","lvl3":"Parameter passing techniques in functions","lvl2":"Self-defined functions"},"type":"lvl3","url":"/define-function#parameter-passing-techniques-in-functions","position":16},{"hierarchy":{"lvl1":"Define functions","lvl3":"Parameter passing techniques in functions","lvl2":"Self-defined functions"},"content":"\n\nThere are four main methods for passing function parameters:\n\nPositional arguments\n\nAssignment by keyword arguments\n\nDefault parameter values\n\nVariable-length arguments\n\nFor positional arguments, the function parameters are assigned values in a one-to-one correspondence with the input order.\n\ndef minus(x1, x2):\n    z = x1 - x2\n    return z\n\n\nprint(minus(10, 6))\n\nIn the code above, when calling the minus function, the parameters are assigned in order, meaning x_1 is set to 10 and x_2 is set to 6.\n\nKeyword argument passing means that when calling a function, you can directly assign values to parameters by name. Python automatically matches the values to parameters based on the names specified in parentheses. For example:\n\ndef minus(x1, x2):\n    z = x1 - x2\n    return z\n\n\nprint(minus(x2=10, x1=6))\n\nIn the above code, when calling the minus function, the parameters are explicitly assigned within the parentheses, resulting in x_2 being set to 10 and x_1 to 6.\n\nIn Python, when defining a function, you can set default values for parameters. When calling the function, if no value is provided for a parameter, the default value will be used. For example:\n\ndef minus(x1, x2=6):\n    z = x1 - x2\n    return z\n\n\nprint(minus(x1=10))  # x2 use the default value 6\nprint(minus(x1=10, x2=5))  # x2 use the value 5 since a value for x2 is provided when calling the function\n\nWhen a function receives multiple arguments, but you’re not exactly sure how many, you can use *args to represent multiple arguments, in which *args can be seen as the name of a list. For example:\n\ndef plus(x, *a):\n    print(\"x is %d\" % x)\n    for var in a:\n        x += var\n    print(\"final x is %d\" % x)\n\n\nplus(3, 4, 5)  # *a is [4, 5]\nplus(3, 4, 5, 6)  # *a is [4, 5, 6]\n\nYou can use **args to pass a variable number of keyword (name-value) arguments. For example:\n\ndef minus(x1, **a):\n    sum = 0\n    for key in a:\n        sum += a[key]\n        return x1 - sum\n\n\nprint(minus(10, x2=3, x3=5))\n\nIn the above codes, **args represents x2 = 3, x3 = 5.\n\n","type":"content","url":"/define-function#parameter-passing-techniques-in-functions","position":17},{"hierarchy":{"lvl1":"Define functions","lvl2":"Debugging"},"type":"lvl2","url":"/define-function#debugging","position":18},{"hierarchy":{"lvl1":"Define functions","lvl2":"Debugging"},"content":"\n\nDebugging a program is an unavoidable step in programming. The purpose of debugging is to help identify and fix errors in the program. Even the best programmers can’t write a completely error-free program on the first try. Python provides several common methods for debugging programs.\n\n","type":"content","url":"/define-function#debugging","position":19},{"hierarchy":{"lvl1":"Define functions","lvl3":"Debug using print()","lvl2":"Debugging"},"type":"lvl3","url":"/define-function#debug-using-print","position":20},{"hierarchy":{"lvl1":"Define functions","lvl3":"Debug using print()","lvl2":"Debugging"},"content":"\n\nThis method typically involves placing print() statements before lines of code that are suspected to contain errors, in order to print out certain variable values or function outputs. This helps the programmer determine where the error is occurring. This debugging method is suitable for situations where the code is short, the problem is simple, and only a few variables need to be checked.\n\nFor example, the following codes have a print() line to ouput the values of a and b to check the possible erros.\n\ndef divide(a, b):\n    print(f\"DEBUG: a={a}, b={b}\")  # check the value of a and b\n    return a / b \n\n\nprint(divide(10, 2))\nprint(divide(5, 0))  # there is somthing wrong here\n\nThe drawbacks of this method is: the print() positions need to be manually modified each time.\n\n","type":"content","url":"/define-function#debug-using-print","position":21},{"hierarchy":{"lvl1":"Define functions","lvl3":"Debug using a dubugger","lvl2":"Debugging"},"type":"lvl3","url":"/define-function#debug-using-a-dubugger","position":22},{"hierarchy":{"lvl1":"Define functions","lvl3":"Debug using a dubugger","lvl2":"Debugging"},"content":"\n\nPython comes with a built-in debugger called pdb. Additionally, other Python IDEs such as Spyder, PyCharm, and VS Code provide dedicated debugging features in their menu or toolbar.\n\nThe general steps for debugging with a debugger are:\n\nSet a breakpoint before the suspected problematic code line\n\nIn IDEs: Click next to the line number (a red dot will appear)\n\nIn pdb: Add the line pdb.set_trace()\n\nUse debugging tools to identify or fix errors\n\nExit debugging mode\n\nThe following codes are an example using pdb to debug:\n\nBefore using pdb, first import the pdb library by import pdb.\n\nimport pdb # import the pdb library\n\n\ndef divide(a, b):\n    pdb.set_trace()  # the line for pdb debugging\n    return a / b\n\n\nprint(divide(10, 2))\n\nAfter running the code, a pdb command-line interface will appear, allowing you to enter debugging commands for troubleshooting.\n\nSome commands for pdb:\n\nCommand\n\nFunction\n\nn (next)\n\nExecute current line (without entering functions)\n\ns (step)\n\nStep into function calls\n\nr (return)\n\nRun until current function returns\n\np var\n\nPrint variable value\n\nc (continue)\n\nContinue execution until next breakpoint\n\nq\n\nQuit debugging\n\n","type":"content","url":"/define-function#debug-using-a-dubugger","position":23},{"hierarchy":{"lvl1":"Define functions","lvl3":"Step Into, Step Over, Step Out, Resume Program","lvl2":"Debugging"},"type":"lvl3","url":"/define-function#step-into-step-over-step-out-resume-program","position":24},{"hierarchy":{"lvl1":"Define functions","lvl3":"Step Into, Step Over, Step Out, Resume Program","lvl2":"Debugging"},"content":"\n\nWhen using an IDE for debugging, Step Into, Step Over, Step Out, and Resume Program are common debugger functions, and their differences are as follows:\n\nStep IntoExecutes code line-by-line. If the current line contains a function call, it enters that function.\n\nEquivalent to s in pdb\n\nStep Over\nExecutes the current line’s code. If the line contains a function call, it runs the entire function without stepping inside, then pauses at the next line.\n\nEquivalent to n in pdb\n\nStep OutWhen inside a function: Completes the remaining code of the current function and returns to its caller.Outside functions: Continues execution until the next breakpoint or program end.\n\nEquivalent to r in pdb\n\nResume Program\nContinues program execution until the next breakpoint or program termination.\n\nEquivalent to c in pdb\n\ndef add(a, b):\n    return a + b\n\n\ndef main():\n    x = 10\n    y = 20\n    result = add(x, y)  # if using \"Step Into\" when debugging, the dubgugger will enter the first line of the \"add\" function\n    print(result)\n\n\nmain()\n\ndef add(a, b):\n    return a + b\n\n\ndef main():\n    x = 10\n    y = 20\n    result = add(x, y)  # if using \"Step Over\" here, the dubugger will execute the \"add\" function and go to the next line in the current block\n    print(result)\n\n\nmain()\n\nimport pdb\n\n\ndef add(a, b):\n    pass # If using \"Step Out\" here, the dubugger will execute the \"add\" function and return to its caller\n    return a + b  \n\n\ndef main():\n    x = 10\n    y = 20\n    result = add(x, y) # Execution will pause here after stepping out\n    print(result)\n\n\nmain()\n\nPython has a keyword called pass, which performs no operation. It is typically used as a placeholder statement and can be helpful during program debugging.\n\nIn some debuggers (such as PyCharm), Step Into My Code is an enhanced version of Step Into that serves the following purposes:\n\nSteps into your own written code while skipping Python built-in libraries and third-party library code.\n\nAvoids entering external libraries (like numpy, pandas, etc.), focusing only on debugging your own code to improve debugging efficiency.\n\nNote\n\nThe debugging fucionts in some Python IDEs may be a little different with the above descriptions, but are generally quite similar.\n\n","type":"content","url":"/define-function#step-into-step-over-step-out-resume-program","position":25},{"hierarchy":{"lvl1":"Define functions","lvl3":"Debug using try-except statements","lvl2":"Debugging"},"type":"lvl3","url":"/define-function#debug-using-try-except-statements","position":26},{"hierarchy":{"lvl1":"Define functions","lvl3":"Debug using try-except statements","lvl2":"Debugging"},"content":"\n\nWhen writing programs, sometimes you’re unsure whether the code will run correctly and want to test how it executes. In such cases, you can use a try-except statement: if the code in the try block fails to execute successfully, the program will then run the code in the except block.\n\n\n\ntry:\n\n      statements\n\nexcept SomeError:\n\n      statements\n\nFor example:\n\ndef devide(x1, x2):\n    try:\n        z = x1 / x2\n        print(z)\n    except ZeroDivisionError:  # ZeroDivisionError is an error when trying to dividing a number by zero\n        print(\"x2 should not be zero\")\n\n\ndevide(5, 0)\n\nIn the above code, if x1 can be divided by x2, output the quotient; otherwise, output a notice.\n\nCommon exception types include:\n\nException Type\n\nDescription\n\nAttributeError\n\nRaised when accessing a non-existent attribute or method of an object.\n\nIndexError\n\nOccurs when trying to access an index outside the valid range of a sequence.\n\nSyntaxError\n\nCaused by incorrect Python syntax (e.g., missing colons or parentheses).\n\nNameError\n\nRaised when referencing an undefined variable or function.\n\nTypeError\n\nOccurs when a function receives an argument of an inappropriate type.\n\nModuleNotFoundError\n\nTriggered when attempting to import a module that does not exist or cannot be found.\n\nValueError\n\nRaised when a function argument has the correct type but an invalid value.\n\n","type":"content","url":"/define-function#debug-using-try-except-statements","position":27},{"hierarchy":{"lvl1":"Define functions","lvl2":"lambda, map, filter, reduce"},"type":"lvl2","url":"/define-function#lambda-map-filter-reduce","position":28},{"hierarchy":{"lvl1":"Define functions","lvl2":"lambda, map, filter, reduce"},"content":"\n\nPython uses lambda, map, filter or reduce to create anonymous functions. The term “anonymous” means these functions are not defined using the standard def statement.\n\nKey Features:\n\nSingle-line only: Lambda functions are restricted to one expression.\n\nSyntax: Separates input arguments and the return value with a colon (:).\n\nThe syntax for lambda anonymous function is:\n\n\n\nfunction_name = lambda parameters: return statements\n\nFor example:\n\nadd = lambda x1, x2: x1 + x2\nprint(add(10, 6))\n\nIn the above codes, “add” is the function name, the parameters are x1, x2 and the return value is x1 + x2.\n\nWe can also use the if-else statement in the lambda function.\n\nMax = lambda a, b: a if a > b else b\nprint(Max(12, 20))\n\nThe map(fun, iter) function applies the function “fun” to each element in an iterable object and returns a map-type iterable object.\n\nKey Features:\n\nApplies a function to every item in an iterable (e.g., list, tuple).\n\nReturns a map object (an iterator), which can be converted to a list, tuple, etc.\n\nfun` can be:\n\nA lambda anonymous function(for simple operations).\n\nA def custom function (for complex logic).\n\na = [1, 2, 3]\nb = map(lambda x: x**2, a)  # 对 a 中每个元素平方\nb\n\nWe can use `list()`` function to convert the map-type iteratble object to the type list.\n\nlist(b)\n\nThe filter(fun, iter) function applies a filtering function “fun” to each element in the iterable iter and returns a filter-type iterable object containing only the elements that meet the condition.\n\na = [1, 2, 3]\nb = filter(lambda x: x >= 2, a)  # filter the elements which are greater equal than 2\nlist(b)\n\nThe reduce(fun, iter) function applies a function “fun” cumulatively to items in an iterable object, reducing them to a single value. It first applies the function to the first two elements in the iterable iter, then uses the result as the first input for fun when processing the third element, and so on.\n\nfrom functools import reduce  # import reduce from the library functools\n\na = [1, 2, 3, 4]\nb = reduce(lambda x1, x2: x1 + x2, a) \nb\n\nThe reduce function can also accept three parameters, in the form of reduce(fun, iter, start=None). In this case:\n\nIt first applies the function fun to the initial value start and the first element of the iterable iter.\n\nThen uses the result as the first input for fun when processing the second element.\n\nThis process continues sequentially through all elements and finally returns a single accumulated value.\n\na = [1, 2, 3, 4]\nb = reduce(lambda x1, x2: x1 + x2, a, 10)  # initial value is 10\nb\n\n","type":"content","url":"/define-function#lambda-map-filter-reduce","position":29},{"hierarchy":{"lvl1":"Define functions","lvl2":"Import other modules* [^1]"},"type":"lvl2","url":"/define-function#import-other-modules-1","position":30},{"hierarchy":{"lvl1":"Define functions","lvl2":"Import other modules* [^1]"},"content":"\n\nIn Python programming, every file with a .py extension is called a module. Often, we need to import functions from other modules just like we import some libraries.\n\n","type":"content","url":"/define-function#import-other-modules-1","position":31},{"hierarchy":{"lvl1":"Define functions","lvl3":"Where Python find modules","lvl2":"Import other modules* [^1]"},"type":"lvl3","url":"/define-function#where-python-find-modules","position":32},{"hierarchy":{"lvl1":"Define functions","lvl3":"Where Python find modules","lvl2":"Import other modules* [^1]"},"content":"\n\nThe search order for Python modules is as follows:\n\nCurrent directory (the folder where the script is located).\n\nDirectories in sys.path:\n\nPaths specified in the PYTHONPATH environment variable.\n\nStandard library paths in the Python installation directory (for built-in libraries).\n\nThe site-packages directory (for installed third-party libraries).\n\nWe can check the directories by the following code using sys.path:\n\nimport sys\n\nprint(sys.path)\n\n","type":"content","url":"/define-function#where-python-find-modules","position":33},{"hierarchy":{"lvl1":"Define functions","lvl3":"Import a sibling module","lvl2":"Import other modules* [^1]"},"type":"lvl3","url":"/define-function#import-a-sibling-module","position":34},{"hierarchy":{"lvl1":"Define functions","lvl3":"Import a sibling module","lvl2":"Import other modules* [^1]"},"content":"\n\nIf the imported module is a sibling file of the current module—meaning they share the same parent directory—for example:\n\nDirectory structureproject_root/\n│── main.py\n│── my_module.py\n\nWe can directly import the sibiling module:\n\nimport my_module\n\nIf we just want to import some function or class named “foo” in the sibling module, we can use from-import statement.\n\nfrom my_module import foo\n\n","type":"content","url":"/define-function#import-a-sibling-module","position":35},{"hierarchy":{"lvl1":"Define functions","lvl3":"Import a nephew/niece module","lvl2":"Import other modules* [^1]"},"type":"lvl3","url":"/define-function#import-a-nephew-niece-module","position":36},{"hierarchy":{"lvl1":"Define functions","lvl3":"Import a nephew/niece module","lvl2":"Import other modules* [^1]"},"content":"If the module to be imported is in a folder at the same level as the current module, for example:\n\nDirectory structureproject_root/\n│── main.py\n│── folder1/\n│    │── my_module.py\n\nWe can import “my_module.py” in the folder “folder1” by the following code.\n\nfrom folder1 import my_module\n\nIf we just want to import the function/class “foo” from “my_module.py”:\n\nfrom folder1.my_module import foo\n\n","type":"content","url":"/define-function#import-a-nephew-niece-module","position":37},{"hierarchy":{"lvl1":"Define functions","lvl3":"Import a aucle/aunt, cousin module","lvl2":"Import other modules* [^1]"},"type":"lvl3","url":"/define-function#import-a-aucle-aunt-cousin-module","position":38},{"hierarchy":{"lvl1":"Define functions","lvl3":"Import a aucle/aunt, cousin module","lvl2":"Import other modules* [^1]"},"content":"\n\nIf the imported module is the sample level with the parent folder:\n\nDirector structure1project_root/\n│── my_module.py\n│── folder1/\n│    │── main.py\n\nOr if the import module is in the folder which has same level with the parent folder:\n\nDirectory structure2project_root/\n│── folder2\n│    │── my_module.py\n│── folder1/\n│    │── main.py\n\nWe want to import “my_module.py” in the module “main.py”.\n\nFirst, we insert the parent directory to sys.path.\n\nimport sys\nimport os\n\n# get the path of  the parent directory\nparent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # .. represents the parent directory\nsys.path.insert(0, parent_dir)  # insert the parent directory to sys.path\n\nThen we can import the my_module accorderingly:\n\nIf the imported module is aucle/aunt： import my_module.\n\nIf the imported module is cousin: from folder2 import my_module.\n\nNote\n\nPyCharm automatically adds the root directory of the entire project folder to sys.path. Therefore, in PyCharm, you can directly import modules based on the folder structure without manually adding the parent directory path via sys.path.\n\nFor example，for the directory structure2, we can directly import “my_module” by the following code:\n\nfrom folder2 import my_module\n\n","type":"content","url":"/define-function#import-a-aucle-aunt-cousin-module","position":39},{"hierarchy":{"lvl1":"Define functions","lvl3":"Import using sys.path.append()","lvl2":"Import other modules* [^1]"},"type":"lvl3","url":"/define-function#import-using-sys-path-append","position":40},{"hierarchy":{"lvl1":"Define functions","lvl3":"Import using sys.path.append()","lvl2":"Import other modules* [^1]"},"content":"\n\nIf the path to your module is complex, you can use methods like sys.path.append() to add the specific path of the module you want to import.\n\nFor example, if you want to import “other_folder/my_module.py”, where other_folder is the full absolute path on your computer’s hard drive, you can do this:\n\nimport sys\nimport os\n\nsys.path.append(os.path.abspath(\"other_folder\"))  # add the path of \"other_foler\" to sys.path\nimport my_module\n\n","type":"content","url":"/define-function#import-using-sys-path-append","position":41},{"hierarchy":{"lvl1":"Define functions","lvl2":"Exercises"},"type":"lvl2","url":"/define-function#exercises","position":42},{"hierarchy":{"lvl1":"Define functions","lvl2":"Exercises"},"content":"\n\nWhich function will you use to find the absolute value of a number in Python?\n\nA.    fabs()\n\nB.    absolute()\n\nC.    abs()\n\nD.    all()\n\nSolution to \n\nExercise 1\n\nC\n\nWhat is the output of the following code?x = 'awesome'\ndef fun():\n  x = 'fantastic'\n    \nfun()\nprint('Python is ' + x)\n\nA.    Python is x\n\nB.    Python is fun\n\nC.    Python is fantasic\n\nD.    Python is awesome\n\nSolution to \n\nExercise 2\n\nD\n\nWhat is the output of the following code?x = 'awesome'\ndef fun():\n    global x\n    x = 'fantastic'\n    \nfun()\nprint('Python is ' + x)\n\nA.    Python is x\n\nB.    Python is fun\n\nC.    Python is fantasic\n\nD.    Python is awesome\n\nSolution to \n\nExercise 3\n\nC\n\nWhat is the output of the following code?y = 5\nfoo = lambda x : x * y\nprint((foo(6))\n\nA.    5\n\nB.    6\n\nC.    11\n\nD.    30\n\nSolution to \n\nExercise 4\n\nD\n\nWhat statement is to skip the current iteration and proceed with the remaining loops?\n\nA.    break\n\nB.    continue\n\nC.    end\n\nD.    return\n\nSolution to \n\nExercise 5\n\nB\n\nLambda functions can take multiple arguments.\n\nA.    True\n\nB.    False\n\nSolution to \n\nExercise 6\n\nA\n\nFor the following code:x = 300\ndef myfunc():\n  x = 200\nmyfunc()\nprint(x)\n\nWhat will be the printed result?\n\nA.    300\n\nB.    200\n\nC.    100\n\nD.    0\n\nSolution to \n\nExercise 7\n\nA\n\nFor the following code:x = 300\ndef myfunc():\n  global x\n  x = 200\nmyfunc()\nprint(x)\n\nWhat will be the printed result?\n\nA.    300\n\nB.    200\n\nC.    100\n\nD.    0\n\nSolution to \n\nExercise 8\n\nB\n\nWhat is the output of the following codes:count = 0\nwhile count < 3:\n   print(\"Hello\")\n   count += 1\nelse:\n   print(\"Else block\")\n\nA.    Prints “Hello” three times and then prints “Else block”\n\nB.    Prints “Hello” three times\n\nC.    Prints “Else block” three times\n\nD.    Raise an error\n\nSolution to \n\nExercise 9\n\nA\n\nLoop and print each element for the following list and break the loop if the item is “banana”.fruits = [\"perch\", , \"grape\", \"apple\", \"banana\", \"cherry\"]\n\nSolution to \n\nExercise 10fruits = [\"perch\", , \"grape\", \"apple\", \"banana\", \"cherry\"]\nfor x in fruits:\n  if x == \"banana\":\n    break\n  print(x)\n\nDefine a function to compute the area of a circle with given radius. (tips: area = \\pi*radius*radius)\n\nSolution to \n\nExercise 11import math\n\ndefine area_cicle(r):\n    area = math.pi * r**2\n    print(f\"the area of the circle is {area:.2f}\")\n\n\nr = 10\narea_circle(r)\n\nDefine a function, with given value of n, it can calculate the sum of the cubes of all natural numbers from 1 to n.\n\nSolution to \n\nExercise 12def sum_cube(n):\n    sum = 0\n    for i in range(1, n+1):\n        sum += i * i *i       \n    return sum\n \n   \nn = 10\nprint(sum_cube(n))\n\nDefine a dict with all the values are numeric and compute the sum of all the values.\n\nSolution to \n\nExercise 13def dict_sum(myDict):      \n    sum = 0\n    for i in myDict: \n        sum = sum + myDict[i]      \n    return sum\n  \ndict = {'a': 100, 'b':200, 'c':300} \nprint(\"Sum :\", dict_sum(dict))\n\nDefine a function to evaluate whether the input year is leap year or not. (tips: a leap year is a year value that is divisible by 4 but not by 100, or divisible by 400.)\n\nSolution to \n\nExercise 14def evaluate(year):\n    if (year % 4) == 0:\n        if (year % 100) == 0:\n            if (year % 400) == 0:\n                print(\"{} is a leap year\".format(year))  \n            else:\n                print(\"{} is not a leap year\".format(year))\n        else:\n            print(\"{} is a leap year\".format(year)) \n    else:\n        print(\"{} is not a lear year\".format(year))\n\nyear = 2025\nevaluate(year)\n\nWrite a Python function that takes a list and returns a new list with distinct elements from the first list.\n\nSample List : [1,2,3,3,3,3,4,5]\n\nUnique List : [1, 2, 3, 4, 5]\n\nSolution to \n\nExercise 15def unique_list(l):\n    # Create an empty list 'x' to store unique elements\n    x = []\n    \n    # Iterate through each element 'a' in the input list 'l'\n    for a in l:\n        # Check if the element 'a' is not already present in the list 'x'\n        if a not in x:\n            # If 'a' is not in 'x', add it to the list 'x'\n            x.append(a)\n    \n    # Return the list 'x' containing unique elements\n    return x\n\n# Print the result of calling the 'unique_list' function with a list containing duplicate elements\nprint(unique_list([1, 2, 3, 3, 3, 3, 4, 5]))\n\n\n\n Toogle google translation \n\n","type":"content","url":"/define-function#exercises","position":43},{"hierarchy":{"lvl1":"Draw graphs"},"type":"lvl1","url":"/draw-pictures","position":0},{"hierarchy":{"lvl1":"Draw graphs"},"content":"\n\nThis chapter will demonstrate how to use Python’s matplotlib library to generate various types of graphs, and briefly introduce another plotting libarary, seaborn, for creating more aesthetically pleasing and sophisticated visualizations.\n\n","type":"content","url":"/draw-pictures","position":1},{"hierarchy":{"lvl1":"Draw graphs","lvl2":"plot"},"type":"lvl2","url":"/draw-pictures#plot","position":2},{"hierarchy":{"lvl1":"Draw graphs","lvl2":"plot"},"content":"\n\nWhen using the matplotlib lirary for plotting, we typically import the pyplot interface from it and name it as plt. Then, we use the plot function to create graphs.\n\nimport matplotlib.pyplot as plt\n\nFor example, the following codes draw the graph of y=sin(x).\n\n# import the libraries\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# plt.style.use('default')\n\n# the data for plotting\nx = np.arange(0, 15, 0.1)  # x-axis coordinate data\ny = np.sin(x)  # y-axis conordinate data\n\n# put the coordinated in the function plot\nplt.plot(x, y)\nplt.text(4, 0.5, \"y=sin(x)\")  # show texts in specified coordinates\n\n# show the grid\nplt.grid()\n\n# show the graph\nplt.show()\n\nThe syntax for plot function is below：\n\nplot([x], y, [fmt], **kwargs)\n\n[x]\n\nOptional parameter, x-axis data\n\ny\n\ny-axis data\n\n[fmt]\n\nOptional parameter, defines basic style: color, marker, line style\n\n**kwargs\n\nOptional parameters, defines line width, labels, etc.\n\nNote\n\nIn this chapter, we use squre brackets [ ] to signify the optional parameters.\n\n[fmt] are the codes for color, marker and line style.\n\nColor Code\n\nEffect\n\nLine Style Code\n\nEffect\n\nMarker Code\n\nEffect\n\nb\n\nBlue\n\n-\n\nSolid line\n\no\n\nFilled circle\n\nr\n\nRed\n\n--\n\nDashed line\n\n.\n\nDot\n\ng\n\nGreen\n\n-.\n\nDash-dot\n\n+\n\nPlus sign\n\nk\n\nBlack\n\n:\n\nDotted line\n\n*\n\nAsterisk\n\nw\n\nWhite\n\n\n\n\n\nx\n\nCross\n\ny\n\nYellow\n\n\n\n\n\n^\n\nTriangle up\n\nc\n\nCyan\n\n\n\n\n\nv\n\nTriangle down\n\nm\n\nMagenta\n\n\n\n\n\ns\n\nSquare\n\ntip\n\nThe plot function fundamentally connects discrete coordinate points with lines to create graphical representations. Consequently, when only two x-coordinates and two y-coordinates are provided, it will generate a straight line segment between these two points.\n\nThe following plot examples shows the usages of  [x],[fmt],**Kwargs.\n\n# The x-axis data defaults to an arithmetic array ranging from 0 to N-1 with a step size of 1, \n# where N is the data volume of the y-axis ordinate \"y\"\nplt.plot(y)  \n\nplt.plot(x, y, \"bo \")  # line color is blue, marker is filled circle\n\nUse lw or ‘linewidth’ to set the line width.\n\nplt.plot(y, \"g-.\", lw=2)  # color is green, line style is dash-dot and line width is 2\n\nIf we want to customize the axis labels, axis ticks, tick ranges, plot title, or add a legend, we can achieve this by setting properties in pyplot functions such as:\n\nxlabel → x-axis label\n\nylabel → y-axis label\n\nxticks → x-axis ticks\n\nyticks → y-axis ticks\n\nxlim → x-axis limits\n\nylim → y-axis lmits\n\ntitle → plot title/capital\n\ngrid → display grid\n\nlegend → display legend\n\nTo adjust image clarity, we can modify the DPI (dots per inch) using plt.rcParams[\"figure.dpi\"]. To change the image size, we can set the width and height via plt.rcParams[\"figure.figsize\"].\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n# generate data\nx = np.arange(0, 15, 0.5)\ny1 = np.sin(x)\ny2 = np.cos(x)\n\n# figure size or dpi settings\nplt.figure(figsize=(4, 3), dpi=150)  \n# or plt.rcParams('figsize') = [4, 3] # the values are width, heigh in inches\n# or plt.rcParams[\"figure.dpi\"] = 100 # dpi is dots-per-inch, default is 100.0\n\n# generate multi lines using \"plot\"\nplt.plot(x, y1, \"go-.\", label=\"y=sin(x)\", linewidth=2) \nplt.plot(x, y2, \"r*--\", label=\"y=cos(x)\", linewidth=2) \n\nplt.ylabel(\"y\")  # y-axis label\nplt.xlabel(\"x\")  # x-axis label\nplt.xticks(np.arange(0, 16))  # Set the x-axis ticks to an array ranging from 0 (inclusive) to 16 (exclusive)\nplt.ylim([-2, 2])  # set the y-axis range from -2 to 2.\nplt.legend()  # show the legend\nplt.grid()  # show the grid\nplt.text(5, 1.5, \"Math graph\")  # show some texts in specified coordinates\nplt.title(\"My Python graph\")  # the capital of the picture\n\n# save the picture in the computer\nplt.savefig(\"my figure.png\")\n\n# show the picture\nplt.show()\n\nTo save the figure in the computer, use the function ‘savefig( )’ with the address texts inside the parenthesis.\n\n","type":"content","url":"/draw-pictures#plot","position":3},{"hierarchy":{"lvl1":"Draw graphs","lvl2":"Scatter plot, bar chart, histogram"},"type":"lvl2","url":"/draw-pictures#scatter-plot-bar-chart-histogram","position":4},{"hierarchy":{"lvl1":"Draw graphs","lvl2":"Scatter plot, bar chart, histogram"},"content":"","type":"content","url":"/draw-pictures#scatter-plot-bar-chart-histogram","position":5},{"hierarchy":{"lvl1":"Draw graphs","lvl3":"scatter","lvl2":"Scatter plot, bar chart, histogram"},"type":"lvl3","url":"/draw-pictures#scatter","position":6},{"hierarchy":{"lvl1":"Draw graphs","lvl3":"scatter","lvl2":"Scatter plot, bar chart, histogram"},"content":"\n\nA scatter plot (aka scatter chart, scatter graph) uses dots to represent values for two different numeric variables. The position of each dot on the horizontal and vertical axis indicates values for an individual data point. Scatter plots are used to observe relationships between variables.\n\nWe can use the functionscatter to draw scatters. They syntax for it is as belows.\n\nscatter(x, y, s=None, c=None, **kwargs)\n\nx\n\nx-coordinate data\n\ny\n\ny-coordinate data\n\n[s]\n\nOptional: a number or array specifying marker size\n\n[c]\n\nOptional: a number or array specifying marker color\n\n**kwargs\n\nOptional: additional properties (e.g., alpha for transparency)\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# data\nproduction = [1125, 1725, 2250, 2875, 2900, 3750, 4125]\ntemperature = [6, 8, 10, 13, 14, 16, 21]\n\nplt.scatter(temperature, production, s=200, c=\"g\")\nplt.xlabel(\"temperature\")  # x-axis label\nplt.ylabel(\"production\")  # y-axis label\nplt.show()\n\n","type":"content","url":"/draw-pictures#scatter","position":7},{"hierarchy":{"lvl1":"Draw graphs","lvl3":"bar, barh","lvl2":"Scatter plot, bar chart, histogram"},"type":"lvl3","url":"/draw-pictures#bar-barh","position":8},{"hierarchy":{"lvl1":"Draw graphs","lvl3":"bar, barh","lvl2":"Scatter plot, bar chart, histogram"},"content":"\n\nA bar chart, also known as a bar graph, is a visual way to represent data using rectangular bars, where the length or height of the bars is proportional to the value they represent.\n\nThe bar chart can be created using the bar function in pyplot. The basic syntax of this function is:\n\nbar(x, height, width=None, **kwargs)\n\nx\n\nX-coordinate data (bar positions)\n\nheight\n\nBar height(s) (numeric value or array)\n\nwidth\n\nOptional: bar width(s) (numeric value or array, default=None)\n\n**kwargs\n\nOptional: additional properties (e.g., color, transparency, etc.)\n\nSuppose the results of a survey on drinking water preferences among Grade 1 and Grade 2 college students are as follows:\n\nChoice\n\nGrade 1\n\nGrade 2\n\nCarbonated Drinks\n\n6\n\n9\n\nGreen Tea\n\n7\n\n4\n\nMineral Water\n\n6\n\n4\n\nJuice\n\n1\n\n5\n\nOthers\n\n2\n\n6\n\nTotal\n\n22\n\n28\n\nimport matplotlib.pyplot as plt\n\nwaters = (\"soft drinks\", \"tea\", \"mineral water\", \"juice\", \"others\")\nbuy_number = [6, 7, 6, 1, 2]\n\nplt.bar(waters, buy_number)\nplt.title(\"Survey result of drinking preference in Grade 1 students\")\nplt.show()\n\nHorizontal bar charts are created using the barh() function, which has essentially the same usage as the standard bar() function.\n\nimport matplotlib.pyplot as plt\n\nwaters = (\"soft drinks\", \"tea\", \"mineral water\", \"juice\", \"others\")\nbuy_number = [6, 7, 6, 1, 2]\n\nplt.barh(waters, buy_number)\nplt.title(\"Survey result of drinking preference in Grade 1 students\")\nplt.show()\n\nTo display survey results for two categories side-by-side using bar charts, you can:\n\nCall bar() or barh() twice with adjusted positional parameters\n\nManually control bar positions and tick labels for proper alignment\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nwaters = (\"soft drinks\", \"tea\", \"mineral water\", \"juice\", \"others\")\ny1 = [6, 7, 6, 1, 2]\ny2 = [9, 4, 4, 5, 6]\n\nbar_width = 0.3\nx1 = np.arange(len(waters))  # x-coordinates for grade 1\nx2 = x1 + bar_width  # x-coordinates for grade 2\n\nplt.bar(x1, height=y1, width=bar_width, color=\"b\", label=\"grade 1\")\nplt.bar(x2, height=y2, width=bar_width, color=\"g\", label=\"grade 2\")\n\nplt.legend()\nplt.xticks(\n    x1 + bar_width / 2, waters\n)  # index_male + bar_width/2 are the x-tick locations, and the list \"waters\" are the x-tick contents\nplt.title(\"Survery results\")\nplt.show()\n\n","type":"content","url":"/draw-pictures#bar-barh","position":9},{"hierarchy":{"lvl1":"Draw graphs","lvl3":"hist","lvl2":"Scatter plot, bar chart, histogram"},"type":"lvl3","url":"/draw-pictures#hist","position":10},{"hierarchy":{"lvl1":"Draw graphs","lvl3":"hist","lvl2":"Scatter plot, bar chart, histogram"},"content":"\n\nA histogram is a chart that plots the distribution of a numeric variable’s values as a series of bars. Each bar typically covers a range of numeric values called a bin or class; a bar’s height indicates the frequency of data points with a value within the corresponding bin.\n\nA histogram is a visual representation of the distribution of quantitative data.\n\nAlthough a histogram may look like a bar chart, but they are different. We use the function histto draw a histogram. The syntax of the function is:\n\nhist(x, bins=None, **kwargs)\n\nx\n\nInput data\n\nbins\n\nOptional parameter, number of bins. If not specified, a value will be automatically calculated.\n\n**kwargs\n\nOptional parameters to define other attributes, such as color, transparency, etc.\n\nFor example:\n\nimport matplotlib.pyplot as plt\n\nx = [141, 159, 166, 172, 177, 182, 188, 196, 203, 214, 143, 160, 167, 173, 177, 183, 189, 196, 203, 215, 144, 160, 168,\n     173,\n     178, 184, 189, 196, 205, 218, 152, 162, 170, 174, 179, 186, 190, 197, 208, 226, 158, 165, 172, 176, 182, 188, 195,\n     202, 213, 237,\n     ]\n\nplt.hist(x, color=\"r\", edgecolor=\"k\",\n         alpha=0.35)  # set the fill color red, edge color black and transparancy rate 0.35\nplt.show()\n\n","type":"content","url":"/draw-pictures#hist","position":11},{"hierarchy":{"lvl1":"Draw graphs","lvl2":"Draw multi plots subplot"},"type":"lvl2","url":"/draw-pictures#draw-multi-plots-subplot","position":12},{"hierarchy":{"lvl1":"Draw graphs","lvl2":"Draw multi plots subplot"},"content":"\n\nTo generate multiple plots at once, the subplot function is typically used. Its basic syntax is as follows:\n\nax = plt.subplot(nrows=1, ncols=1, index=1, **kwargs)\n\nnrows\n\nNumber of rows of subplots\n\nncols\n\nNumber of columns of subplots\n\nindex\n\nPosition index of the subplot, counted from top-left to bottom-right (starting at 1)\n\n**kwargs\n\nAdditional parameters, such as for specifying axis ranges\n\nax\n\nVariable name for the subplot object, used for parameter adjustment\n\nThe layout is organized in rows and columns, which are represented by the arguments nrows and ncols. The third argument index represents the index (indexing from top left to bottom right) of the current plot.\n\nThe following example demonstrates how to create 3 subplots, with one of them spanning across 2 columns.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n# the first plot\nx = np.arange(0, 10, 0.5)\ny = np.sin(x)\nax1 = plt.subplot(2, 1, 1)  # divide the canvas into 2 rows and 1 column and this subplot is in the position index 1\nax1.plot(x, y, \"go-.\")\nax1.grid()\nax1.set_title(\"sin(x)\")  # set the title of the subplot\n\n# the second plot\nproduction = [1125, 1725, 2250, 2875, 2900, 3750, 4125]\ntemp = [6, 8, 10, 13, 14, 16, 21]\nax2 = plt.subplot(2, 2, 3)  # divide the canvas into 2 rows and 1 column and this subplot is in the position index 3\nax2.scatter(temp, production, s=200, c=\"g\")  \n\n# the third plot\nwaters = (\"soft\", \"tea\", \"water\", \"juice\", \"others\")\nbuy_number = [6, 7, 6, 1, 2]\nax3 = plt.subplot(2, 2, 4)\nax3.bar(waters, buy_number)\n\nplt.suptitle(\"My plots\")  # set the title of the whole figure\nplt.show()\n\nThere is also a subplots function, which is used as fig, axs = plt.subplots(nrows=1, ncols=1, index=1, **kwargs). Here, fig is used to adjust parameters for the entire figure, while axs is used to modify parameters for individual subplots. Due to space limitations, we won’t elaborate further on this.\n\n","type":"content","url":"/draw-pictures#draw-multi-plots-subplot","position":13},{"hierarchy":{"lvl1":"Draw graphs","lvl2":"Pie chart, box chart* "},"type":"lvl2","url":"/draw-pictures#pie-chart-box-chart","position":14},{"hierarchy":{"lvl1":"Draw graphs","lvl2":"Pie chart, box chart* "},"content":"\n\n* means this section may not be delivered in class.\n\n","type":"content","url":"/draw-pictures#pie-chart-box-chart","position":15},{"hierarchy":{"lvl1":"Draw graphs","lvl3":"pie","lvl2":"Pie chart, box chart* "},"type":"lvl3","url":"/draw-pictures#pie","position":16},{"hierarchy":{"lvl1":"Draw graphs","lvl3":"pie","lvl2":"Pie chart, box chart* "},"content":"\n\nA pie chart, also known as a circle chart, is a type of graph that uses slices of a circle to represent data. Each slice represents a portion or percentage of a whole. The size of each slice corresponds to its value or proportion of the total.\n\nWe can draw the pie char using the function pie, of which the syntax is below：\n\npie(x, explode=None, labels=None, autopct=None, **kwargs)\n\nx\n\nArray, the proportional size of each wedge\n\nexplode\n\nOptional, array, the offset radius for each wedge\n\nlabels\n\nOptional, string array, labels for each wedge\n\nautopct\n\nOptional, string or function, format string or function for wedge values\n\n**kwargs\n\nOptional, additional properties like shadow, startangle, etc.\n\nimport matplotlib.pyplot as plt\n\n\nlabels = (\"soft drinks\", \"tea\", \"mineral water\", \"juice\", \"others\")\nx = [6, 10, 11, 8, 15]\nexplode = [0, 0.1, 0, 0, 0]  \n\nplt.pie(x, explode=explode, labels=labels, autopct=\"%.2f%%\", shadow=True, startangle=90)\nplt.legend()  \nplt.show()\n\n","type":"content","url":"/draw-pictures#pie","position":17},{"hierarchy":{"lvl1":"Draw graphs","lvl3":"boxplot","lvl2":"Pie chart, box chart* "},"type":"lvl3","url":"/draw-pictures#boxplot","position":18},{"hierarchy":{"lvl1":"Draw graphs","lvl3":"boxplot","lvl2":"Pie chart, box chart* "},"content":"\n\nBox plot is a graphical representation of the distribution of a dataset. It displays key summary statistics such as the median, quartiles, and potential outliers in a concise and visual manner.\n\nWe use the functionn boxplotto draw the box plot, of which the syntax is:\n\nboxplot(x, notch=false, vert=false, **kwargs)\n\nx\n\nInput data\n\nnotch\n\nOptional, whether to draw a notched boxplot\n\nvert\n\nWhether to draw vertical boxes (False for horizontal)\n\n**kwargs\n\nOptional parameters for additional properties\n\nAssume a transcript as below：\n\nModule\n\nStudent A\n\nStudent B\n\nStudent C\n\nStudent D\n\nStudent E\n\nStudent F\n\nStudent G\n\nStudent H\n\nStudent I\n\nStudent J\n\nStudent K\n\nPython\n\n76\n\n90\n\n97\n\n71\n\n70\n\n93\n\n86\n\n83\n\n78\n\n85\n\n81\n\nEconomics\n\n93\n\n81\n\n76\n\n88\n\n66\n\n79\n\n83\n\n92\n\n78\n\n86\n\n78\n\nMarketing\n\n74\n\n87\n\n85\n\n69\n\n90\n\n80\n\n77\n\n84\n\n91\n\n74\n\n70\n\nFinance\n\n68\n\n75\n\n70\n\n84\n\n73\n\n60\n\n76\n\n81\n\n88\n\n68\n\n75\n\nStatistics\n\n55\n\n91\n\n68\n\n73\n\n84\n\n81\n\n70\n\n69\n\n94\n\n62\n\n71\n\nDraw the box plot:\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\nscores = [\n    [76, 90, 97, 71, 70, 93, 86, 83, 78, 85, 81],\n    [93, 81, 76, 88, 66, 79, 83, 92, 78, 86, 78],\n    [74, 87, 85, 69, 90, 80, 77, 84, 91, 74, 70],\n    [68, 75, 70, 84, 73, 60, 76, 81, 88, 68, 75],\n    [55, 91, 68, 73, 84, 81, 70, 69, 94, 62, 71],\n]\ncourses = (\"Python\", \"Economics\", \"Marketing\", \"Finance\", \"Statistics\")\n\nplt.boxplot(scores, vert=False)\nplt.yticks(np.arange(1, 6), courses)  # set the y ticks\nplt.show()\n\n","type":"content","url":"/draw-pictures#boxplot","position":19},{"hierarchy":{"lvl1":"Draw graphs","lvl2":"Introduction to Seaborn *"},"type":"lvl2","url":"/draw-pictures#introduction-to-seaborn","position":20},{"hierarchy":{"lvl1":"Draw graphs","lvl2":"Introduction to Seaborn *"},"content":"\n\nSeaborn is another commonly used Python library that builds upon matplotlib. It produces more aesthetically pleasing visualizations and integrates particularly well with Pandas data structures.\n\nInstall the library Seanborn by pip install\n\npip install seaborn\n\n# Import seaborn\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Apply the default theme\nsns.set_theme()\n\nx = np.arange(0, 15, 0.5)\ny = np.sin(x)\nplt.plot(x, y)\nplt.show()\n\nAs we can see, after applying Seaborn’s theme, the color scheme of the plot has changed. Seaborn comes with many built-in datasets, and next we’ll import the tips dataset.\n\n# Load an example dataset \"tips\"\ntips = sns.load_dataset(\"tips\")\ntips\n\n","type":"content","url":"/draw-pictures#introduction-to-seaborn","position":21},{"hierarchy":{"lvl1":"Draw graphs","lvl3":"relplot","lvl2":"Introduction to Seaborn *"},"type":"lvl3","url":"/draw-pictures#relplot","position":22},{"hierarchy":{"lvl1":"Draw graphs","lvl3":"relplot","lvl2":"Introduction to Seaborn *"},"content":"\n\ntype(tips)\n\nIt can be observed that after loading the tips dataset, it is stored as a Pandas DataFrame. Seaborn offers streamlined plotting capabilities for DataFrame structures. As an example, we’ll use the relplot() function (relational plots) to illustrate Seaborn’s visualization approach. The basic usage of relplot() is:\n\nrelplot(data=None, x=None, y=None, row=None, col=None，hue=None, kind='scatter', **kwargs)\n\ndata\n\nInput dataset, typically in Pandas DataFrame or Numpy array format\n\nx\n\nVariable for x-axis\n\ny\n\nVariable for y-axis\n\nrow/col\n\nVariables to create subplots by row or column\n\nhue\n\nGrouping variable that will produce elements with different colors\n\nkind\n\nPlot type: 'line' or 'scatter'\n\n**kwargs\n\nAdditional parameters (e.g., style, sizes, etc.)\n\nsns.relplot(\n    data=tips,\n    x=\"total_bill\",\n    y=\"tip\",\n    col=\"sex\",  # generate subplots by the category \"sex\"\n    hue=\"smoker\",  # produce different colors by the category \"smoker\"\n    style=\"smoker\",  # produce elements with different styles by the category \"smoker\"\n)\nplt.show()\n\nWhen generating line plots, data points sharing the same x-coordinate values will be aggregated. The visualization will display the mean value along with a 95% confidence interval.\n\nsns.relplot(data=tips, x=\"day\", y=\"tip\", hue=\"smoker\", kind=\"line\")  \nplt.show()\n\nSeaborn also provides the regplot function, which can perform linear regression along with a 95% confidence interval fitting on the data.\n\nsns.regplot(data=tips, x=\"total_bill\", y=\"tip\")\n\nFor curve fitting, you can further configure parameters such as order, logx, and logistic in regplot to generate the desired plot.\n\n","type":"content","url":"/draw-pictures#relplot","position":23},{"hierarchy":{"lvl1":"Draw graphs","lvl3":"barplot","lvl2":"Introduction to Seaborn *"},"type":"lvl3","url":"/draw-pictures#barplot","position":24},{"hierarchy":{"lvl1":"Draw graphs","lvl3":"barplot","lvl2":"Introduction to Seaborn *"},"content":"\n\nSeaborn provides built-in functions for generating common statistical visualizations, including:\n\nbarplot() for bar charts\n\nhistplot() for histograms\n\nboxplot() for box plots\n\nsns.barplot(\n    data=tips, y=\"day\", x=\"tip\", hue=\"smoker\", orient=\"h\"  # \"orient\" is to plot the bar whether \"vertically\" or \"horizontally\"\n)\nplt.show()\n\nsns.histplot(\n    data=tips,\n    x=\"tip\",\n)\nplt.show()\n\nsns.boxplot(\n    data=tips,\n    x=\"day\",\n    y=\"tip\",\n)\nplt.show()\n\nSeaborn offers additional plotting functions such as scatterplot for scatter plots, histplot for histograms, heatmap() for heatmaps and violinplot() for violin plots. Due to space limitations, we won’t cover them in detail here. Interested readers may refer to the official documentation for further exploration.\n\n","type":"content","url":"/draw-pictures#barplot","position":25},{"hierarchy":{"lvl1":"Draw graphs","lvl2":"Exercises"},"type":"lvl2","url":"/draw-pictures#exercises","position":26},{"hierarchy":{"lvl1":"Draw graphs","lvl2":"Exercises"},"content":"\n\nWhat is the purpose of the xlabel() function in Matplotlib?\n\nA.    Set the x-axis label\n\nB.    Set the y-axis label\n\nC.    Set the title\n\nD.    Set the legend\n\nSolution to \n\nExercise 1\n\nA\n\nWhich Matplotlib method is used to save a figure to a file?\n\nA.    savefig()\n\nB.    savefigure()\n\nC.    save()\n\nD.    output()\n\nSolution to \n\nExercise 2\n\nA\n\nWhich method below is to add text annotations to a Matplotlib plot?\n\nA.    annotate()\n\nB.    text()\n\nC.    message()\n\nD.    add_annotation()\n\nSolution to \n\nExercise 3\n\nB\n\nWhich Matplotlib method is used to set the figure size?\n\nA.    set_size()\n\nB.    figure_size()\n\nC.    set_figsize()\n\nD.    figure(figsize=())\n\nSolution to \n\nExercise 4\n\nD\n\nWhat is the purpose of the subplot() function in Matplotlib?\n\nA.    Adjust subplot spacing\n\nB.    Add subplots to a figure\n\nC.    Create multiple plots in one figure\n\nD.    Set the subplot title\n\nSolution to \n\nExercise 5\n\nC\n\nHow to set the transparency of elements in a Matplotlib plot?\n\nA.    transparency parameter in plot()\n\nB.    alpha parameter in plot()\n\nC.    set_transparency() method\n\nD.    set_alpha() method\n\nSolution to \n\nExercise 6\n\nB\n\nHow to plot a simple line graph using Matplotlib in Python?\n\nA.    plot(x_values, y_values)\n\nB.    draw_line(x_values, y_values)\n\nC.    line_plot(x_values, y_values)\n\nD.    line(x_values, y_values)\n\nSolution to \n\nExercise 7\n\nA\n\nWhich function below is most suitable to show the distribution of data?\n\nA.    bar()\n\nB.    plot()\n\nC.    hist()\n\nD.    scatter()\n\nSolution to \n\nExercise 8\n\nC\n\nPlot the graphs of the following 2 functions and fill the area between them. (tips: use fill_between to fill the color between some plots）\\begin{align}\nf(x)=&\\sqrt{2|x| - x^2}\\\\\ng(x)=&-2.14\\sqrt{\\sqrt{2}-\\sqrt{|x|}}\n\\end{align}\n\nSolution to \n\nExercise 9import matplotlib.pyplot as plt\nimport numpy as np\nimport math\n\nx = np.linspace(-2, 2, 1000)\ny1 = [math.sqrt(2 * abs(i) - i**2) for i in x]\ny2 = [-2.14 * math.sqrt(math.sqrt(2) - math.sqrt(abs(i))) for i in x]\n\nplt.plot(x, y1, \"r\")\nplt.plot(x, y2, \"r\")\nplt.fill_between(x, y1, y2, color=\"r\")\n\nplt.show()\n\nPlot the graph of the following function, and try to vary the value of α from 0 to 20 to achieve a dynamic heart-shaped effect. (tips: Use a loop combined with the parameters pause and clf to refresh the graph.)f(x)=x^{2/3}+0.9(3.3-x^2)^{1/2}\\sin(\\alpha\\pi x)\n\nSolution to \n\nExercise 10\n\nThis is a solution:import matplotlib.pyplot as plt\nimport numpy as np\n\n\n# type %matplotlib qt to shown figure in a separate window\nx = np.linspace(-1.8, 1.8, 1000)\nalpha = 1\n\nwhile alpha <= 21:\n    plt.xlim(-3, 3)\n    plt.ylim(-2, 4)\n    y = abs(x)**(2/3) + 0.9*np.sqrt(3.3 - x**2)*np.sin(alpha*(np.pi)*x)\n    plt.plot(x, y)\n    \n    plt.text(-1.6, 3, r'$f(x)=x^{2/3}+0.9(3.3-x^2)^{1/2}\\sin(\\alpha\\pi x)$')   \n    alpha_s = str(round(alpha, 2))\n    tx = plt.text(-0.5, 2.5, r'$\\alpha=$' + alpha_s)\n    plt.pause(0.02) # pause 0.02 s\n    if alpha <= 20:\n        alpha += 0.1\n        plt.clf() # clear current figure\n    else:\n        break\n\nThis is another solution:import numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.animation import FuncAnimation\n\n\ndef animate(alpha):\n    x = np.linspace(-1.8, 1.8, 1000)\n    y = abs(x) ** (2 / 3) + 0.9 * np.sqrt(3.3 - x**2) * np.sin(alpha * (np.pi) * x)\n    PLOT.set_data(x, y)\n    time_text.set_text(r\"$\\alpha$ = \" + str(round(alpha, 2)))\n    return PLOT, time_text\n\n\nfig = plt.figure()\nax = fig.add_subplot(111, xlim=(-2.5, 2.5), ylim=(-2, 4))  # or plt.subplot\n(PLOT,) = ax.plot([], [])  # return all the lines\nplt.text(-1.2, 3, r\"$f(x)=x^{2/3}+0.9(3.3-x^2)^{1/2}\\sin(\\alpha\\pi x)$\")\ntime_text = ax.text(-0.45, 2.5, \"\")  # transform = ax.transAxes\n\nani = FuncAnimation(fig, animate, frames=100, interval=200, repeat=False)\nplt.show()\n\n\n\n Toogle google translation \n\n","type":"content","url":"/draw-pictures#exercises","position":27},{"hierarchy":{"lvl1":"Preface"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Preface"},"content":"\n\nThis book is designed to help readers quickly master Python data analysis techniques through clear explanations and concise code. Drawing on the author’s extensive experience teaching Python courses, the content is especially tailored for students in business schools.\n\nThe material in this book is adapted from my previously online Chinese-language book, various blog posts, LaTeX-based lecture notes, and teaching resources used in my Python classes.\n\nI am currently a lecturer at Brunel University London, and I hope this book will support students in developing practical coding skills for business analytics.\n\nDr Zhen Chen\n\n21th May, 2025 at Uxbridge, UK Toogle google translation \n\n","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Introduction to Numpy"},"type":"lvl1","url":"/introduction-to-numpy","position":0},{"hierarchy":{"lvl1":"Introduction to Numpy"},"content":"\n\nNumpy is a crucial extension library in Python that provides extensive support for array and matrix operations, along with a comprehensive collection of mathematical methods designed to emulate the capabilities of mathematical software like MATLAB. NumPy is indispensable for data science, engineering, and research due to its efficiency and integration with other key libraries like Pandas, Matplotlib, Scipy, etc.\n\nKey Features of NumPy:\n\nMulti-dimensional Arrays:\n\nEfficient ndarray objects for numerical computations\n\nSupports vectorized operations\n\nMathematical methods:\n\nLinear algebra, Fourier transforms, random number generation, etc.\n\nWe first need to import the numpy library before using it:\n\nimport numpy as np\n\n","type":"content","url":"/introduction-to-numpy","position":1},{"hierarchy":{"lvl1":"Introduction to Numpy","lvl2":"Create an array"},"type":"lvl2","url":"/introduction-to-numpy#create-an-array","position":2},{"hierarchy":{"lvl1":"Introduction to Numpy","lvl2":"Create an array"},"content":"\n\nThe array method in NumPy can directly convert Python’s sequence type into NumPy’s array type ndarray.\n\nFor example, a one-dimensional array:\n\na = np.array((1, 2, 3, 4))\nprint(a)\ntype(a)\n\nA two-dimensional array:\n\nb = [[1, 2], [3, 4]]\na = np.array(b)\na\n\nNote\n\nThe parentheses in the array method must include a sequence type; it cannot be written directly as np.array(1, 2, 3, 4).\n\nIn NumPy, the zeros method can create a matrix with all elements set to 0, the ones method can create a matrix with all elements set to 1, and the empty method can create an uninitialized matrix with arbitrary element values.\n\nnp.zeros((3, 4))  # a zero matrix of 3 rows and 4 columns\n\nnp.ones((3, 4))  # a ones matrix of 3 rows and 4 columns\n\nnp.empty((3, 4))  # an empty matrix of 3 rows and 4 columns\n\nIn NumPy, the arange method can generate an array with an arithmetic sequence.\n\nnp.arange(10)  # generate an array from 0 to 10 (exclusive) with a default step size of 1\n\nnp.arange(5, 10)  # generate an array from 5 to 10 (exclusive) with a default step size of 1\n\nnp.arange(5, 10, 2)  # enerate an array from 5 to 10 (exclusive) with step size of 2\n\nAnother similar method is linspace. The difference is that in the arange method, the third argument represents the step size of the arithmetic sequence, while in the linspace method, the third argument indicates the total number of elements to generate. If you need to generate a sequence of equally spaced floating-point numbers, using linspace is preferable.\n\nnp.linspace(0, 2, 9)  # generate 9 numbers from 0 to 2 (exclusive)\n\nWe can cast the type from ndarray to list by using list().\n\na = np.arange(10)\nlist(a)\n\nThe common attributes for ndarray are listed in the table below:\n\nProperty\n\nMeaning\n\nndarray.ndim\n\nDimensions of the ndarray\n\nndarray.shape\n\nA tuple of integers representing the size of the array in each dimension\n\nndarray.size\n\nTotal number of elements in the array\n\nndarray.dtype\n\nData type of the elements in the array\n\na = np.ones((2, 3))\na.ndim\n\na.shape\n\na.size\n\na.dtype\n\n","type":"content","url":"/introduction-to-numpy#create-an-array","position":3},{"hierarchy":{"lvl1":"Introduction to Numpy","lvl2":"Indexing and slicing"},"type":"lvl2","url":"/introduction-to-numpy#indexing-and-slicing","position":4},{"hierarchy":{"lvl1":"Introduction to Numpy","lvl2":"Indexing and slicing"},"content":"\n\nFor one-dimensional arrays, NumPy’s indexing and slicing are similar to those of Python list types.\n\na = np.arange(4, 10)  \na[2]\n\na[2]  # 数组 a 的第 3 个元素\n\na[2:4]  # the 3rd and 4th of the ndarray\n\na[-1]  # the last element in the array\n\na[::-1]  # reverse of the array\n\nFor multidimensional arrays, NumPy array indexing and slicing use a single pair of brackets [ ] with commas separating different dimensions.\n\n# Create a 3-row by 4-column two-dimensional array by the 'reshape 'method\n# 'reshape' does not alter the values but reorganizes the original array with the specified number of rows and columns\nb = np.arange(12).reshape(3, 4)  \nprint(b)\n\nb[1, 2]  # the element at row 2, column 3\n\nb[1:3, 2]  # the elements from the 2nd to 3rd row in the 3rd column of the two-dimensional array.\n\nb[2, :]  # all the elments in the 3rd row\n\nlist(b) # cast the 2-D ndarray to a list\n\n","type":"content","url":"/introduction-to-numpy#indexing-and-slicing","position":5},{"hierarchy":{"lvl1":"Introduction to Numpy","lvl2":"Concatenating"},"type":"lvl2","url":"/introduction-to-numpy#concatenating","position":6},{"hierarchy":{"lvl1":"Introduction to Numpy","lvl2":"Concatenating"},"content":"\n\nIn NumPy, arrays can be concatenated using the append or concatenate method: append joins two arrays, while concatenate can join two or more arrays.\n\na = np.arange(5)\na\n\nb = np.arange(3)\nb\n\nnp.append(a, b)\n\nc = np.arange(4)\nc\n\nnp.concatenate((a, b, c))  # there are parentheses () inside\n\n","type":"content","url":"/introduction-to-numpy#concatenating","position":7},{"hierarchy":{"lvl1":"Introduction to Numpy","lvl2":"Array computations"},"type":"lvl2","url":"/introduction-to-numpy#array-computations","position":8},{"hierarchy":{"lvl1":"Introduction to Numpy","lvl2":"Array computations"},"content":"\n\nNumPy supports various algebraic operations on arrays.\n\na = np.arange(4)\nb = np.arange(3, 7)\nprint(a)\nprint(b)\nprint(a - b)\n\nprint(a + b)\n\nGet the average value of an array by mean() or average().\n\nnp.mean(a)\n\nnp.average(a)\n\nGet the average value of each column in a 2-D array with argument axis=0.\n\nGet the average value of each row in a 2-D array with and argument axis=1.\n\nc = np.array([[4.0, 5.0], [6.0, 7.0]])\nprint(np.average(c)) # or using mean\nprint(np.average(c, axis=0))  # or using mean\nprint(np.average(c, axis=1))  # or using mean\n\nGet the maximum of an array by max(), minimu by min.\n\nGet the index of the maximum value by argmax(), minium index by argmin().\n\nnp.max(a)\n\nnp.argmin(a)\n\na * 2  # multiply every element by 2\n\na**2  # square each element of the array.\n\na > 2  # comare every element with one value\n\nc = np.array([[4.0, 5.0], [6.0, 7.0]])\nprint(c)\nprint(c.transpose()) # transpose a 2-D array\n\nnp.linalg.inv(c)  # inverse matrix \n\neigenvalues, eigenvectors = np.linalg.eig(c)  # eigenvalues and eigenvectors of the 2D array c\nprint(\"eigenvalues are \", eigenvalues)\nprint(\"eigenvectors are\", eigenvectors)\n\nd = np.array([[1.0, 2.0], [3.0, 4.0]])\nd\n\nnp.dot(c, d)  # the product of matrices c and d\n\nnp.multiply(c, d)  # element-wise multiplication of matrices c and d\n\nThe NumPy library also includes several other commonly used methods, as shown in the table below:\n\nMethod\n\nDescription\n\nnp.abs(x)\n\nComputes the absolute value of each element\n\nnp.sqrt(x)\n\nComputes the square root of each element\n\nnp.square(x)\n\nComputes the square of each element\n\nnp.sign(x)\n\nDetermines the sign (positive/negative) of each element\n\nnp.ceil(x)\n\nRounds each element up to the nearest integer\n\nnp.floor(x)\n\nRounds each element down to the nearest integer\n\nnp.exp(x)\n\nComputes the exponential value of each element\n\nnp.log(x),np.log10(x),np.log2(x)\n\nComputes the natural logarithm, base-10 logarithm, and base-2 logarithm of each element\n\nNumPy performs numerical computations significantly faster than Python’s built-in list. For large-scale mathematical operations, prioritize using NumPy for processing.\n\nAdditionally, NumPy provides a specialized two-dimensional array type called Matrix, which offers more convenient operations for certain matrix computations. Interested readers can refer to the \n\nofficial documentation for details.\n\n","type":"content","url":"/introduction-to-numpy#array-computations","position":9},{"hierarchy":{"lvl1":"Introduction to Numpy","lvl2":"Generate random values using NumPy*"},"type":"lvl2","url":"/introduction-to-numpy#generate-random-values-using-numpy","position":10},{"hierarchy":{"lvl1":"Introduction to Numpy","lvl2":"Generate random values using NumPy*"},"content":"\n\nThe random module in NumPy supports virtually all probability distributions and can generate random numbers in multi-row, multi-column arrays at once.\n\n* means this section may not be delivered in class.\n\nimport numpy as np\n\nnp.random.uniform(1, 10, [2, 2])  # generate 2 row 2 column random numbers uniformally distributed between 1 (inclusive) and 10 (exclusive)\n\nnp.random.uniform(1, 10, 5)  # generate 5 random numbers uniformally distributed between 1 (inclusive) and 10 (exclusive)\n\nnp.random.randint(1, 10, [2, 2])  # generate 2 row 2 column random integer numbers uniformally distributed between 1 (inclusive) and 10 (exclusive)\n\nnp.random.normal(5, 1, [2, 2])  # generate 2 row 2 column random numbers normally distributed with mean 5 and standard deviation 1\n\nnp.random.poisson(5, [2, 2])  # generate 2 row 2 column random numbers Poisson distributed with argument 5\n\nNumPy also allows setting the seed for the random number generator via the random.seed() argument. The same seed should produce identical random numbers.\n\nnp.random.seed(500)\nnp.random.normal(5, 1, 6)  # generate 6 random numbers normally distributed with mean 5 and standard deviation 1\n\nAdditionally, NumPy also allows you to define a random number generator object via RandomState(), where the argument inside the parentheses is the random seed. You can then use this object to call specific random distribution generator methods. For example:\n\nrvs = np.random.RandomState(500)\nrvs.normal(5, 1, 6) \n\n","type":"content","url":"/introduction-to-numpy#generate-random-values-using-numpy","position":11},{"hierarchy":{"lvl1":"Introduction to Numpy","lvl2":"time, datatime library"},"type":"lvl2","url":"/introduction-to-numpy#time-datatime-library","position":12},{"hierarchy":{"lvl1":"Introduction to Numpy","lvl2":"time, datatime library"},"content":"\n\n","type":"content","url":"/introduction-to-numpy#time-datatime-library","position":13},{"hierarchy":{"lvl1":"Introduction to Numpy","lvl3":"time library","lvl2":"time, datatime library"},"type":"lvl3","url":"/introduction-to-numpy#time-library","position":14},{"hierarchy":{"lvl1":"Introduction to Numpy","lvl3":"time library","lvl2":"time, datatime library"},"content":"\n\ntime is a Python built-in libray that provides many time-related methods, such as getting the current time, pausing program execution, measuring execution time, and more.\n\nGet the current time in seconds since January 1, 1970, 00:00:00 (UTC)  by time().\n\nimport time\n\ntimestamp = time.time()\nprint(timestamp)\n\nGet a tuple of the structured format of the current time by strtime.\n\ncurrent_time = time.localtime()\nprint(current_time)\n\nGet the formatted time by strftime.\n\nformatted_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\nprint(formatted_time)\n\nThe codes for time format in strftime:\n\nCode\n\nMeaning\n\n%Y\n\n4-digit year (e.g., 2025)\n\n%y\n\n2-digit year (e.g., 25)\n\n%m\n\n2-digit month (01-12)\n\n%d\n\n2-digit day (01-31)\n\n%D\n\nEquivalent to %m/%d/%y\n\n%B\n\nFull month name (January-December)\n\n%b\n\nAbbreviated month name (e.g. Jul)\n\n%W\n\nWeek number of the year\n\n%w\n\nWeek number of the month\n\n%H\n\nHour in 24-hour format (00-23)\n\n%M\n\nMinute (00-59)\n\n%S\n\nSecond (00-59)\n\nSuspends execution for the given number of seconds using sleep().\n\nprint(\"Start\")\ntime.sleep(3)  # sleep for 3 seconds\nprint(\"End\")\n\nGet the computation time by time().\n\nstart = time.time()\nfor _ in range(1000000):\n    pass\nend = time.time()\nprint(f\"Execution time: {end - start:.6f} seconds\")\n\nGet more precise computation time by perf_counter().\n\nstart = time.perf_counter()\nfor _ in range(1000000):\n    pass\nend = time.perf_counter()\nprint(f\"Execution time: {end - start:.6f} seconds\")\n\nGet the CPU time used by the current process.\n\nstart = time.process_time()\nfor _ in range(1000000):\n    pass\nend = time.process_time()\nprint(f\"CPU time used: {end - start:.6f} seconds\")\n\n","type":"content","url":"/introduction-to-numpy#time-library","position":15},{"hierarchy":{"lvl1":"Introduction to Numpy","lvl3":"datetime library","lvl2":"time, datatime library"},"type":"lvl3","url":"/introduction-to-numpy#datetime-library","position":16},{"hierarchy":{"lvl1":"Introduction to Numpy","lvl3":"datetime library","lvl2":"time, datatime library"},"content":"\n\ndatetime is part of Python’s standard built-in library, offering methods for date and time manipulation, including fetching the current time, date calculations, timezone handling, and more.\n\nGet current datetime by now().\n\nfrom datetime import datetime\n\nnow = datetime.now()\nprint(now)\n\nCreate datetime by datetime().\n\nfrom datetime import datetime\n\ndt = datetime(2025, 2, 17, 10, 30, 57)\nprint(dt)\n\nFormat the datetime by strftime().\n\nfrom datetime import datetime\n\ndt = datetime(2025, 2, 17, 10, 30, 57)\n\nformatted_str = dt.strftime(\"%Y-%m-%d %H:%M:%S\")\nprint(formatted_str)\n\nDatetime compuation\n\nfrom datetime import datetime, timedelta\n\ndt = datetime(2025, 2, 17, 10, 30, 57)\nnew_dt = dt + timedelta(days=5, hours=3)\nprint(new_dt)\n\nfrom datetime import datetime\n\ndt1 = datetime(2025, 2, 17, 10, 30, 57)\ndt2 = datetime(2025, 2, 20, 15, 0, 0)\n\ndiff = dt2 - dt1\nprint(diff)\nprint(diff.total_seconds())\n\n","type":"content","url":"/introduction-to-numpy#datetime-library","position":17},{"hierarchy":{"lvl1":"Introduction to Numpy","lvl2":"Exercises"},"type":"lvl2","url":"/introduction-to-numpy#exercises","position":18},{"hierarchy":{"lvl1":"Introduction to Numpy","lvl2":"Exercises"},"content":"\n\nHow to create a NumPy array from a Python list?\n\nA.    np.array(list)\n\nB.    numpy(list)\n\nC.    np.create(list)\n\nD.    array(list)\n\nSolution to \n\nExercise 1\n\nA\n\nHow to access the element at the second row and third column of a 2D NumPy array ‘arr’?\n\nA.    arr[1][2]\n\nB.    arr[2, 3]\n\nC.    arr[2][3]\n\nD.    arr[1, 2]\n\nSolution to \n\nExercise 2\n\nD\n\nWhat does the np.zeros((1, 2)) method in NumPy do?\n\nA.    Create an array with ones, 1 row and 2 columns\n\nB.    Create an array with zeros, 1 row and 2 columns\n\nC.    Create an identy matrix\n\nD.    Creates an array with random values\n\nSolution to \n\nExercise 3\n\nB\n\nWhat does the code np.arange(1, 10, 2) in NumPy do?\n\nA.    Creates an array with values from 1 to 10\n\nB.    Creates an array with values from 1 to 10 with step 2\n\nC.    Creates an array with values from 1 to 9 with step 2\n\nD.    Creates an array with values from 1 to 9\n\nSolution to \n\nExercise 4\n\nC\n\nHow to find the indices of the maximum value in a NumPy array ‘arr’?\n\nA.    np.max(arr)\n\nB.    np.argmax(arr)\n\nC.    np.maximum(arr)\n\nD.    np.max_index(arr)\n\nSolution to \n\nExercise 5\n\nB\n\nHow can you calculate the mean for each row of a 2D NumPy array ‘arr’?\n\nA.    np.mean(arr, axis=2)\n\nB.    np.mean(arr, axis=0)\n\nC.    np.mean(arr, axis=1)\n\nD.    np.average(arr, axis=0)\n\nSolution to \n\nExercise 6\n\nC\n\n\n\n Toogle google translation \n\n","type":"content","url":"/introduction-to-numpy#exercises","position":19},{"hierarchy":{"lvl1":"Introduction to Pandas"},"type":"lvl1","url":"/introduction-to-pandas","position":0},{"hierarchy":{"lvl1":"Introduction to Pandas"},"content":"\n\nPandas is one of the most important data analysis tools in Python for data processing. Built on NumPy, it offers many methods for handling large datasets and allows flexible, efficient data manipulation.\n\nThe main data type used in pandas is the DataFrame, which is a two-dimensional structure similar to a table in Excel. To use pandas, you first need to import it. In fact, the name ‘Pandas’ is short for ‘panel data’.\n\nimport pandas as pd\n\n","type":"content","url":"/introduction-to-pandas","position":1},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Creating, Reading, and Storing Data"},"type":"lvl2","url":"/introduction-to-pandas#creating-reading-and-storing-data","position":2},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Creating, Reading, and Storing Data"},"content":"","type":"content","url":"/introduction-to-pandas#creating-reading-and-storing-data","position":3},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Creating Data","lvl2":"Creating, Reading, and Storing Data"},"type":"lvl3","url":"/introduction-to-pandas#creating-data","position":4},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Creating Data","lvl2":"Creating, Reading, and Storing Data"},"content":"\n\nFor example, consider the following data:\n\nName\n\nStatistics\n\nAccounting\n\nMakerting\n\nJim\n\n85\n\n82\n\n84\n\nLily\n\n68\n\n63\n\n90\n\nJack\n\n90\n\n88\n\n78\n\nIn general, there are two ways to create a DataFrame.\n\nCreate the DataFrame by dictionaries dict.\n\nCreate the DataFrame by an NumPy ndarray and argumens columns or index.\n\nimport pandas as pd\n\ndf = pd.DataFrame(\n    {\n        \"Name\": [\"Jim\", \"Lily\", \"Jack\"],\n        \"Statistics\": [85, 68, 90],\n        \"Accounting\": [82, 63, 88],\n        \"Marketing\": [84, 90, 78],\n    }\n)\nprint(df)\n\nNote\n\n‘D’ and ‘F’ are capitalized for the DataFrame method.\n\nAnother way to create DataFrame with argument columns:\n\nimport numpy as np\nimport pandas as pd\n\ndata = np.array([[\"Jim\", 85, 82, 84], [\"Lily\", 68, 63, 90], [\"Jack\", 90, 88, 78]])\ndf2 = pd.DataFrame(data, columns=[\"Name\", \"Statistics\", \"Accounting\", \"Marketing\"])\ndf2\n\nAnother way to create DataFrame with both argumens columns and index:\n\nimport numpy as np\nimport pandas as pd\n\ndata = np.array([[85, 82, 84], [68, 63, 90], [90, 88, 78]])\ncolumns=[\"Statistics\", \"Accounting\", \"Marketing\"]\nindex=[\"Jim\", \"Lily\", \"Jack\"]\ndf3 = pd.DataFrame(\n    data,\n    index=index,\n    columns=columns\n)\ndf3\n\nIn the above outputs, the first row are column lables while the first column are row indices. We can visit them by columns and index, respectively.\n\ndf.columns\n\ndf.index\n\nOne column or row data of a DataFrame is called a Series.\n\ntype(df['Statistics'])\n\nGet the number of rows and columns in a DataFrame by shape.\n\ndf.shape\n\nGet the number of cells in a DataFrame by size.\n\ndf.size\n\nGet the data types of each column by dtypes\n\ndf.dtypes\n\nPandas also supports converting one-dimensional or two-dimensional arrays/lists directly into DataFrame format.\n\na = [1, 2, 3]\npd.DataFrame(a)\n\na = [[1, 2, 3], [4, 5, 6]]\npd.DataFrame(a)\n\n","type":"content","url":"/introduction-to-pandas#creating-data","position":5},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Reading Data","lvl2":"Creating, Reading, and Storing Data"},"type":"lvl3","url":"/introduction-to-pandas#reading-data","position":6},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Reading Data","lvl2":"Creating, Reading, and Storing Data"},"content":"\n\nIn most cases, we need to read data files (such as Excel files). Suppose the example above is saved in an Excel file named ‘transcripts.xlsx’ located in the “datas/” directory on your computer. We can read the file using the read_excel method:\n\nimport pandas as pd\n\ndf = pd.read_excel(\"datas/transcripts.xlsx\")\n# or df = pd.read_excel(\"datas\\\\transcripts.xlsx\")\n# or df = pd.read_excel(r\"datas\\transcripts.xlsx\")\n\nNote\n\nFile paths on macOS use the forward slash / as a separator, while Windows uses the backslash \\.\n\nAdding an r before a file path string (e.g., r\"path\") preserves the original meaning of the string and prevents special characters from being escaped.\n\nThe syntax for read_excelis:\n\nread_excel(io, sheetname=0, header=0, skiprows=None, index_col=None, encoding=None)\n\nio\n\nThe file path and name of the data file, usually provided as a string.\n\nsheetname\n\nThe name or index of the worksheet. Defaults to 0, which reads the first sheet.\n\nheader\n\nThe row to use as column names. Defaults to 0, meaning the first row is used as headers.\n\nskiprows\n\nNumber of rows to skip from the top of the file.\n\nindex_col\n\nColumn to use as the row labels of the DataFrame.\n\nencoding\n\nEncoding format, commonly 'gbk' or 'utf-8'.\n\nNote\n\nWhen reading certain data files, you may need to add the decoding argument encoding='gbk' or encoding='utf-8' for proper reading.\n\nAnother common data file format is CSV (CSV is short for comma separated values). We can simply use Pandas’ read_csv method, whose syntax is essentially the same as read_excel.\n\nThe read_csv method can also read .txt files, typically by specifying the separator using the sep or delimiter parameter, whose default value is ','.\n\n","type":"content","url":"/introduction-to-pandas#reading-data","position":7},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Store the data","lvl2":"Creating, Reading, and Storing Data"},"type":"lvl3","url":"/introduction-to-pandas#store-the-data","position":8},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Store the data","lvl2":"Creating, Reading, and Storing Data"},"content":"\n\nTo save data, use the to_excel or to_csv method. For example, to save our DataFrame df to the “datas/” folder with the filename “marks.xlsx”:\n\ndf.to_excel(\"datas/marks.xlsx\")\n\nThe folder must first exists in the computer before using to_excel or to_csv.\n\nBy default, the row indeices are not written to the file. If you want to include the index in the saved file, you can set index=True (the default is index=False).\n\n","type":"content","url":"/introduction-to-pandas#store-the-data","position":9},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Access and change data"},"type":"lvl2","url":"/introduction-to-pandas#access-and-change-data","position":10},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Access and change data"},"content":"\n\nTo quickly view the statistical summary of each column in a DataFrame, you can use the describe() method. It includes information such as the number of non-null values, mean, standard deviation, minimum, maximum, and quartiles for each column.\n\ndf.describe()\n\nAdditionally, there are several useful method:\n\nmethod\n\nDescription\n\ninfo()\n\nView the data type of each column\n\nhead(n=5)\n\nView the first n (default is 5) rows of the data\n\ntail(n=5)\n\nView the last n (default is 5)rows of the data\n\ndf.head(2) # view the first 2 rows\n\n","type":"content","url":"/introduction-to-pandas#access-and-change-data","position":11},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Access the data of a single row, column or cell","lvl2":"Access and change data"},"type":"lvl3","url":"/introduction-to-pandas#access-the-data-of-a-single-row-column-or-cell","position":12},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Access the data of a single row, column or cell","lvl2":"Access and change data"},"content":"\n\nThe simplest way to view a specific column of data is by entering the column name within square brackets [ ]. For example, to view the ‘Marketing’ scores column:\n\ndf['Marketing']\n\nTo view a particular row of data, use the loc[ ] method with the row index.\n\ndf.loc[0]  # show the data of the first row\n\ndf.loc[2]  # show the data of the 3rd row\n\nTo view a specific cell, a convenient method is to use double square brackets [ ][ ], with the column label and row index inside each bracket respectively; Another way is to put the row index and column label insider loc[ ].\n\ndf[\"Marketing\"][1]\n\ndf.loc[1, \"Marketing\"]\n\n","type":"content","url":"/introduction-to-pandas#access-the-data-of-a-single-row-column-or-cell","position":13},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Acess multi-row or multi-column data","lvl2":"Access and change data"},"type":"lvl3","url":"/introduction-to-pandas#acess-multi-row-or-multi-column-data","position":14},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Acess multi-row or multi-column data","lvl2":"Access and change data"},"content":"\n\nTo view multiple rows and columns of data, you can use iloc[ ], which not only allows accessing multiple rows and columns but also supports retrieving single rows, single columns, or even individual cell data.。\n\ndf.iloc[1] # view the data in the 2nd row\n\ndf.iloc[0:2] # view the data of the first 2 rows\n\ndf.iloc[[0, 2]]  # view the data of the 1st and the 3rd rows\n\nView the column data with [:, ].\n\ndf.iloc[:, 1]  # view the data of the 2nd column\n\ndf.iloc[:, 0:2]  # view the data of the first 2 columns\n\ndf.iloc[:, [0, 2]]  # view the data of the 1st and 3rd columns\n\nView the data in a block.\n\ndf.iloc[0:2, 0:2] # view the data in the first 2 rows and the first 2 columns\n\ndf.iloc[[0, 2], [0, 2]]  # view the data in row 1 and 3, column 1 and 3\n\ndf.iloc[[0, 2], 0:2]  # view the data in row 1 and 3, column 1 and 2\n\nView the data in some cell.\n\ndf.iloc[1, 1]  # view the data in the cell of row 1 and column 1\n\nTo view specific columns of data, in addition to using iloc, you can directly pass a list of column labels inside square brackets [ ].\n\ndf[[\"Statistics\", \"Marketing\"]]\n\nIt is same as the following:\n\ndf.iloc[:, [1, 3]]\n\n","type":"content","url":"/introduction-to-pandas#acess-multi-row-or-multi-column-data","position":15},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"View the statistical values of the data","lvl2":"Access and change data"},"type":"lvl3","url":"/introduction-to-pandas#view-the-statistical-values-of-the-data","position":16},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"View the statistical values of the data","lvl2":"Access and change data"},"content":"\n\nPandas provides built-in statistical method to calculate summary statistics for column data. These method include: mean() (average), max() (maximum), min() (minimum), median(), std() (standard deviation), count(), skew() (skewness), quantile(), and more. In some cases, you may need to specify the argument numeric_only=True to ensure the method is only applied to numeric columns.\n\nSometimes we may need to cast the data types to numeric before using those methods.\n\ndf[\"Statistics\"].mean()\n\n# to calculate the average score for each course\n# since the first column ('names') is non-numeric, the argument numeric_only=True is added.`\ndf.mean(numeric_only=True)  \n\ndf[\"Accounting\"].max()\n\nUsing ‘axis=1’ to apply the function to rows\n\ndf.mean(numeric_only=True, axis=1)  # computer the average score of each student\n\n","type":"content","url":"/introduction-to-pandas#view-the-statistical-values-of-the-data","position":17},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Revise data","lvl2":"Access and change data"},"type":"lvl3","url":"/introduction-to-pandas#revise-data","position":18},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Revise data","lvl2":"Access and change data"},"content":"\n\nWhen modifying data in a pandas DataFrame, you can assign new values based on pandas index positions: either assigning a column/row to a single value or to a list with equal length, using [ ] and .iloc[], respectively.\n\ndf[\"Accounting\"] = 80  # revise all the accounting scores to 80\ndf\n\ndf[\"Accounting\"] = [64, 76, 88]  # revise the accounting scores to be the list values\ndf\n\ndf.iloc[1] = 80  # revise all the values in row 2 to 80\ndf\n\ndf.iloc[1] = [\"Ella\", 95, 90, 89]  # revise all the values in row 2 to the list values\ndf\n\nRevise the value in some cell:\n\ndf.iloc[1, 1] = 55  \ndf\n\nTo change the data type of column, using method astype().\n\ndf['Marketing'].astype(float)\n\n","type":"content","url":"/introduction-to-pandas#revise-data","position":19},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Data cleaning"},"type":"lvl2","url":"/introduction-to-pandas#data-cleaning","position":20},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Data cleaning"},"content":"","type":"content","url":"/introduction-to-pandas#data-cleaning","position":21},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Data replacement replace, fillna","lvl2":"Data cleaning"},"type":"lvl3","url":"/introduction-to-pandas#data-replacement-replace-fillna","position":22},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Data replacement replace, fillna","lvl2":"Data cleaning"},"content":"\n\nWhen processing data, it is often necessary to perform batch operations on outliers or erroneous values in the raw data. Pandas provides the replace method to facilitate this task conveniently. The first argument of the replace method is the original value in the data, and the second argument is the value to be replaced.\n\nFor example, consider the following student grades:\n\nimport pandas as pd\n\ndf = pd.DataFrame(\n    [[55, 68, 70], [52, 63, 68], [74, 60, 58]],\n    columns=[\"Statistics\", \"Python\", \"Finance\"],\n    index=[\"Jack\", \"Lily\", \"Tom\"],\n)\ndf\n\nReplace the score 68 with 65:\n\ndf.replace(68, 65)\ndf\n\nThe original data does not change. To change the original data, we need addtional argument inplace=True.\n\nThe methods fillna, drop_duplicates,dropna,rename can also add the argumentinplace=True to change the original data.\n\ndf.replace(68, 65, inplace=True)\ndf  \n\nPandas provides the fillna method to batch replace missing values (NaN) in a data table.\n\nWhen reading some data files by Pandas, some blank cells will be treated as Numpy’s NaN (Not a Number) type.\n\nimport numpy as np\n\ndf = pd.DataFrame(\n    np.array([[55, 68, 70], [52,  np.nan, 68], [74, 60, np.nan]]),\n    columns=[\"Statistics\", \"Python\", \"Finance\"],\n    index=[\"Jack\", \"Lily\", \"Tom\"],\n)\ndf\n\ndf.fillna(80)  # replace NaN with 80\n\nPandas can sue the method isnullto evaluate whether the cell value is null：\n\ndf[\"Finance\"].isnull()\n\n","type":"content","url":"/introduction-to-pandas#data-replacement-replace-fillna","position":23},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Cast the data type astype","lvl2":"Data cleaning"},"type":"lvl3","url":"/introduction-to-pandas#cast-the-data-type-astype","position":24},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Cast the data type astype","lvl2":"Data cleaning"},"content":"\n\nFrquently, we need to perform data transformations on raw data. For example, if some numerical values in the original data are stored as text, we must convert them into numeric types before performing subsequent calculations. A commonly used method for data type conversion is astype.\n\nimport pandas as pd\n\ndf = pd.DataFrame(\n    [[\"55\", \"68\", \"70\"], [\"52\", \"63\", \"68\"], [\"74\", \"60\", \"58\"]],\n    columns=[\"Statistics\", \"Python\", \"Finance\"],\n    index=[\"Jack\", \"Lily\", \"Tom\"],\n)\ndf\n\nCheck the data types of each column by the method dtypes.\n\nprint(df.dtypes)\n\nWe use astype cast the data type of each folumn to type float.\n\ndf[[\"Statistics\", \"Python\", \"Finance\"]] = df[[\"Statistics\", \"Python\", \"Finance\"]].astype(float)\ndf\n\nprint(df.dtypes)\n\nWe can also change the data type to string or integer by modifying the argument of astype to str or int.\n\n","type":"content","url":"/introduction-to-pandas#cast-the-data-type-astype","position":25},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Remove duplicates drop_duplicates","lvl2":"Data cleaning"},"type":"lvl3","url":"/introduction-to-pandas#remove-duplicates-drop-duplicates","position":26},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Remove duplicates drop_duplicates","lvl2":"Data cleaning"},"content":"\n\nWhen dealing with large datasets, duplicate data is a common issue. The drop_duplicates method can be used to remove redundant entries. For example:\n\nimport numpy as np\nimport pandas as pd\n\ndata = np.array([[\"Jim\", 85, 82, 84], [\"Jim\", 85, 82, 84], [\"Lily\", 68, 63, 90], [\"Jack\", 90, 88, 78]])\ndf = pd.DataFrame(data, columns=[\"Name\", \"Statistics\", \"Accounting\", \"Marketing\"])\ndf\n\nWe use drop_duplicates to drop the identical rows.\n\ndf.drop_duplicates()\n\nThe syntax of drop_duplicates is as follows:\n\nSyntax of the drop_duplicates function:\n\nDataFrame.drop_duplicates(keep='first', inplace=False, ignore_index=False)\n\nkeep\n\n'first': Keep first occurrence, remove subsequent duplicates (default)\n\n'last': Keep last occurrence, remove previous duplicates\n\nFalse: Remove all duplicates\n\ninplace\n\nIf True, modifies the DataFrame in place without returning a new object\n\nignore_index\n\nIf True, the resulting DataFrame's index will be relabeled (default False)\n\n","type":"content","url":"/introduction-to-pandas#remove-duplicates-drop-duplicates","position":27},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Remove missing valuesdropna","lvl2":"Data cleaning"},"type":"lvl3","url":"/introduction-to-pandas#remove-missing-valuesdropna","position":28},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Remove missing valuesdropna","lvl2":"Data cleaning"},"content":"\n\ndropna can drop the missing values in a Dataframe. Its syntax is as follows:\n\nDataFrame.dropna(axis=0, how='any', thresh=None, inplace=False, ignore_index=False)\n\naxis\n\naxis=0 drops rows containing missing values, axis=1 drops columns containing missing values\n\nhow\n\nDefault how='any': drops row/column if any values are missing\n\nhow='all': drops row/column only if all values are missing\n\nthresh\n\nMinimum number of non-missing values required to keep the row/column\n\ninplace\n\nIf True, modifies the DataFrame in place without returning a new object\n\nignore_index\n\nIf True, the resulting DataFrame's index will be reset (default False)\n\nimport numpy as np\n\ndf = pd.DataFrame(\n    np.array([[55, 68, 70], [52,  np.nan, 68], [74, 60, np.nan]]),\n    columns=[\"Statistics\", \"Python\", \"Finance\"],\n    index=[\"Jack\", \"Lily\", \"Tom\"],\n)\ndf\n\ndf.dropna()  # drop all the rows with NaN\n\ndf.dropna(axis=1)  # drop all the columns with NaN\n\ndf.dropna(how=\"all\")\n\n","type":"content","url":"/introduction-to-pandas#remove-missing-valuesdropna","position":29},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Rename rename","lvl2":"Data cleaning"},"type":"lvl3","url":"/introduction-to-pandas#rename-rename","position":30},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Rename rename","lvl2":"Data cleaning"},"content":"\n\nWhen working with data, we may sometimes need to rename the row or column labels. This is where the rename function comes into play. The rename function takes a dictionary as its argument, where:\n\nThe dictionary keys represent the current names (to be replaced).\n\nThe dictionary values represent the new names.\n\nUse the argument columns or index to specify changing the names of columns or rows\n\nimport numpy as np\nimport pandas as pd\n\ndata = np.array([[\"Jim\", 85, 82, 84], [\"Lily\", 68, 63, 90], [\"Jack\", 90, 88, 78]])\ndf = pd.DataFrame(data, columns=[\"Name\", \"Statistics\", \"Accounting\", \"Marketing\"])\ndf\n\ndf.rename(columns={\"Statistics\": \"Python\", \"Accouting\": \"Finance\"})  # rename two column labels\n\nUse the argument inplace=True if wanting to change the original data.\n\n","type":"content","url":"/introduction-to-pandas#rename-rename","position":31},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Add, delete and merge data"},"type":"lvl2","url":"/introduction-to-pandas#add-delete-and-merge-data","position":32},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Add, delete and merge data"},"content":"\n\n","type":"content","url":"/introduction-to-pandas#add-delete-and-merge-data","position":33},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Add data","lvl2":"Add, delete and merge data"},"type":"lvl3","url":"/introduction-to-pandas#add-data","position":34},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Add data","lvl2":"Add, delete and merge data"},"content":"\n\nTo add a new column at the end of the original data, the syntax is similar to revising the data, using [ ] and .loc[ ] for adding columns or rows:\n\ndf[\"Python Programming\"] = 60 # add one column of data in which all the values equal a single value\ndf\n\ndf[\"Financing\"] = [60, 50, 70] # add one column of data in which the values equal to a list\ndf\n\nTo add a new row at the end of the original data, using .loc[ ].\n\nnot .iloc[ ], which can’t enlarge the DataFrame.\n\ndf.loc[3,:] = [\"David\", 65, 70, 69, 55, 83] \ndf\n\nIf inserting a column to specific index, using the method insert.\n\ndf.insert(1, \"Economy\", [61, 72, 84, 81])  # insert a new column at column index 1\ndf\n\nTo insert rows at a specific position, Pandas currently does not have a dedicated method for this operation. The common approach is to use the concat() method to combine multiple DataFrames. Additionally, both concat() and merge() can be used to add multiple columns or rows. For detailed usage, please refer to the “Merge Data” section later in this documentation.\n\n","type":"content","url":"/introduction-to-pandas#add-data","position":35},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Delete data","lvl2":"Add, delete and merge data"},"type":"lvl3","url":"/introduction-to-pandas#delete-data","position":36},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Delete data","lvl2":"Add, delete and merge data"},"content":"\n\nPandas can use the drop() method to remove rows or columns. To delete a row, specify the row index as the argument along with inplace=True. If the argumentinplace=True is omitted, the original DataFrame remains unchanged.\n\ndf.drop(3, inplace=True)  # delete the 3rd row\ndf\n\nTo delete a column, using drop()  with an additional argument axis = 1**\n\ndf.drop(\"Python Programming\", inplace=True, axis=1)\ndf\n\nTo delete multi rows or columns, using drop() with the indices or lables in a list.\n\ndf.drop([\"Marketing\", \"Financing\"], inplace=True, axis=1)  # delete two columns\ndf\n\ndf.drop([0, 2], inplace=True) # delete two rows\ndf\n\ndrop() method can drop data with conditions. For example:\n\ndf = pd.DataFrame(\n    {\n        \"Name\": [\"Jim\", \"Lily\", \"Jack\"],\n        \"Statistics\": [85, 68, 90],\n        \"Accounting\": [82, 63, 88],\n        \"Marketing\": [84, 90, 78],\n    }\n)\n\ndf.drop(df[df[\"Statistics\"]<70].index, inplace=True) # delete the rows in which the statistics score is higher than 70\ndf\n\nUsing reset_index(drop=True) to reset the row indices and drop the original indices\n\ndf.reset_index(drop=True)\n\n","type":"content","url":"/introduction-to-pandas#delete-data","position":37},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Merge data","lvl2":"Add, delete and merge data"},"type":"lvl3","url":"/introduction-to-pandas#merge-data","position":38},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Merge data","lvl2":"Add, delete and merge data"},"content":"\n\nIn Pandas, two commonly used method for combining datasets are concat and merge.\n\nUse concat when the two DataFrames have identical column labels.\n\nIn other cases, merge is typically preferred.\n\ndf1 = pd.DataFrame(\n    {\n        \"Name\": [\"Jim\", \"Lily\", \"Jack\"],\n        \"Statistics\": [85, 68, 90],\n        \"Accounting\": [82, 63, 88],\n        \"Marketing\": [84, 90, 78],\n    }\n)\n\ndf1\n\ndf2 = pd.DataFrame(\n    {\"Name\": [\"David\", \"Ella\"], \"Statistics\": [83, 59], \"Accounting\": [62, 70], \"Marketing\": [64, 78]}\n)\ndf2\n\nSince the two DataFrames have same column lables, using concat([ ])and put the two DataFrames in a list to merge.\n\npd.concat([df1, df2])  #  there are square brackets [ ]\n\nTo rename the indexes after merging, you can add the argument ignore_index=True, which will reassign sequential numeric indexes starting from 0 to the merged data.\n\npd.concat([df1, df2], ignore_index=True)\n\nconcat 默认按行合并，若按列合并，可以在小括号内添加参数axis=1\n\n假如有下面的数据：\n\ndf3 = pd.DataFrame(\n    {\n        \"Name\": [\"Jim\", \"Lily\", \"Jack\"],\n        \"Python\": [65, 68, 60],\n        \"Business Modelling\": [72, 63, 78],\n    }\n)\n\ndf3\n\ndf1\n\nWhen df1 and df3 share the same ‘Name’ column but have different other column names, and we want to add df3’s columns to df1, we should use the merge() method. The typical syntax is as follows:\n\nDataFrame.merge(right, how='inner', on=None)\n\nright\n\nThe other DataFrame to merge;\n\nhow\n\nDefault 'inner': performs inner join, merging only matching keys from both DataFrames\n\n'outer': performs full outer join, merging all keys from both DataFrames\n\n'left': performs left join, preserving all keys from the left DataFrame\n\n'right': performs right join, preserving all keys from the right DataFrame\n\non\n\nColumn labels to join on (single or multiple)\n\nSo, for df1 and df3, when using merge, the matching key is ‘Name’:\n\ndf1.merge(df3, on=\"Name\")\n\nWhen merging DataFrames, Pandas will automatically fill missing values with NaN for non-matching fields. The following example demonstrates the results of different join method:\n\ndf1\n\ndf4 = pd.DataFrame(\n    {\n        \"Name\": [\"Jim\", \"Lily\", \"Robert\"],\n        \"Python\": [65, 78, 60],\n        \"Business Modelling\": [72, 73, 68],\n    }\n)\n\ndf4\n\ndf1.merge(df4, on=\"Name\")\n\ndf1.merge(df4, on=\"Name\", how=\"outer\") \n\ndf1.merge(df4, on=\"Name\", how=\"left\")\n\ndf1.merge(df4, on=\"Name\", how=\"right\")\n\n","type":"content","url":"/introduction-to-pandas#merge-data","position":39},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Filter, sort and group the data"},"type":"lvl2","url":"/introduction-to-pandas#filter-sort-and-group-the-data","position":40},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Filter, sort and group the data"},"content":"","type":"content","url":"/introduction-to-pandas#filter-sort-and-group-the-data","position":41},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Filter data","lvl2":"Filter, sort and group the data"},"type":"lvl3","url":"/introduction-to-pandas#filter-data","position":42},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Filter data","lvl2":"Filter, sort and group the data"},"content":"\n\nWhen querying DataFrame data based on certain conditions, some comparison operators are commonly used, such as: >, >=, ==, <, <=, !=. Conditional queries are generally applied only to column data. During the query process, Pandas first generates a Boolean index (True or False) and then produces the queried data by specifying this index.\n\nimport pandas as pd\n\ndf = pd.DataFrame(\n    {\n        \"Name\": [\"Jim\", \"Lily\", \"Jack\"],\n        \"Statistics\": [85, 68, 90],\n        \"Accounting\": [82, 63, 88],\n        \"Marketing\": [84, 90, 78],\n    }\n)\n\ndf\n\ndf[\"Statistics\"] > 70  #  get the boolean index\n\ndf[df[\"Statistics\"] > 70]  # get the conditional data\n\nFor multi-condition queries, you can use & to represent AND (both conditions must be satisfied) and | to represent OR (either condition can be satisfied). And, each condition is in the paratheses ( ).\n\ndf[(df[\"Statistics\"] > 70) & (df[\"Marketing\"] > 80)]  # get the data where statistics score is greater than 70, and marketing score is greater than 80\n\ndf[(df[\"Statistics\"] > 70) | (df[\"Marketing\"] > 80)] \n\nWe can get the unique values of a column using the method unique().\n\nimport pandas as pd\n\ndf = pd.DataFrame(\n    {\n        \"Name\": [\"Jim\", \"Lily\", \"Jack\"],\n        \"Statistics\": [82, 68, 82],\n        \"Accounting\": [72, 63, 72],\n        \"Marketing\": [84, 90, 78],\n    }\n)\n\ndf\n\ndf['Accounting'].unique()\n\n","type":"content","url":"/introduction-to-pandas#filter-data","position":43},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Sort data","lvl2":"Filter, sort and group the data"},"type":"lvl3","url":"/introduction-to-pandas#sort-data","position":44},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Sort data","lvl2":"Filter, sort and group the data"},"content":"\n\nWhen working with data, sorting is often necessary. Pandas provides a convenient method called sort_values for sorting numerical data. Its syntax is as follows:\n\nDataFrame.sort_values(by, axis=0, ascending=True, inplace=False, na_position='last', ignore_index=False)\n\nby\n\nColumn labels to sort by (axis=0) or row indices (axis=1); multiple values allowed\n\naxis\n\n0 for column-wise sorting, 1 for row-wise sorting (default: 0)\n\nascending\n\nSort order: True for ascending, False for descending (default: True)\n\ninplace\n\nWhether to modify the DataFrame in place (default: False)\n\nna_position\n\nPosition for missing values: 'first' or 'last' (default: 'last')\n\nignore_index\n\nIf True, the resulting axis will be labeled 0, 1, ..., n-1 (default: False)\n\nSort the scores of Statistics in ascending order.\n\ndf.sort_values(by=\"Statistics\")\n\nSory the scores of both Statistics and Marketing in descending order.\n\ndf.sort_values(by=[\"Statistics\", \"Marketing\"], ascending=False)\n\nFor the argument by, with “Statistics” preceding “Advanced Mathematics”, it means: first sort by Statistics scores in descending order, and for entries with identical Statistics scores, then sort by Advanced Mathematics scores in descending order.\n\nSince column labels often get shuffled during sorting:\n\nUse ignore_index = True to reset the index labels sequentially.\n\nUse inplace = True to modify the original DataFrame directly.\n\ndf.sort_values(by=\"Marketing\", ignore_index=True)  # reset the index\n\ndf.sort_values(by=\"Marketing\", ignore_index=True)  \ndf # the original data keeps same\n\ndf.sort_values(by=\"Marketing\", ignore_index=True, inplace=True) \ndf # the original data is changed after adding `inplace=True`\n\n","type":"content","url":"/introduction-to-pandas#sort-data","position":45},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Group the data groupby","lvl2":"Filter, sort and group the data"},"type":"lvl3","url":"/introduction-to-pandas#group-the-data-groupby","position":46},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Group the data groupby","lvl2":"Filter, sort and group the data"},"content":"\n\nIn data analysis, it’s often necessary to group and aggregate data. For example, when analyzing students’ final exam scores, you might need to calculate average scores, highest scores, etc. by major or class. Pandas’ groupby() method conveniently implements these operations.\n\nThe groupby operation is frequently combined with aggregation method such as:\n\nmean (average)\n\nmax (maximum value)\n\nmin (minimum value)\n\nmedian (median)\n\nstd (standard deviation)\n\nmad (mean absolute deviation)\n\ncount (number of non-null values)\n\nsize (total count, including nulls)\n\nskew (skewness)\n\nquantile (quantile values)\n\nBelow is a DataFrame about transcript.\n\ndf = pd.DataFrame(\n    [\n        [\"Lily\", \"US\", \"5\", 85, 68, 90],\n        [\"Tom\", \"UK\", \"6\", 82, 63, 88],\n        [\"Jack\", \"India\", \"6\", 84, 90, 78],\n        [\"David\", \"UK\", \"6\", 75, 68, 80],\n        [\"Ella\", \"India\", \"5\", 69, 55, 63],\n        [\"Julie\", \"China\", \"5\", 89, 95, 93],\n    ],\n    columns=[\"Name\", \"Nation\", \"Level\", \"Statistics\", \"Accounting\", \"Finance\"],\n)\ndf\n\ndf.groupby(\"Level\").count() # group by 'Level'\n\ndf.groupby(\"Level\").size() \n\nUse numeric_only = True to operate only on the numeric values\n\ndf.groupby(\"Level\").mean(\n    numeric_only=True\n)  # Get the mean scores for each module by \"Level\"\n\ndf.groupby([\"Nation\", \"Level\"]).mean(numeric_only=True) \n\nWe can assign the data after grouping to a new DataFrame.\n\ndf2 = df.groupby([\"Nation\", \"Level\"]).mean(numeric_only=True) \ndf2\n\ndf2.index\n\n","type":"content","url":"/introduction-to-pandas#group-the-data-groupby","position":47},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Method reset_index() or argument as_index=False","lvl2":"Filter, sort and group the data"},"type":"lvl3","url":"/introduction-to-pandas#method-reset-index-or-argument-as-index-false","position":48},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Method reset_index() or argument as_index=False","lvl2":"Filter, sort and group the data"},"content":"\n\nThe indices of a DataFrame often change after Pandas processing, as have mentioned before, we have two ways to stop the changes.\n\nUse a method reset_index().\n\nUse an argument as_index=False inside some method.\n\ndf2 = df.groupby([\"Nation\", \"Level\"]).mean(numeric_only=True).reset_index()\ndf2\n\ndf2 = df.groupby([\"Nation\", \"Level\"], as_index=False).mean(numeric_only=True)\ndf2\n\nSometimes, the reset_index() method can be used with the drop=True argument to remove the index.\n\nThe reset_index() method can also use the names argument to rename column headers.\n\ndf2 = (\n    df.groupby([\"Nation\", \"Level\"]).mean(numeric_only=True).reset_index(names=[\"Class\", \"Gender\"])\n) \ndf2\n\ndf2.columns\n\n","type":"content","url":"/introduction-to-pandas#method-reset-index-or-argument-as-index-false","position":49},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Output data to a NumPy array or a list"},"type":"lvl2","url":"/introduction-to-pandas#output-data-to-a-numpy-array-or-a-list","position":50},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Output data to a NumPy array or a list"},"content":"\n\nIn Pandas, the values method can convert DataFrame data into a NumPy array format. For example, using the previous data example:\n\ndf.values\n\ndf[[\"Statistics\", \"Accounting\"]].values\n\nYou can also use the tolist() method to convert a column of data into Python’s native list type.\n\ndf[\"Statistics\"].tolist()\n\n","type":"content","url":"/introduction-to-pandas#output-data-to-a-numpy-array-or-a-list","position":51},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Apply a function/method"},"type":"lvl2","url":"/introduction-to-pandas#apply-a-function-method","position":52},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Apply a function/method"},"content":"\n\nPandas can use the method apply to apply a function/method to the data.\n\nimport numpy as np\n\ndf[\"Statistics\"].apply(np.sqrt)  # apply the method sqrt in NumPy to compute the squre root of a colun\n\nWe can also self define a lambda fuction inside apply( ).\n\ndf[\"new Statistics\"] = df[\"Statistics\"].apply(lambda x: x - 10) # minus every score in \"Statistics\" by 10 to a new column\ndf \n\napply can also apply other more complex self defined function. For example, the following code transfers the numeric scores in other forms.\n\ndef replace_score(x):\n    if x >= 70:\n        return \"A\"\n    elif x >= 60:\n        return \"B\"\n    elif x >= 50:\n        return \"C\"\n    else:\n        return \"Failed\"\n\n\ndf[\"new Statistics\"] = df[\"new Statistics\"].apply(replace_score)\ndf\n\n","type":"content","url":"/introduction-to-pandas#apply-a-function-method","position":53},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Process time-series data"},"type":"lvl2","url":"/introduction-to-pandas#process-time-series-data","position":54},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Process time-series data"},"content":"","type":"content","url":"/introduction-to-pandas#process-time-series-data","position":55},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"to_datetime and dt.strftime","lvl2":"Process time-series data"},"type":"lvl3","url":"/introduction-to-pandas#to-datetime-and-dt-strftime","position":56},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"to_datetime and dt.strftime","lvl2":"Process time-series data"},"content":"\n\nIn practical work, we often encounter large amounts of time series data. The raw time series data is typically in text format, which needs to be converted into datetime format. Pandas provides the to_datetime method to convert other datetime formats into Python’s datetime format. For example:\n\nimport pandas as pd\n\npd.to_datetime(\"20200514\") # transfor the date text \"20200514\" to Timestamp format\n\npd.to_datetime(\"2020/05/14\")\n\npd.to_datetime(\"2020-05-14\")\n\nIn the code above, we can see that the to_datetime method converts different types of time-related string data into the Timestamp format: year-month-day hour:minute:second.\nAnother function, dt.strftime, can convert Pandas Timestamp data into strings of other formats. For example:\n\ndf = pd.DataFrame(\n    {\n        \"Enrollment date\": [\"2016-09-15\", \"2017-03-23\", \"2018-09-05\"],\n        \"Statistics\": [65, 58, 70],\n        \"Python\": [62, 63, 78],\n        \"Finance\": [64, 60, 78],\n    }\n)\ndf\n\ndf.iloc[0, 0]  # original date string\n\ndf[\"Enrollment date\"] = pd.to_datetime(df[\"Enrollment date\"])  # change original date to Python's Timestamp type\ndf\n\ndf.iloc[0, 0]\n\ndf[\"Enrollment date\"].dt.strftime(\"%m-%d-%y\")  # change the date to specific format\n\ndf[\"Enrollment date\"].dt.strftime(\"%m-%d-%Y\")  \n\ndf[\"Enrollment date\"].dt.strftime(\"%D\")  \n\ndf[\"Enrollment date\"].dt.strftime(\"%Y-%W\")  \n\ndf[\"Enrollment date\"].dt.strftime(\"%Y-%m-%w\") \n\n","type":"content","url":"/introduction-to-pandas#to-datetime-and-dt-strftime","position":57},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Data aggregation resample* ","lvl2":"Process time-series data"},"type":"lvl3","url":"/introduction-to-pandas#data-aggregation-resample","position":58},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Data aggregation resample* ","lvl2":"Process time-series data"},"content":"\n\nFor many time-series datasets, it’s often necessary to aggregate data at specific periodic intervals. This can be achieved using Pandas’ resample method. To use this method, the DataFrame must have a datetime-like index.\n\n* means this section may not be delivered in class.\n\nOnly having a datetime-like column is not enough, the index of the DataFrame must be a datetime-like\n\nimport numpy as np\n\nindex = pd.date_range(\"12/24/2019\", periods=10, freq=\"D\")  # generate a date range\nindex\n\ndf = pd.DataFrame(np.arange(10), index=index)  # generate a DataFrame with data range as index\ndf\n\ndf.resample(\"ME\").sum()  # use resample to sum the data every month\n\ndf.resample(\"3D\").sum()  # use resample to sum the data every 3 days\n\ndf.resample(\"W\").sum()  # use resample to sum the data every week\n\nIn the resample method’s arguments, T represents minutes and H represents hours. Besides being used with the sum() method, it can also be combined with:\n\nasfreq() → Returns the value at the specified frequency (without aggregation).\n\nffill() → Forward fills missing values after resampling.\n\napply() → Applies a custom aggregation function.\n\n","type":"content","url":"/introduction-to-pandas#data-aggregation-resample","position":59},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Pandas draw picutres*"},"type":"lvl2","url":"/introduction-to-pandas#pandas-draw-picutres","position":60},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Pandas draw picutres*"},"content":"\n\nIn addition to visualization with Matplotlib and Seaborn, Pandas also provides its own plotting function plot(). The basic syntax is as follows:\n\nDataFrame.plot(x=None, y=None, kind='line', subplots=False, title=None)\n\nx\n\nColumn name for x-axis data\n\ny\n\nColumn name(s) for y-axis data\n\nkind\n\nPlot type (default: 'line'). Options: 'bar', 'barh', 'box', 'pie', 'scatter', 'hist', etc.\n\nsubplots\n\nWhether to generate separate subplots for each column (True/False)\n\ntitle\n\nTitle of the plot\n\nWe load a dataset ‘iris’ from seaborn.\n\nimport seaborn as sns\n\ndf = sns.load_dataset('iris')\ndf\n\ndf.plot()\n\nThe above picture shows that the plot method of Pandas draw a line chart for each numeric column.\n\ndf['sepal_length'].plot(kind=\"hist\", title=\"My picture\")  # draw a histogram chart for a column\n\ndf.plot(x=\"sepal_length\", y=\"sepal_width\", kind=\"scatter\")  # draw scatter chart with given axis\n\nPandas provides a comprehensive set of data processing methods with numerous argument configurations. Due to space limitations, this book does not elaborate on them in detail. When using Pandas for data processing, readers are encouraged to consult the \n\nofficial documentation for further reference.\n\n","type":"content","url":"/introduction-to-pandas#pandas-draw-picutres","position":61},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Exercises"},"type":"lvl2","url":"/introduction-to-pandas#exercises","position":62},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Exercises"},"content":"\n\nHow to creat a DataFrame ‘df’ for the following panel data?\n\nNation\n\nCapital\n\nUK\n\nLondon\n\nUS\n\nWashington DC\n\nChina\n\nBeijing\n\nSolution to \n\nExercise 1import pandas as pd\n\ndf = pd.DataFrame({'Nation': ['UK', 'US', 'China'], 'Capital': ['London', 'Washinton DC', 'Beijing']})\n\norimport pandas as pd\nimport numpy as pd\n\ndata = np.array([['UK', 'US', 'China'], ['London', 'Washinton DC', 'Beijing']])\ndf = pd.DataFrame(data, columns=['Nation', 'Capital'])\n\nHow to view the cell ‘London’ of the following DataFrame?df = pd.DataFrame({'Nation': ['UK', 'US', 'China'], 'Capital': ['London', 'Washinton DC', 'Beijing']})'?\n\nSolution to \n\nExercise 2df.iloc[0, 0]\n\nordf['Capital'][0]\n\nordf.loc[0, 'Capital']\n\nHow to read a CSV file into a Pandas DataFrame?\n\nA.    pd.load_csv()\n\nB.    pd.read_csv()\n\nC.    pd.open_csv()\n\nD.    pd.import_csv()\n\nSolution to \n\nExercise 3\n\nB\n\nWhat is the default index type when a DataFrame is created?\n\nA.    Numeric index starting from 1\n\nB.    Alphanumeric index based on row number\n\nC.    Numeric index starting from 0\n\nD.    Strings\n\nSolution to \n\nExercise 4\n\nC\n\nHow can you select a specific column ‘Score’ from a DataFrame ‘df’?\n\nA.    df(‘Score’)\n\nB.    df.select_column(‘Score’)\n\nC.    df.get_column(‘Score’)\n\nD.    df[‘Score’]\n\nSolution to \n\nExercise 5\n\nD\n\nWhat is the purpose of the head() method in Pandas?\n\nA.    To display the last few rows of a DataFrame\n\nB.    To display the first few rows of a DataFrame\n\nC.    To display summary statistics of a DataFrame\n\nD.    To display maximums of a DataFrame\n\nSolution to \n\nExercise 6\n\nB\n\nWhat does the shape attribute of a DataFrame represent??\n\nA.    Get the number of rows and columns\n\nB.    Get the number of cells\n\nC.    Get the data types of columns\n\nD.    Get the number of rows\n\nSolution to \n\nExercise 7\n\nA\n\nHow can you filter rows in a DataFrame ‘df’ based on a condition ‘condition’?\n\nA.    df.filter(condition)\n\nB.    df[condition]\n\nC.    df.filter_rows(condition)\n\nD.    df.select_rows(condition)\n\nSolution to \n\nExercise 8\n\nB\n\nHow to drop a column ‘name’ from a DataFrame ‘df’ in Pandas?\n\nA.    df.drop(‘name’, axis=1)\n\nB.    df.drop(‘name’)\n\nC.    df.remove(‘name’, axis=1)\n\nD.    df.remove(‘name’)\n\nSolution to \n\nExercise 9\n\nA\n\nWhat is the purpose of the describe() method in Pandas?\n\nA.    To describe the data types of columns\n\nB.    To provide information about missing values\n\nC.    To provide the size of the data\n\nD.    To display summary statistics of a DataFrame\n\nSolution to \n\nExercise 10\n\nD\n\nHow to merge two DataFrames based on a common column in Pandas?\n\nA.    df.join()\n\nB.    df.concate()\n\nC.    df.combine()\n\nD.    df.merge()\n\nSolution to \n\nExercise 11\n\nD\n\nWhat does the astype() method in Pandas do?\n\nA.    Converts a DataFrame to a NumPy array\n\nB.    Converts data types of columns in a DataFrame\n\nC.    Adds a new column to a DataFrame\n\nD.    Removes duplicate values from a DataFrame\n\nSolution to \n\nExercise 12\n\nB\n\nHow to apply a custom function to each element in a Pandas DataFrame ‘df’?\n\nA.    df.apply()\n\nB.    \n\ndf.map()\n\nC.    df.modify()\n\nD.    \n\ndf.call()\n\nSolution to \n\nExercise 13\n\nA\n\nHow to reset the index of a Pandas DataFrame ‘df’?\n\nA.    df.set_index()\n\nB.    df.reset_index()\n\nC.    df.index_set()\n\nD.    df.index_reset()\n\nSolution to \n\nExercise 14\n\nB\n\nHow to remove duplicate values in a Pandas DataFrame ‘df’?\n\nA.    df.delete_duplicate()\n\nB.    df.eliminate_duplicate()\n\nC.    df.remove_duplicate()\n\nD.    df.drop_duplicate()\n\nSolution to \n\nExercise 15\n\nD\n\nWhich of the following method can handle missing values in a Pandas DataFrame ‘df’?\n\nA.    df.fillna()\n\nB.    df.dropna()\n\nC.    Both A and B\n\nD.    Neither A and B\n\nSolution to \n\nExercise 16\n\nC\n\nHow to save a Pandas DataFrame ‘df’ to a CSV file ‘data.csv’?\n\nA.    df.save_csv(‘data.csv’)\n\nB.    df.to_csv(‘data.csv’)\n\nC.    df.csv(‘data.csv’)\n\nD.    df.export_csv(‘data.csv’)\n\nSolution to \n\nExercise 17\n\nB\n\nHow to output the first 10 rows of a DataFrame ‘df’?\n\nA.    \n\ndf.top(20)\n\nB.    df.tail(10)\n\nC.    df.head(10)\n\nD.    df.export(10)\n\nSolution to \n\nExercise 18\n\nC\n\nWhat argument to put insider the method ‘dropna()’ to make sure that the changes are done for the original DataFrame ‘df’?\n\nA.    dropna(inplace=True)\n\nB.    dropna(replace=True)\n\nC.    dropna(fill=True)\n\nD.    dropna(drop=True))\n\nSolution to \n\nExercise 19\n\nA\n\nWhich method for converting a column into Python’s date formats?\n\nA.    date()\n\nB.    datetime()\n\nC.    to_date()\n\nD.    to_datetime()\n\nSolution to \n\nExercise 20\n\nD\n\nFor the following panel data:\n\nStudent\n\nModule1\n\nModule2\n\nModule3\n\nStu1\n\n50\n\n45\n\n56\n\nStu2\n\n81\n\n76\n\n73\n\nStu3\n\n60\n\n65\n\n62\n\nStu4\n\n77\n\n58\n\n60\n\nStu5\n\n60\n\n59\n\n54\n\nStu6\n\n40\n\n55\n\n53\n\nStu7\n\n57\n\n65\n\n70\n\nUse Pandas to achieve the following:\n\nPut the above panel data to a Pandas DataFrame.\n\nDrop the student row who has modul score less than 50 (< 50).\n\nOutput the average score, maximum score of each module for the remnant students.\n\nRank the remnant students by the average score of all modules.\n\nOutput the final result to a csv file in the D drive named ‘output.csv’.\n\nSolution to \n\nExercise 21import pandas as pd\nimport numpy as np\n\ncolumns = ['Student', 'Module1', 'Module2', 'Module3']\ndata = np.array([['Stu1', 50, 45, 56], ['Stu2', 81, 76, 73], ['Stu3', 60, 65, 62],\\\n                 ['Stu4', 77, 58, 60], ['Stu5', 60, 59, 54], ['Stu6', 40, 55, 53],\\\n                 ['Stu7', 57, 65, 70]])\n\ndf = pd.DataFrame(data, columns=columns)\ndf[['Module1', 'Module2', 'Module3']] = df[['Module1', 'Module2', 'Module3']].astype(float) # question1\ndf = df[(df['Module1']>50) &(df['Module2']>50) & (df['Module3']>50)] # question2\ndf['Average score'] = df.mean(numeric_only=True, axis = 1)\ndf['Max score'] = df.max(numeric_only=True, axis = 1) # question3\ndf = df.sort_values(by='Average score', ascending=False) # question4\ndf.reset_index(inplace=True)\ndf.to_csv('D:/output.csv') # question5\n\n\n\n Toogle google translation \n\n\n\n","type":"content","url":"/introduction-to-pandas#exercises","position":63},{"hierarchy":{"lvl1":"Output, read and write files"},"type":"lvl1","url":"/print-read-files","position":0},{"hierarchy":{"lvl1":"Output, read and write files"},"content":"","type":"content","url":"/print-read-files","position":1},{"hierarchy":{"lvl1":"Output, read and write files","lvl2":"print function"},"type":"lvl2","url":"/print-read-files#print-function","position":2},{"hierarchy":{"lvl1":"Output, read and write files","lvl2":"print function"},"content":"\n\nIn Python, outputting content is very straightforward using the print() function. Inside the parentheses, you can pass various data types such as numbers, strings, lists, dictionaries, and more.\n\nprint([12, 45, 69])  # list\n\ndict = {\"name\": \"chen\", \"mark\": 85}\nprint(dict)  # dict\n\nYou can also output strings and variables together inside the print() function.\n\na = [1, 2, 3]\nb = 4\nprint(\"a =\", a, \", b =\", b)\n\nBy default, the print() function adds a newline character at the end of the output, moving the cursor to the next line.\n\na = \"zhang\"\nage = 25\nprint(\"my name is\",  a)  # the cursor is moving to the next line\nprint(\"age is\", age)\n\nTo modify the ending behavior of the print() function’s cursor, you can use the end argument, which defaults to a newline character \\n.\n\na = \"zhang\"\nage = 25\nprint(\"my name is %s\" % a, end=\"-\")\nprint(\"age is %d\" % age)\n\n","type":"content","url":"/print-read-files#print-function","position":3},{"hierarchy":{"lvl1":"Output, read and write files","lvl2":"Using f-string"},"type":"lvl2","url":"/print-read-files#using-f-string","position":4},{"hierarchy":{"lvl1":"Output, read and write files","lvl2":"Using f-string"},"content":"\n\nWe can use f-string for more flexible outputs of strings. The variable is in the curly braces { }.\n\na = [1, 2, 3]\nprint(f\"the array is {a}\")  # output a list variable\n\nb = 3.2\nprint(f\"the array is {a}, the numer is {b}\") # output several variables\n\nimport math\n\nb = 4.56\nprint(f\"the numbers are {math.pi} and {b}\")\n\nWe can use colons : to specify variable alignment, width, precision, and type in the f-string.\n\nThe format after the colons : is：\n\n: <fill> <alignment><width><.><presition><type>\n\nThe notations for alignment are：\n\nCode\n\nMeaning\n\n>\n\nAlign right (default)\n\n<\n\nAlign left\n\n^\n\nAlign center\n\nThe notations for varaible types are:\n\nCode\n\nMeaning\n\nExample (value=42.5)\n\nOutput\n\ns\n\nString format (default)\n\nf\"{'text':s}\"\n\n'text'\n\nd\n\nDecimal integer\n\nf\"{42:d}\"\n\n42\n\nf\n\nFixed-point float\n\nf\"{42.5:.2f}\"\n\n42.50\n\ne\n\nScientific notation\n\nf\"{42.5:.2e}\"\n\n4.25e+01\n\n%\n\nPercentage format\n\nf\"{0.425:.1%}\"\n\n42.5%\n\na = 1\nb = 4.56\n# The first number is a floating-point number rounded to 3 decimals\n# The second number is right-aligned with a width of 20, rounded to 2 decimals, and displayed as a percentage\nf\"the numbers are {a:.3f} and {b = :>20.2%}\"\n\na = 5.6\nprint(f\"{a = :+^10.2f}\")  # fill with +, align center, width is 10, rounded to 2 decimals\n\n","type":"content","url":"/print-read-files#using-f-string","position":5},{"hierarchy":{"lvl1":"Output, read and write files","lvl2":"Using format*"},"type":"lvl2","url":"/print-read-files#using-format","position":6},{"hierarchy":{"lvl1":"Output, read and write files","lvl2":"Using format*"},"content":"\n\n* means this section may not be delived in class.\n\nWe can also achieve different formats of output using format. The syntax is:\n\n\n\nstring with curly braces { }.format(value1, value2...)\n\nIn the string, { } is the location of the variable, and the values of the varaibles are in ( ).\n\na = 3\nb = 4.56\nprint(\"the numbers are {} and {:.3f}\".format(a, b))\n\nWe can add the location index of the variable inside the { }.\n\na = 3\nb = 4.56\nprint(\"the numbers are {1} and {0}\".format(a, b))  # specify the variable index indside {}\nprint(\"the numbers are {0} and {1}\".format(a, b))\nprint(\"the numbers are {0} and {1} and {0}\".format(a, b))\n\nTo output a curly brace, use double curly braces: {{, }}.\n\nprint(\"the numbers are {{ {0} }} and {{ {1} }}\".format(a, b))\n\nWhen using the format() method, you can achieve formatted output by including a colon : and additional arguments within the curly braces {}, similar to how f-strings work.\n\na = 3\nb = 4.56\nprint(\"the numbers are {0:10.2f} and {0:.3%}\".format(a, b))\n\na = 123456\nprint(\"the numer is {:e}\".format(a))\n\na = 5\nprint(\"a = {:0>5d}\".format(a))  # align left, fill with 0, width 5, type integer\n\na = 5.6\nprint(\"a = {:+^10.2f}\".format(a))  # align center, fill with +, width 10, round to 2 decimals\n\nAs f-string, the width and precision values can be passed as variables using curly braces {} with argument assignment, for example:\n\na = 5.6\nprint(\"a = {:^{width}.{precision}f}\".format(a, width=10, precision=3))  # width and precision as variables\n\na = 5.6\nwidth = 10\nprecision = 3\nprint(f\"a = {a:^{width}.{precision}f}\")  # width and precision as variables\n\n","type":"content","url":"/print-read-files#using-format","position":7},{"hierarchy":{"lvl1":"Output, read and write files","lvl2":"Using % for output*"},"type":"lvl2","url":"/print-read-files#using-for-output","position":8},{"hierarchy":{"lvl1":"Output, read and write files","lvl2":"Using % for output*"},"content":"\n\nThe percent sign % can also achieve various formatted outputs, with syntax rules similar to C language. Here are some specific examples for reference:\n\nimport math\n\nprint(\"the number is %d\" % math.pi)  # output a float to integer format\n\nprint(\"the number is %.2f\" % math.pi)  # output a float rouding to 2 decimals\n\nprint(\"the number is %.2f\\n\" % math.pi)  # \\n indicates a line break after print(), moving the cursor to the next line\n\nb = 4.56\nprint(\"the numbers are %.2f and %d\" % (math.pi, b))  # output multi variables\n\nprint(\"the number is %5.2f\" % math.pi)  # output a float rounding to 2 decimals with width 5\n\nprint(\"the number is %s\" % 321)  # output in a string format\n\nprint(\"%.1f%%\" % b)  # output in a percentage format\n\n","type":"content","url":"/print-read-files#using-for-output","position":9},{"hierarchy":{"lvl1":"Output, read and write files","lvl2":"Read and write files"},"type":"lvl2","url":"/print-read-files#read-and-write-files","position":10},{"hierarchy":{"lvl1":"Output, read and write files","lvl2":"Read and write files"},"content":"\n\nPython operates on text files following the steps: open → operate → close. It opens a file from the computer’s storage location, performs some read or write operations, and then closes the file. While the file is open, it is in a “locked” state, meaning other processes on the computer cannot access it. Once the file is closed, it becomes accessible to other processes.\n\nPython uses the function open() to open a file object and the syntax is:\n\nopen(filename, mode)\n\n\n\nfilename\n\nAn string with address and file name;\n\n\n\nthe default address is the current file folder\n\nmode\n\nRead/write mode and the default is read-only model (r)\n\nThe read/write modes include:\n\nMode\n\nDescription\n\nFile Pointer\n\nFile Existence\n\n'r'\n\nRead-only (default)\n\nStarts at beginning\n\nFile must exist\n\n'w'\n\nWrite (overwrites existing file)\n\nStarts at beginning\n\nCreates file if missing\n\n'a'\n\nAppend (adds to end of file)\n\nStarts at end\n\nCreates file if missing\n\n'r+'\n\nRead + Write\n\nStarts at beginning\n\nFile must exist\n\n'w+'\n\nWrite + Read (overwrites)\n\nStarts at beginning\n\nCreates file if missing\n\n'a+'\n\nAppend + Read\n\nStarts at end\n\nCreates file if missing\n\nComparisions between different modes:\n\nMode\n\nr\n\nr+\n\nw\n\nw+\n\na\n\na+\n\nRead\n\n✓\n\n✓\n\n\n\n✓\n\n\n\n✓\n\nWrite\n\n\n\n✓\n\n✓\n\n✓\n\n✓\n\n✓\n\nCreate\n\n\n\n\n\n✓\n\n✓\n\n✓\n\n✓\n\nOverwrite\n\n\n\n\n\n✓\n\n✓\n\n\n\n\n\nStart at begining\n\n✓\n\n✓\n\n✓\n\n✓\n\n\n\n\n\nStart at end\n\n\n\n\n\n\n\n\n\n✓\n\n✓\n\nFor example:\n\nf = open(\n    \"test.txt\", \"w\"\n)  # creat a file in the current folder; if creating the file under the E drive:  f = open('E:\\\\files\\\\test.txt', 'r')\nf.write(\"My name is Tim Cook\\nHis name is Elon Musk\")  # write the contents and use \\n for line break\nf.close()  # close the opened file\n\nThe above program creates a new .txt file in the current directory. It writes content to the file using the write() method, where \\n represents a newline.\n\nTo create or modify a file at a specific location, you can further include a file path string in the filename.\n\nThe following codes read all the contents from the file through the method read() and return a string.\n\nf = open(\"test.txt\", \"r\")\nstr = f.read()  # read the contents and return a string\nprint(str)  # print the string\nf.close()  # close the opened file\n\nTo read just one line, you can use the readline() method. Alternatively, you can use the readlines() method to read all lines, which returns a list where each element is a line from the file.\n\nIn practical Python file reading and writing, the with-open statement is often used. Since file operations may raise an IOError, if an error occurs, the f.close() statement may not be executed, leaving the file open in the background. Using the with-open statement allows you to omit the f.close() call safely.\n\nThe above reading and writing code can also be rewritten as:\n\n# write contents\nwith open(\"test.txt\", \"w\") as f:\n    f.write(\"My name is Tim Cook\\nHis name is Elon Musk\")\n\n# read contents\nwith open(\"test.txt\", \"r\") as f:\n    str = f.read()  \n    print(str)  \n\nTo read and write data format files such as .txt, .xls, .xlsx, and .csv, it is common to use the Pandas library to read files and process data. Readers can refer to the Pandas chapter in this book for more details.\n\nTo read and write Word format files, libraries such as textract and docx2txt can be used. This book does not go into further detail on this topic—interested readers can look up relevant information online.\n\n","type":"content","url":"/print-read-files#read-and-write-files","position":11},{"hierarchy":{"lvl1":"Output, read and write files","lvl2":"os, sys library*"},"type":"lvl2","url":"/print-read-files#os-sys-library","position":12},{"hierarchy":{"lvl1":"Output, read and write files","lvl2":"os, sys library*"},"content":"\n\n","type":"content","url":"/print-read-files#os-sys-library","position":13},{"hierarchy":{"lvl1":"Output, read and write files","lvl3":"os library","lvl2":"os, sys library*"},"type":"lvl3","url":"/print-read-files#os-library","position":14},{"hierarchy":{"lvl1":"Output, read and write files","lvl3":"os library","lvl2":"os, sys library*"},"content":"\n\nThe os in Python is a standard library for interacting with the operating system, providing functionalities for handling files, directories, processes, and environment variables.\n\nBelow are some usages of the os:\n\nimport os\n\nprint(os.name)  # get the name of the current computer system: 'posix' (Linux/macOS) or 'nt' (Windows)\nprint(os.getcwd())  # get current working directory\nprint(os.listdir())  # get a list of all the files under the current working directory\n\nChange working directory\n\nos.chdir('/path/to/directory')  # change current working directory to new address: '/path/to/directory'\n\nCreate or delete a directory\n\nimport os\n\nos.mkdir('new_dir')  # create a new directory\nos.makedirs('parent/child/grandchild')  # create hierarchy directories\nos.rmdir('new_dir')  # delete an empty\nos.removedirs('parent/child/grandchild') # remove hierarchy directories\n\nFile renaming rename or deletion remove\n\nimport os\n\nfile_path = \"new_file.txt\"  \nwith open(file_path, \"w\") as f:\n    f.write(\"Hello, this is a new file!\")\n\nos.rename('new_file.txt', 'new_file2.txt')  # rename the file\nos.remove('new_file2.txt')  # remove the file\n\nGet environment variable\n\nprint(os.environ)  # get all the environment variables\nprint(os.environ.get('specific'))  # get a specific environment variable 'specific'\nos.environ['NEW_VAR'] = 'Hello'  # set value for an enviroment variable\n\nPath operations\n\nimport os.path\n\nprint(os.path.abspath('file.txt'))  # get the absolute path of the file 'file.txt'\nprint(os.path.dirname('file.txt'))  # get the directory of the file 'file.txt'\nprint(os.path.join('dir', 'file.txt'))  # concatenate the path strings 'dir' with 'file.txt'\nprint(os.path.exists('file.txt'))  # check whether the path 'file.txt' exists\nprint(os.path.isfile('file.txt'))  # check whether the string 'file.txt' is a file or not\nprint(os.path.isdir('dir'))  # check whether the string 'dir' is a directory or not\nprint(os.path.splitext('file.txt'))  # split the pathname into a pair (root, ext), where root is the part of the path before the file extension and ext is the file extension.\nprint(os.path.basename('/path/to/file.txt'))  # get the file name from the string inside the ()\n\nThe following example gets the file name of the current file.\n\nimport os\n\n# __file__ can get the full path of the current file\ncurrent_file_path = __file__ \n\n# get the current file name\ncurrent_file_name = os.path.basename(current_file_path)\n\nProcess management\n\nimport os\n\nprint(os.getpid())  # get the id of the current process\nprint(os.getppid())  # get the id of the parent process\n\n","type":"content","url":"/print-read-files#os-library","position":15},{"hierarchy":{"lvl1":"Output, read and write files","lvl3":"sys library","lvl2":"os, sys library*"},"type":"lvl3","url":"/print-read-files#sys-library","position":16},{"hierarchy":{"lvl1":"Output, read and write files","lvl3":"sys library","lvl2":"os, sys library*"},"content":"\n\nThe sys  provides variables and functions that are related to the Python interpreter and its environment. It is useful for handling command-line arguments, runtime environment settings, and standard input and output operations.\n\nGet the version of current Python using sys.version\n\nimport sys\n\nprint(sys.version)\n\nGet the name of current computer system using sys.platform\n\nprint(sys.platform)  # get current computer system such as  'win32', 'linux', 'darwin'\n\nGet the seaching paths by sys.path\n\nprint(sys.path)  # get all the searching paths\nsys.path.append(\"/my/custom/path\")  # append a searching path\n\n","type":"content","url":"/print-read-files#sys-library","position":17},{"hierarchy":{"lvl1":"Output, read and write files","lvl2":"Exercises"},"type":"lvl2","url":"/print-read-files#exercises","position":18},{"hierarchy":{"lvl1":"Output, read and write files","lvl2":"Exercises"},"content":"\n\nWhich method is used to read the entire content of a file as a string?\n\nA.    read()\n\nB.    readline()\n\nC.    readlines()\n\nD.    read_file()\n\nSolution to \n\nExercise 1\n\nA\n\nWhat is the output of the following program:print ('{0:.2%}'.format(1.0 / 3))\n\nA.    0.33\n\nB.    33.33%\n\nC.    0.33%\n\nD.    33%\n\nSolution to \n\nExercise 2\n\nB\n\nThe default opening mode when opening a file with the open() function is ‘r’ for ‘reading’.\n\nA.    True\n\nB.    False\n\nSolution to \n\nExercise 3\n\nA\n\nWhat is the purpose of the ‘with’ statement in file handling?\n\nA.    create a new file\n\nB.    open a file\n\nC.    automatically close the file\n\nD.    save a file\n\nSolution to \n\nExercise 4\n\nC\n\nWhat happens to the original file content if you open a file like this:open('test.txt', 'w')\n\nA.    The original content will be overwritten\n\nB.    Any new content will be added after the original content\n\nSolution to \n\nExercise 5\n\nA\n\nWhat does the following code do?with open(\"file.txt\", \"a\") as file:\n   file.write(\"data\")\n\nA.    read the content  of ‘file.txt’\n\nB.    append “data” to “file.txt”\n\nC.    create a new file “file.txt”\n\nD.    replace the content of “file.txt” with “data”\n\nSolution to \n\nExercise 6\n\nC\n\nFormatted output of 0.0003278 in scientific notation, rouding to 4 decimal places as percentage\n\nSolution to \n\nExercise 7print(\"{:.4%}\".format(0.0003278))\n\nora = 0.0003278\nprint(f\"{a:.4%}\")\n\nWrite the following txts to a file ‘tesla.txt’, read it and output the contents.\n\nTesla, Inc. is an American multinational automotive and clean energy company. Headquartered in Austin, Texas, it designs, manufactures and sells battery electric vehicles (BEVs), stationary battery energy storage devices from home to grid-scale, solar panels and solar shingles, and related products and services.\n\nTesla was incorporated in July 2003 by Martin Eberhard and Marc Tarpenning as Tesla Motors. Its name is a tribute to inventor and electrical engineer Nikola Tesla. In 2008, the company began production of its first car model, the Roadster sports car, followed by the Model S sedan in 2012, the Model X SUV in 2015, the Model 3 sedan in 2017, the Model Y crossover in 2020, the Tesla Semi truck in 2022 and the Cybertruck pickup truck in 2023.\n\nSolution to \n\nExercise 8with open(\"tesla.txt\", \"w\") as f:\n    f.write(\n        \"\"\"Tesla, Inc. is an American multinational automotive and clean energy company. Headquartered in Austin, Texas, it designs, manufactures and sells battery electric vehicles (BEVs), stationary battery energy storage devices from home to grid-scale, solar panels and solar shingles, and related products and services.\n        \nTesla was incorporated in July 2003 by Martin Eberhard and Marc Tarpenning as Tesla Motors. Its name is a tribute to inventor and electrical engineer Nikola Tesla. In 2008, the company began production of its first car model, the Roadster sports car, followed by the Model S sedan in 2012, the Model X SUV in 2015, the Model 3 sedan in 2017, the Model Y crossover in 2020, the Tesla Semi truck in 2022 and the Cybertruck pickup truck in 2023.\"\"\"\n    )\n\nwith open(\"tesla.txt\", \"r\") as f:\n    str = f.read()\n    print(str)\n\n\n\n Toogle google translation \n\n","type":"content","url":"/print-read-files#exercises","position":19},{"hierarchy":{"lvl1":"Python statistics"},"type":"lvl1","url":"/statistics1","position":0},{"hierarchy":{"lvl1":"Python statistics"},"content":"\n\nIn this chapter, we explain how to perform statistical analysis on data using Python. Rather than delving into the theoretical and computational details of the statistical concepts and methods, we aim to provide intuitive, visual explanations that are easy to understand.\n\n","type":"content","url":"/statistics1","position":1},{"hierarchy":{"lvl1":"Python statistics","lvl2":"Mean, Variance"},"type":"lvl2","url":"/statistics1#mean-variance","position":2},{"hierarchy":{"lvl1":"Python statistics","lvl2":"Mean, Variance"},"content":"\n\nThe mean value is the average value of a number of numeric data. To calculate the mean, find the sum of all numeric values, and divide the sum by the number of values.\n\nVariance is the squared deviation of a variable from its mean.\n\nA large variance indicates that the data is spread out, while a small variance indicates that the data is clustered closely around the mean.\n\nWe use the dataset “tips” as an example from the Seaborn library.\n\nimport seaborn as sns\n\ntips = sns.load_dataset('tips')\ntips                       \n\nThe following codes draw a graph of the data in the column “tip”.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnum = tips.shape[0]\nplt.scatter(x=np.arange(num), y=tips[\"tip\"], label=\"tip\")\nplt.axhline(y=np.mean(tips['tip']), color='r', linestyle='--', label='mean') # axhline can draw a horizonal line parallel to the axis\nplt.legend()\nplt.show()\n\nTo compute the mean, we can use the method mean() from Numpy or Pandas.\n\nThe method numpy in Numpycan computer the average value of\n\nnp.mean(tips[\"tip\"])\n\nSince “tips” is a DataFrame type, we can directly use the methods of Pandas to it.\n\ntips[\"tip\"].mean()\n\nTo compute the variance, we can use the method var() from Numpy or Pandas.\n\nnp.var(tips[\"tip\"])\n\ntips[\"tip\"].var()\n\nThe square root of the variance is called standard deviation.\n\n","type":"content","url":"/statistics1#mean-variance","position":3},{"hierarchy":{"lvl1":"Python statistics","lvl2":"Distribution"},"type":"lvl2","url":"/statistics1#distribution","position":4},{"hierarchy":{"lvl1":"Python statistics","lvl2":"Distribution"},"content":"\n\nIn data analysis, the columns of a dataset represent random variables—quantities that fluctuate due to randomness. A probability distribution characterizes the likelihood of different values these variables may assume.\n\n","type":"content","url":"/statistics1#distribution","position":5},{"hierarchy":{"lvl1":"Python statistics","lvl3":"Uniform distribution","lvl2":"Distribution"},"type":"lvl3","url":"/statistics1#uniform-distribution","position":6},{"hierarchy":{"lvl1":"Python statistics","lvl3":"Uniform distribution","lvl2":"Distribution"},"content":"\n\nThe uniform distribution is a probability distribution where each value within a certain range is equally likely to occur and values outside of the range never occur.\n\nFor the visualization of the distribution of data, we can draw the histogram graph.\n\nimport numpy as np\nimport seaborn as sns\n\nsns.set_theme()\ndata = np.random.uniform(100, 200, 10000) # generate 10000 random datas uniformally distributed between 50 and 100\nsns.histplot(data=data) # use the histplot of seaborn to draw the histogram graph\n\nFor uniformly distributed data, the histogram typically displays bars of approximately equal height, resulting in a flat or level appearance.\n\n","type":"content","url":"/statistics1#uniform-distribution","position":7},{"hierarchy":{"lvl1":"Python statistics","lvl3":"Normal distribution","lvl2":"Distribution"},"type":"lvl3","url":"/statistics1#normal-distribution","position":8},{"hierarchy":{"lvl1":"Python statistics","lvl3":"Normal distribution","lvl2":"Distribution"},"content":"\n\nNormal distribution, also known as the Gaussian distribution, is a probability distribution that appears as a “bell curve” when graphed. The normal distribution describes a symmetrical plot of data around its mean value, where the width of the curve is related to the standard deviation. The data near the mean are more frequent in occurrence than data far from the mean.\n\nThe normal distribution is perhaps the most important distribution. Many real world phenomena, like IQ test scores and human heights/weights, roughly follow a normal distribution. Many common statistical tests also assume distributions are normal.\n\nThe central limit theorem says that the sampling distribution of the mean will always be normally distributed, as long as the sample size is large enough.\n\nimport numpy as np\nimport seaborn as sns\n\ndata = np.random.normal(100, 30, 10000) # generate 10000 random data normall distributed between 50 and 100\nsns.histplot(data=data) # use the histplot of seaborn to draw the histogram graph\n\nFor uniformly distributed data, the histogram typically displays a bell shape.\n\n","type":"content","url":"/statistics1#normal-distribution","position":9},{"hierarchy":{"lvl1":"Python statistics","lvl2":"Correlation"},"type":"lvl2","url":"/statistics1#correlation","position":10},{"hierarchy":{"lvl1":"Python statistics","lvl2":"Correlation"},"content":"\n\nThere are three types of correlation coefficients that can be computed by the pandas.DataFrame.corr() method: Pearson Correlation (default), Spearman Rank Correlation, Kendall Tau Correlation.\n\nThe value of all three correlation coefficients ranges from -1 to +1.  What is a good correlation? It depends on the use, usually at least 0.6 (or -0.6) to call it a good correlation.\n\n","type":"content","url":"/statistics1#correlation","position":11},{"hierarchy":{"lvl1":"Python statistics","lvl3":"Pearson correlation","lvl2":"Correlation"},"type":"lvl3","url":"/statistics1#pearson-correlation","position":12},{"hierarchy":{"lvl1":"Python statistics","lvl3":"Pearson correlation","lvl2":"Correlation"},"content":"\n\nPearson Correlation measures how strongly and in which direction two numerical variables are related in a linear fashion.\n\nIts value ranges from -1 to +1. When its value is positive, it signifies a direct (positive) relationship; when its value is negative, it signifies an inverse (negative) relationship.\n\nValues of correlation closer to +1 or -1 suggest that the data points align more closely along a straight line, indicating a stronger linear relationship.\n\nConversely, when correlation is near 0, the linear relationship is weak.\n\nWe usually first draw a graph to visulize the relationship of two variables before computing the correaltion values.\n\nsns.regplot(data=tips, x=\"total_bill\", y=\"tip\")\n\ntips['total_bill'].corr(tips['tip']) # compute the Pearson correlation\n\nPearson Correlation is most common of all the correlation measures.\n\n`Pearson Correlation is suitable when variables are normally distributed and linearly related.\n\n","type":"content","url":"/statistics1#pearson-correlation","position":13},{"hierarchy":{"lvl1":"Python statistics","lvl3":"Spearman correlation","lvl2":"Correlation"},"type":"lvl3","url":"/statistics1#spearman-correlation","position":14},{"hierarchy":{"lvl1":"Python statistics","lvl3":"Spearman correlation","lvl2":"Correlation"},"content":"\n\nThe Spearman correlation coefficient is a measure of the monotonicity of the relationship between two ranked/ordered datasets. Its value varies between -1 and +1 with 0 implying no correlation. Correlations close to -1 or +1 imply a strong monotonic relationship. Positive correlations imply that as x increases, so does y. Negative correlations imply that as x increases, y decreases.\n\nimport matplotlib.pyplot as plt\n\nsns.barplot(\n    data=tips,\n    x=\"size\",\n    y=\"tip\", \n)\n\ntips['size'].corr(tips['tip'], method=\"spearman\") # compute the spearman correlation\n\nimport matplotlib.pyplot as plt\n\nsns.barplot(\n    data=tips,\n    x=\"day\",\n    y=\"tip\", \n)\n\nUse Pandas’ factorize( ) method to obtain a numeric representation of catogorical data.\n\nimport pandas as pd\n\ntips[\"day_numeric\"] = pd.factorize(tips[\"day\"])[0] # [1] is the orginal catogorical data\ntips\n\ntips['day_numeric'].corr(tips['tip'], method=\"spearman\") # compute the spearman correlation\n\nKendall Tau correlation is similar to Spearman correlation but more focused on pairwise disagreements between two ranking lists and are more suitable for the data with many tied ranks. Due to space limitation, we omit its introduction.\n\nThe following table summerizes the differences of the three correlation measures.\n\nFeature\n\nPearson\n\nSpearman\n\nKendall Tau\n\nRelationship Measured\n\nLinear\n\nMonotonic (can be non-linear)\n\nMonotonic (based on ranks)\n\nSensitivity to Outliers\n\nHigh\n\nLow\n\nLower\n\nData Type Requirement\n\nContinuous, Normally Distributed\n\nRanked or Ordinal\n\nRanked or Ordinal\n\nDistribution Assumption\n\nAssumes normality\n\nNo distribution assumption\n\nNo distribution assumption\n\n","type":"content","url":"/statistics1#spearman-correlation","position":15},{"hierarchy":{"lvl1":"Python statistics","lvl2":"Hypothesis test"},"type":"lvl2","url":"/statistics1#hypothesis-test","position":16},{"hierarchy":{"lvl1":"Python statistics","lvl2":"Hypothesis test"},"content":"\n\nHypothesis testing enables data scientists to determine whether their findings, theories, or assumptions are the result of random chance or supported by statistical evidence.\n\nA hypothesis is a proposed explanation or prediction derived from prior knowledge or observation.\n\nExamples of a hypothesis: (1) there is no relationship between gender and the amount of tips; (2) smokers give more tips than non-smokers.\n\nThere are two parts of a hypothesis:\n\nNull Hypothesis (H_0):\nThe null hypothesis proposes that there is no effect or difference between the variables in two or more samples. For example, a null hypothesis might state, “There is no relationship between gender and the amount of tips.”\nIt is the default assumption and the one that is formally tested—either to be retained or rejected based on statistical evidence.\n\nAlternative Hypothesis (H_1):\nThe alternative hypothesis suggests that there is a meaningful effect or difference between the variables. For instance, it might state, “Gender has an impact on the amount of tips.”\nThis hypothesis represents what we aim to support if the null hypothesis is rejected.\n\nBelow are some hypothesis testing terms:\n\nLevel of Significance (α): often denoted as α, is the threshold we set to decide whether to reject the null hypothesis H_0.\n\nA common value is 0.05, meaning we are willing to accept a 5% chance of a false assumption.\n\nIf the p-value ≤ α, we reject the null hypothesis.\n\np-value: The p-value tells us how likely it is to observe our data, or something more extreme, if the null hypothesis were true.\n\nA small p-value (typically ≤ 0.05) suggests that the observed result is unlikely under the null hypothesis H_0, and we reject it.\n\nA large p-value indicates that the data is consistent with the null hypothesis H_0, and we accept it.\n\nConfidence Level: The  confidence level tells us how confident we are that a confidence interval contains the true value of a population parameter (like the mean or proportion). Confidence level = 1 - \\alpha, where \\alpha is the level of significance.\n\nA 95% confidence level means that if we repeated the experiment many times, about 95% of the resulting confidence intervals would contain the true value.\n\nConfidence Interval (CI): A confidence interval is a range of values estimated from sample data that is likely to contain the true value of a population parameter.\n\nFor example: “We are 95% confident that the true average height is between 170 cm and 175 cm.”\n\n","type":"content","url":"/statistics1#hypothesis-test","position":17},{"hierarchy":{"lvl1":"Python statistics","lvl3":"t-test","lvl2":"Hypothesis test"},"type":"lvl3","url":"/statistics1#t-test","position":18},{"hierarchy":{"lvl1":"Python statistics","lvl3":"t-test","lvl2":"Hypothesis test"},"content":"\n\nStudent's t-test is a statistical test used to test whether the difference between the numerical values of two groups is statistically significant or not.\n\nIn this test, the test statistic follows a Student's t-distribution under the null hypothesis. This distribution is similar to normal distribution but with slightly larger variance, and is more suitable for testing the real life sampled data. In addition to mean and varariance, it has another parameter called degree of freedom, which is the number of values in the final calculation of a statistic that are free to vary.\n\nThere are 3 types t-tests in general and we can use the corresponding methods in the scipy.stats from the scipy library:\n\nOne sample t-test → ttest_1samp\n\nTwo independent sample t-test → ttest_ind\n\nTwo dependent sample t-test → ttest_rel\n\nTwo events are independent if the occurrence of one event does not affect the chances of the occurrence of the other event. In hypothestis tests, independent means one sampeld data is not affected by other sampled data.\n\n","type":"content","url":"/statistics1#t-test","position":19},{"hierarchy":{"lvl1":"Python statistics","lvl3":"One sample t-test","lvl2":"Hypothesis test"},"type":"lvl3","url":"/statistics1#one-sample-t-test","position":20},{"hierarchy":{"lvl1":"Python statistics","lvl3":"One sample t-test","lvl2":"Hypothesis test"},"content":"\n\nA one-sample t-test is to test whether the mean of a population equals to/not less than/not greater than a value specified in a null hypothesis. The syntax for the method ttest_1samp is below:\n\nttest_1samp(a, popmean, alternative='two-sided')\n\na\n\nArray like, sampled observations\n\npopmean\n\nUsually float, expected value in null hypothesis\n\nalternative\n\n\"two-sided\", H1: the mean of the sampled data is different than the given population mean\n\n\"less\", H1: the mean of the sampled data is less than the given population mean\n\n\"greater\", H1: the mean of the sampled data is greater than the given population mean\n\nFor example, we test the null hypothesis H_0: the mean of tips is equal to 3.\n\nInstall the library Scipy by pip install\n\npip install scipy\n\nfrom scipy import stats\nimport seaborn as sns\n\ntips = sns.load_dataset('tips')\nstats.ttest_1samp(tips['tip'], popmean=3)\n\nttest_1samp return the t-statistics, p-value and the number of degrees of freedom.\n\nSuppose we choose a confidence level 95% (or equivalently, significance level \\alpha=0.05). Since the p-value is 0.98 > 0.05, we do not reject the null hypothesis H_0. Namely, we can believe that the mean of tips is equal to 3 (the probability is 98.45%).\n\nFor example, we test a one-sided null hypothesis H_0: the mean of tips is not less than 3.\n\ntips = sns.load_dataset('tips')\nstats.ttest_1samp(tips['tip'], popmean=3, alternative='less')\n\nSuppose we choose a confidence level 95% (or equivalently, significance level \\alpha=0.05). Since the p-value is 0.49 > 0.05, we do not reject the null hypothesis H_0. Namely, we can believe that the mean of tips is not less than 3 (the probability is 50.77%).\n\n","type":"content","url":"/statistics1#one-sample-t-test","position":21},{"hierarchy":{"lvl1":"Python statistics","lvl3":"Two sample t-test","lvl2":"Hypothesis test"},"type":"lvl3","url":"/statistics1#two-sample-t-test","position":22},{"hierarchy":{"lvl1":"Python statistics","lvl3":"Two sample t-test","lvl2":"Hypothesis test"},"content":"\n\nA two-sample t-test tests the null hypothesis such that the means of two populations are equal or the mean of one population is not less than/not greater than another.\n\nFor independent two samples, this can be done by the method ttest_ind(), the syntex of which is below:\n\nttest_ind(a, b, equal_var=True, alternative='two-sided')\n\na\n\nArray like, sampled observations\n\nb\n\nArray like, the other sampled observations\n\nequal_var\n\nIf True (default), perform a standard independent 2 sample test that assumes equal population variances\n\nIf False, perform Welch’s t-test, which does not assume equal population variance\n\nalternative\n\n\"two-sided\", H1: the mean of the sampled data is different than the other sampled data\n\n\"less\", H1: the mean of the sampled data is less than the other sampled data\n\n\"greater\", H1: the mean of the sampled data is greater than the other sampled data\n\nFor example, we want to test the null hypothesis H_0: the amount of tips from male customers shows no difference with that of female cusotomers.\n\nimport seaborn as sns\nfrom scipy import stats\n\ntips = sns.load_dataset(\"tips\")\nmale_tip = tips[tips[\"sex\"] == \"Male\"][\"tip\"]\nfemale_tip = tips[tips[\"sex\"] == \"Female\"][\"tip\"]\n\nstats.ttest_ind(male_tip, female_tip)\n\nP-value is 0.16. If we choose a confidence level 95%, we should accept the null hypothsis H_0 since 0.16>0.05.\n\nFor dependent two samples, this can be done by the method ttest_rel(), the syntex of which is similar to ttest_ind.\n\nExamples of dependent two samples such as students’ scores in two different exams but from the same group of students, or repeated sampling scores from the students in the same class.\n\n","type":"content","url":"/statistics1#two-sample-t-test","position":23},{"hierarchy":{"lvl1":"Python statistics","lvl3":"Anova","lvl2":"Hypothesis test"},"type":"lvl3","url":"/statistics1#anova","position":24},{"hierarchy":{"lvl1":"Python statistics","lvl3":"Anova","lvl2":"Hypothesis test"},"content":"\n\nAnalysis of Variance (ANOVA) is a statistical formula used to compare variances to determine if there is any difference between the means two or more groups.\n\nAnova can be easiy done by the method anova in the library pingouin.\n\nInstall the library pingonin by pip install\n\npip install pingouin\n\nNote\n\n%pip is more suitable for install libraries in the Jupyter notebook environment\n\nThe syntax for anova is below.\n\nanova(data, between=None)\n\ndata\n\nDataFrame\n\nbetween\n\nString or list with N elements, name of column(s) in data containing the between-subject factor(s)\n\nIf between is a single string, a one-way ANOVA is computed. If between is a list with two or more elements, a N-way ANOVA is performed\n\nFor example, the null hypothesis H_0: the amount of tips from male customers shows no difference with that of female cusotomers, can also tested by ANOVA.\n\nimport pingouin as pg\nimport seaborn as sns\n\ntips = sns.load_dataset(\"tips\")\npg.anova(tips, dv=\"tip\", between=\"sex\")\n\nThere is much information in the output, but the most imoportant one if the p-value shown by the “p-unc”. Since the p-value 0.167 is larger than 0.05, we should accept the null hypothesis at a 95% confidence level. The test result is in consitent with that of the two sample t-test.\n\nFor example, test the null hypothesis H_0: there is no difference between the amount of tips and the day of the week.\n\npg.anova(tips, dv=\"tip\", between=\"day\")\n\nSince the p-value 0.174 is larger than 0.05, we should accept the null hypothesis at a 95% confidence level.\n\nFor example, test three null hypotheses:\n\nH_0: there is no difference between the amount of tips and whether the customer is a smoker or not.\n\nH_0: there is no difference between the amount of tips and the sex of the customers.\n\nH_0: there is no difference between the amount of tips and the interation of sex and smoker.\n\npg.anova(tips, dv=\"tip\", between=[\"sex\", \"smoker\"])\n\nSince the p-values are all larger than 0.05, we should accept all the null hypothese at a 95% confidence level.\n\n","type":"content","url":"/statistics1#anova","position":25},{"hierarchy":{"lvl1":"Python statistics","lvl3":"\\chi^2 tests","lvl2":"Hypothesis test"},"type":"lvl3","url":"/statistics1#id-chi-2-tests","position":26},{"hierarchy":{"lvl1":"Python statistics","lvl3":"\\chi^2 tests","lvl2":"Hypothesis test"},"content":"\n\nPearson’s Chi-Square Test is to evaluate the relationship between categorical variables, which determines whether significant differences of the frquencies within data. Since the statistic used is \\chi^2 distribution, we call this test \\chi^2 test.\n\nIt can be easiy done by the method chi2_independence in the library pingouin.\n\nchi2_independence(data, x, y)\n\ndata\n\nDataFrame\n\nx, y\n\nString, the variables names for the Chi-squared test. Must be names of columns in data\n\nFor example, we want to know whether the survival rate is related with gender from the titanic data.\n\nH_0: there is no difference between the gender in the survivals.\n\nimport pingouin as pg\nimport seaborn as sns\n\ntitanic = sns.load_dataset(\"titanic\")\ntitanic\n\npg.chi2_independence(titanic, x=\"survived\", y=\"sex\")\n\nThere is a lot of information in the output. But we can only care about the p-value in the first row of the column “pval”. Since it is much smaller than 0.05, we can reject the null hypothesis at confidence level 95%.\n\nThe first two part of the information are expected frequencies, observed frequencies, respectively. The thrid part of the information is all the test results with different values of lambda.\n\nNote\n\nAnova test can also be done by the library statesmodels and \\chi^2 test can also be done by the library scipy. But they are more cumbesome than pingouin.\n\nStandardization is a process of transforming the data to make it more suitable for some statistical analysis or machine learning.\n\nThe main reasons include:\n\nTo remove the effect of different units and scales\n\nVariables may have different units (e.g., dollars, percentages, counts).\n\nWithout standardization, variables with larger scales may dominate the model (especially in regression or distance-based models like KNN, SVM).\n\nTo compare variable importance\n\nIn regression, standardized coefficients allow you to compare which variable has a stronger effect on the outcome.\n\nTo improve model performance\n\nMany machine learning models (e.g., gradient descent-based, PCA, K-means) work better when input features are on similar scales.\n\nTo meet assumptions of some statistical tests\n\nSome models assume variables are normally distributed or centered around 0, especially in multivariate analysis.\n\nThere are two common methods for standardizing data: z-score standardization and min-max standardization.","type":"content","url":"/statistics1#id-chi-2-tests","position":27},{"hierarchy":{"lvl1":"Python statistics","lvl3":"Z-score Standardization (StandardScaler)","lvl2":"Hypothesis test"},"type":"lvl3","url":"/statistics1#z-score-standardization-standardscaler","position":28},{"hierarchy":{"lvl1":"Python statistics","lvl3":"Z-score Standardization (StandardScaler)","lvl2":"Hypothesis test"},"content":"\n\nTransforms data to have mean (\\mu) = 0 and standard deviation (\\sigma) = 1.z = \\frac{x - \\mu}{\\sigma}\n\nIn python, it is easy to standardize the data with the method fit_transform( ) from the class StandardScaler of the library sklearn.\n\nfrom sklearn.preprocessing import StandardScaler\nimport seaborn as sns\n\ncrashes = sns.load_dataset('car_crashes')\nscaler = StandardScaler()\ncrash_standard = scaler.fit_transform(crashes.iloc[:, 0:-1]) # standarize the data except the last column\nprint(crash_standard[1:10]) # print the first 10 rows\n\nMin-Max Normalization (0-1 Scaling)\n\nThis method scales data to the [0, 1] range.x' = \\frac{x - \\min(x)}{\\max(x) - \\min(x)}\n\nfrom sklearn.preprocessing import MinMaxScaler\nimport seaborn as sns\n\ncrashes = sns.load_dataset('car_crashes')\nscaler = MinMaxScaler()\ncrash_standard = scaler.fit_transform(crashes.iloc[:, 0:-1]) # standarize the data except the last column\nprint(crash_standard[1:10]) # print the first 10 rows\n\nThere is no negative values after standarization for the min-max method.\n\n","type":"content","url":"/statistics1#z-score-standardization-standardscaler","position":29},{"hierarchy":{"lvl1":"Python statistics","lvl2":"Factor analysis* "},"type":"lvl2","url":"/statistics1#factor-analysis","position":30},{"hierarchy":{"lvl1":"Python statistics","lvl2":"Factor analysis* "},"content":"\n\n* means this section may not be delivered in the class.\n\nFactor analysis is a statistical method used to identify underlying latent factors that explain the patterns of correlations among observed variables. It helps to uncover the hidden structure in the data by modeling observed variables as linear combinations of a smaller number of unobserved factors. In simple terms, factor analysis reduces the dimensionality of data by assuming that multiple observed variables are influenced by fewer common factors.\n\nFactor analysis is extensively applied in fields such as market research, advertising, psychology, finance, and operations research. Take market research for an example, it helps identify price-sensitive customer segments, uncover brand attributes that affect consumer preferences, and provides insights into the factors influencing the choice of distribution channels.\n\nThe main objective of factor analysis is to reduce the number of observed variables and find unobservable variables, which can be achieved in two steps:\n\nFactor extraction\n\nThis process uses statistical methods (such as principal component analysis or maximum likelihood) to find factors that explain the maximum shared variance among the variables, determining the number of factors and their initial loadings (the strength of the relationship between factors and variables).\n\nFactor rotation\n\nFactor rotation is applied after factor extraction to adjust the factor loading matrix in order to make the factors easier to interpret. Rotation redistributes the loadings to achieve a simpler and more meaningful structure (close to 1 or 0), where each factor loads highly on a few variables and minimally on others. Common rotation methods include orthogonal rotation (e.g., Varimax), which keeps factors uncorrelated, and oblique rotation (e.g., Promax), which allows factors to be correlated.\n\nIn short, factor extraction finds “what factors exist,” and factor rotation makes those factors “easier to understand.”\n\n","type":"content","url":"/statistics1#factor-analysis","position":31},{"hierarchy":{"lvl1":"Python statistics","lvl2":"Structural equation model*"},"type":"lvl2","url":"/statistics1#structural-equation-model","position":32},{"hierarchy":{"lvl1":"Python statistics","lvl2":"Structural equation model*"},"content":"\n\nStructural Equation Modeling (SEM) is especially useful when the research involves latent variables (concepts that can’t be directly observed) and complex relationships among multiple variables—such as mediation, moderation or multiple simultaneous dependencies.\n\nVariables like job satisfaction, employee engagement, customer loyalty, leadership style, or brand perception are not directly measurable.\n\nThese are called latent variables and typically measured through surveys using multiple items. SEM allows us to model the relationship between latent constructs and their observed indicators (this is called the measurement model).\n\nSEM is also ideal when the model includes complex cause-effect relationships and we want to test direct and indirect effects simultaneously.\n\nFor example, we can use SEM to test the following relationship:\n\nDoes corporate Social Responsibility (CSR) positively influence a company’s Brand Image, which in turn enhances Customer Satisfaction, ultimately leading to increased Customer Loyalty.\n\nCorporate Social Responsibility (CSR) → Brand Image → Customer Satisfaction → Customer Loyalty\n\nHow motivation and leadership style affect both job performance and turnover intention at the same time.\n\nMotivation        ──→ Job PerformanceLeadership Style  ──→ Job PerformanceMotivation        ──→ Turnover IntentionLeadership Style  ──→ Turnover Intention\n\n","type":"content","url":"/statistics1#structural-equation-model","position":33},{"hierarchy":{"lvl1":"Python statistics","lvl3":"An example of using SEM","lvl2":"Structural equation model*"},"type":"lvl3","url":"/statistics1#an-example-of-using-sem","position":34},{"hierarchy":{"lvl1":"Python statistics","lvl3":"An example of using SEM","lvl2":"Structural equation model*"},"content":"\n\nWe use an example in one marketing research showing how tuo use SEM.\n\n","type":"content","url":"/statistics1#an-example-of-using-sem","position":35},{"hierarchy":{"lvl1":"Python statistics","lvl4":"Research question, assumptions and variables","lvl3":"An example of using SEM","lvl2":"Structural equation model*"},"type":"lvl4","url":"/statistics1#research-question-assumptions-and-variables","position":36},{"hierarchy":{"lvl1":"Python statistics","lvl4":"Research question, assumptions and variables","lvl3":"An example of using SEM","lvl2":"Structural equation model*"},"content":"\n\nResearch question: this study aims to explore the impact mechanism of social media advertising (e.g., Instagram ads) on consumers’ purchase intention, and to analyze the mediating role of brand trust and the moderating role of personal innovativeness.\n\nResearch Hypotheses:\n\nH1: Attractiveness of social media advertising positively influences brand trust.\n\nH2: Brand trust positively influences purchase intention.\n\nH3: Brand trust mediates the relationship between advertising attractiveness and purchase intention.\n\nH4: Personal innovativeness moderates the relationship between advertising attractiveness and brand trust (the effect is stronger among highly innovative individuals).\n\nThe hypotheses is illustrated by the following graph.\n\ngraph LR\n  X[Social media advertising X] --> M[Brand Trust M]\n  M --> Y[Purchase Intention Y]\n  X --> Y\n  Z[Personal Innovativeness Z] --> X\n  Z --> M\n\nVariable Design:\n\nIndependent Variable (X): Attractiveness of social media advertising (measured by: advertising creativity, visual design, information usefulness).\n\nMediating Variable (M): Brand trust (measured by: brand reliability, brand integrity).\n\nDependent Variable (Y): Purchase intention (measured by: willingness to buy, willingness to recommend to others).\n\nModerating Variable (Z): Personal innovativeness (categorical variable: high vs. low innovativeness groups).\n\nModerating varaible: Determines whether the strength or direction of the effect of the independent variable (X) on the dependent variable (Y) changes depending on different levels of another variable.\n\nMediating variable: Explains how the independent variable (X) influences the dependent variable (Y) through an intermediate mechanism (M).\n\n","type":"content","url":"/statistics1#research-question-assumptions-and-variables","position":37},{"hierarchy":{"lvl1":"Python statistics","lvl4":"Data collection","lvl3":"An example of using SEM","lvl2":"Structural equation model*"},"type":"lvl4","url":"/statistics1#data-collection","position":38},{"hierarchy":{"lvl1":"Python statistics","lvl4":"Data collection","lvl3":"An example of using SEM","lvl2":"Structural equation model*"},"content":"\n\nWe can collect the data by questionaries: there aer 3 questions related with social media advertisement, 3 questions related with brand trust and 1 questions related personal innovativeness.\n\nGenerally, the number of respondents should be at least 10 times of the number of questions in a questionary.\n\nEach latent variable was measured using 3-5 Likert-scale items (e.g., “The design of this advertisement is appealing to me,” with response options ranging from 1 = strongly disagree to 5 = strongly agree).\n\nThe following codes generate the data in a DataFrame by randome samples.\n\nimport numpy as np\nimport pandas as pd\n\n# data collection\nnp.random.seed(123)\nn = 300  # Sample size\n\n# True scores of latent variables (used to generate observed items)\nlatent_ad = np.random.normal(5, 1, n)  # Latent variable: Ad Attractiveness\nlatent_trust = 0.6 * latent_ad + np.random.normal(\n    0, 1, n\n)  # Brand Trust (influenced by ads)\nlatent_purchase = (\n    0.7 * latent_trust + 0.3 * latent_ad + np.random.normal(0, 1, n)\n)  # Purchase Intention\n\n# Generate observed items (with measurement error)\ndata = pd.DataFrame(\n    {\n        # Ad Attractiveness items (3 items)\n        \"ad1\": latent_ad + np.random.normal(0, 0.5, n),\n        \"ad2\": latent_ad + np.random.normal(0, 0.5, n),\n        \"ad3\": latent_ad + np.random.normal(0, 0.5, n),\n        # Brand Trust items (3 items)\n        \"trust1\": latent_trust + np.random.normal(0, 0.5, n),\n        \"trust2\": latent_trust + np.random.normal(0, 0.5, n),\n        \"trust3\": latent_trust + np.random.normal(0, 0.5, n),\n        # Purchase Intention items (2 items)\n        \"purchase1\": latent_purchase + np.random.normal(0, 0.5, n),\n        \"purchase2\": latent_purchase + np.random.normal(0, 0.5, n),\n        # Moderator variable (Personal Innovativeness, 0 = Low, 1 = High)\n        \"group\": np.random.binomial(1, 0.5, n),  # Random group assignment\n    }\n)\n\ndata\n\n","type":"content","url":"/statistics1#data-collection","position":39},{"hierarchy":{"lvl1":"Python statistics","lvl4":"Pre-test","lvl3":"An example of using SEM","lvl2":"Structural equation model*"},"type":"lvl4","url":"/statistics1#pre-test","position":40},{"hierarchy":{"lvl1":"Python statistics","lvl4":"Pre-test","lvl3":"An example of using SEM","lvl2":"Structural equation model*"},"content":"\n\nIn research methodology (especially in fields such as surveys, psychometrics, and educational assessment), reliability and validity are two core indicators for evaluating the quality of a measurement scale.\n\nReliablity\n\nReliability refers to the consistency of measurement. It means that if the questions in a questionnaire are asked repeatedly to the same person, their responses should remain consistent each time.\n\nOne common types of reliability is internal consistency and typically measured using Cronbach’s alpha (α).\n\nα ≥ 0.9: Excellent\n\n0.8 ≤ α < 0.9: Good\n\n0.7 ≤ α < 0.8: Acceptable\n\nCronbach’s alpha (α) can be computed by the method cronbach_alpha in the library pingouin.\n\ncronbach_alpha(data, items=None, scores=None)\n\ndata\n\nDataFrame\n\nitem\n\nString, column in \"data\" with the items names\n\nscores\n\nString, column in \"data\" with the scores\n\nimport pingouin as pg\n\n# cronbach alpha test\ncronbach_result = pg.cronbach_alpha(data=data)\nprint(f\"cronbach alpha value is {cronbach_result[0]:.2f}\")\n\nThe method “cronbach_alpha” returns the Cronbach's alpha and the corresponding 95% confidence interval.\n\nValidity\n\nValidity refers to whether a test or study measures what it claims to measure. For example, can a certain set of IQ test questions truly reflect a person’s real intelligence?\n\nThere are several common types of validity listed below.\n\nConstruct Validity\n\nAssesses whether the instrument truly measures the theoretical construct it is intended to.\n\nCommon Methods / Indicators:\n\nExploratory Factor Analysis (EFA): Identifies underlying factor structures.\n\nConfirmatory Factor Analysis (CFA): Tests how well the proposed model fits the observed data. Key fit indices include:\n\nChi-square/df ratio (χ²/df)\n\nRMSEA (Root Mean Square Error of Approximation)\n\nCFI (Comparative Fit Index)\n\nTLI (Tucker-Lewis Index)\n\nSRMR (Standardized Root Mean Square Residual)\n\nAverage Variance Extracted (AVE): Assesses convergent validity (AVE ≥ 0.50 is acceptable).\n\nComposite Reliability (CR): Evaluates internal consistency of latent variables.\n\nimport numpy as np\nimport pandas as pd\nfrom semopy import Model, calc_stats\n\n# Set random seed for reproducibility\nnp.random.seed(42)\nn_samples = 300\n\n# Generate latent variables with assumed relationships\n# BrandImage ~ N(0,1)\nBrandImage = np.random.normal(0, 1, n_samples)\n# Customer Satisfaction influenced by BrandImage + noise\nCustSatis = 0.7 * BrandImage + np.random.normal(0, 0.5, n_samples)\n# Customer Loyalty influenced by BrandImage and CustSatis + noise\nCustLoyal = 0.3 * BrandImage + 0.6 * CustSatis + np.random.normal(0, 0.5, n_samples)\n\n# Function to generate observed indicators from latent variables\ndef generate_indicators(latent_var):\n    # Each latent variable is measured by 3 indicators with measurement error (std=0.3)\n    return latent_var.reshape(-1, 1) + np.random.normal(0, 0.3, (n_samples, 3))\n\n# Generate observed variables for each latent variable\nBI = generate_indicators(BrandImage)  # Brand Image indicators\nCS = generate_indicators(CustSatis)   # Customer Satisfaction indicators\nCL = generate_indicators(CustLoyal)   # Customer Loyalty indicators\n\n# Combine all observed indicators into one dataset\ndata = np.hstack([BI, CS, CL])\n\n# Create DataFrame with appropriate column names matching SEM model\ncolumns = ['BI1', 'BI2', 'BI3', 'CS1', 'CS2', 'CS3', 'CL1', 'CL2', 'CL3']\ndf = pd.DataFrame(data, columns=columns)\n\n# Transform data to simulate Likert-scale scores (1 to 5)\ndf = 3 + df          # Shift mean to around 3\ndf = df.clip(1, 5)   # Clip values to range [1, 5]\ndf = df.round(2)     # Round to 2 decimal places\n\nprint(\"Sample of simulated data:\")\nprint(df.head())\n\n# Define SEM model using lavaan-style syntax\nmodel_desc = '''\nBrandImage =~ BI1 + BI2 + BI3\nCustSatis =~ CS1 + CS2 + CS3\nCustLoyal =~ CL1 + CL2 + CL3\n\nCustSatis ~ BrandImage\nCustLoyal ~ BrandImage + CustSatis\n'''\n\n# Initialize and fit SEM model\nmodel = Model(model_desc)\nmodel.fit(df)\n\n# Inspect and print path coefficients and loadings\nprint(\"\\nPath coefficients and loadings:\")\nprint(model.inspect())\n\n# Calculate and print model fit statistics (CFI, TLI, RMSEA, AIC, BIC)\nstats = calc_stats(model)\nprint(\"\\nModel fit indices:\")\nprint(stats[['CFI', 'TLI', 'RMSEA', 'AIC', 'BIC']])\n\n\nDiscriminant Validity\n\nAssesses the extent to which constructs that should not be related are indeed distinct.\n\nCommon Methods / Indicators:\n\nFornell-Larcker Criterion: The square root of the AVE for each construct should be greater than its correlations with other constructs.\n\nHTMT Ratio (Heterotrait-Monotrait): Measures inter-construct correlations. HTMT values < 0.85 (or 0.90) are considered acceptable.\n\nContent Validity\n\nExamines whether the items adequately cover the domain of the construct.\n\nHow to do?\n\nExpert review (at least three subject matter experts assess the relevance of each item).\n\nPilot study (feedback from a small sample of respondents is used to revise unclear wording).\n\n","type":"content","url":"/statistics1#pre-test","position":41},{"hierarchy":{"lvl1":"Python statistics","lvl2":"Exercises"},"type":"lvl2","url":"/statistics1#exercises","position":42},{"hierarchy":{"lvl1":"Python statistics","lvl2":"Exercises"},"content":"\n\n使用python 中的statsmodels库或sklearn库，编程实现《统计学》或《计量经济学》课程上的一些数据分析习题。\n\n\n\n Toogle google translation \n\n","type":"content","url":"/statistics1#exercises","position":43},{"hierarchy":{"lvl1":"Python machine learning"},"type":"lvl1","url":"/statistics2","position":0},{"hierarchy":{"lvl1":"Python machine learning"},"content":"\n\nIn this chapter, we explain how to perform some machine leanrning methods using Python. Rather than delving into the theoretical and computational details of those methods, we aim to provide intuitive, visual explanations that are easy to understand.\n\nOne key machine leanring library in Python is scikit-learn, which focuses on some classical machine lenarning methods such as linear regression, supoport vector machine, random forest, clustring, and so on.\n\nInstall it using pip install:\n\npip install scikit-learn\n\nWhen we use this library in Python, its name is sklearn.\n\nAnother widely used marchine learning library is PyTorch, which is deep learning framework and build some deep learning networks like RNN, CNN, Transformer, and so on.\n\n","type":"content","url":"/statistics2","position":1},{"hierarchy":{"lvl1":"Python machine learning","lvl2":"Linear regression"},"type":"lvl2","url":"/statistics2#linear-regression","position":2},{"hierarchy":{"lvl1":"Python machine learning","lvl2":"Linear regression"},"content":"\n\nlinear regression is a model that estimates the relationship between a scalar response (dependent variable) and one or more explanatory variables (regressor or independent variable).\n\nLinear regression is widely used in biological and social sciences to describe possible relationships between variables. It ranks as one of the most important tools used in these disciplines.\n\nFor example, for a seaborn dataset “car_crashes”, which contains data on car crashes in different U.S. states.\n\nimport seaborn as sns\n\ncrashes = sns.load_dataset('car_crashes')\ncrashes.head()  \n\nDescriptions for each column are below:\n\nVariable Name\n\nDescription\n\ntotal\n\nTotal number of car crash deaths per 10,000 people in each state\n\nspeeding\n\nProportion of deaths due to speeding (as a fraction of total)\n\nalcohol\n\nProportion of deaths involving alcohol (as a fraction of total)\n\nnot_distracted\n\nProportion of deaths not caused by distraction\n\nno_previous\n\nProportion of drivers involved in fatal crashes with no prior violations\n\nins_premium\n\nAlternative column for insurance premium\n\nins_losses\n\nAverage insurance losses per driver (in US dollars)\n\nabbrev\n\nTwo-letter abbreviation of the US state\n\nA scatter plot for the speeding and total number of crashes is given below.\n\nsns.regplot(data=crashes, x=\"speeding\", y=\"total\")\n\nWe may assume there is a linear relationship between the amount of total crashes and the speeding, i.e.,\n\n\\text{total}=\\beta_0+\\beta_1\\text{ speeding}\n\nGeometrically, linear regression involves finding the best-fitting line through a set of points, represented by a linear equation as shown above, where \\beta_0 is called the intercept.\n\nThe most common way to comute the linear regreesion model is by the ordinary least square method, for which we can use the function OLS() from the library Statsmodels.\n\nUsing the statsmodels library to perform regression typically involves the following steps:\n\nConstruct the regression model using the function OLS() and fit().\n\nOutput the regression results using the summary() function.\n\nObtain predicted values using the predict() function. This step can be omitted if not for prediction.\n\nIn the following code, we build a linear model for the equation \n\n(1) using statsmodels.formula.api.\n\nimport statsmodels.formula.api as smf\n\n# the linear model is definded by strings the in the formula\nmodel = smf.ols(formula=\"total ~ speeding\", data=crashes).fit()\n\n# model summary\nprint(model.summary())\n\nThere are a lot of information in the output table, but we usually concern several key informations:\n\nValues of coefficicent \\beta_0, \\beta_1, \\dots\n\nThey are given in the column “coef”. From them, we can get the fitted model. For this example, it is:\n\\text{tip}=9.5459 +1.2493 \\text{ total\\_bill}\n\np-values of the independent variables.\n\nThe p-values are given in the column “P>|t|”. If the p-value of an independe variable is less than 0.05, it means there is linear relationship between the independent variable and the dependent variable at 95% confidence level. For this example, the p-values are all 0.000.\n\nR^2\n\nIt is given by the value on the right of \"R-squred: \" at the top right of the table. It measures the proportion of variability in the dependent variable explained by the model, with a range between 0 and 1. The closer it is to 1, the better the model fit. For this example, it is 0.374.\n\nIn regression analysis, there is no universal threshold for what constitutes a “good” R² value, as it heavily depends on the field of study and research context. However, here are some general guidelines:\n\nR² > 0.7: Often considered strong in social sciences or fields with high noise.\n\nR² = 0.3–0.7: Moderate explanatory power (common in economics, biology, etc.).\n\nR² < 0.3: Weak fit, but may still be meaningful in noisy domains (e.g., psychology, climate studies).\n\nR² ≈ 0: Model explains almost none of the variability.\n\nThe general syntax for the function ols() is given below.\n\nstatsmodels.formula.api.ols(formula, data)\n\nformula\n\nUsually a string, the formula specifying the model.\n\ndata\n\nUsually a DataFrame or dict, the data for the model\n\nThe general syntax for the formula is below:\n\ny ~ x1 + x2 + x1:x2 + C(x3)\n\ny is the dependent (response) variable\n\nx1, x2, x3 are independent (regressor) variables\n\nC(x3) means x3 is catorgorical variable\n\n~ separates the dependent variable from the predictors\n\n+ adds independent variables\n\n-1 removes the intercept (by default it’s included)\n\nx1:x2 adds an interaction term only, which equals x1*x2\n\nx1*x2 adds both main terms and the interaction, which equals x1 + x2 + x1*x2\n\nNormally in regression, we assume that variables affect the outcome independently. But sometimes, the combined effect of two variables is more (or less) than just adding their individual effects — that’s where interaction terms come in.\n\nFor example, we can apply a linear regression between the amount of total crashes, the speeding and the alcohol:\n\n\\text{total}=\\beta_0+\\beta_1\\text{ speeding}+\\beta_2\\text{ alcohol}\n\nimport statsmodels.formula.api as smf\nimport seaborn as sns\n\ncrashes = sns.load_dataset('car_crashes')\n\n# the linear model is definded by strings the in the formula\nmodel = smf.ols(formula=\"total ~ speeding + alcohol\", data=crashes).fit()\n\n# model summary\nprint(model.summary())\n\nOr, if we consider the interaction of speeding and alcohol (drivers with alcohol tend to driving with highe speed):\n\n\\text{total}=\\beta_0+\\beta_1\\text{ speeding}+\\beta_2\\text{ alcohol}+\\beta_3\\text{ alcohol*speeding}\n\nimport statsmodels.formula.api as smf\nimport seaborn as sns\n\ncrashes = sns.load_dataset('car_crashes')\n\n# the linear model is definded by strings the in the formula\n# the below code equals: model = smf.ols(formula=\"total ~ alcohol*speeding\", data=crashes).fit()\nmodel = smf.ols(formula=\"total ~ speeding + alcohol + alcohol:speeding\", data=crashes).fit()\n\n# model summary\nprint(model.summary())\n\nFor the catogorical variable, we use the dataset “tips” as an example to fit the following equation:\n\n\\text{tip}=\\beta_0+\\beta_1\\text{ total\\_bill}+\\beta_2\\text{ day}\n\nimport statsmodels.formula.api as smf\nimport seaborn as sns\n\ntips = sns.load_dataset('tips')\n\n# the linear model is definded by strings the in the formula\nmodel = smf.ols(formula=\"tip ~ total_bill + C(day)\", data=tips).fit()\n\n# model summary\nprint(model.summary())\n\nNote\n\nLinear regression can also be performed using non-formula-based modeling, non-OLS methods or other libraries, which are omitted here due to space limitations.\n\n","type":"content","url":"/statistics2#linear-regression","position":3},{"hierarchy":{"lvl1":"Python machine learning","lvl2":"Standardize Data"},"type":"lvl2","url":"/statistics2#standardize-data","position":4},{"hierarchy":{"lvl1":"Python machine learning","lvl2":"Standardize Data"},"content":"\n\nStandardization is a process of transforming the data to make it more suitable for some statistical analysis or machine learning.\n\nThe main reasons include:\n\nTo remove the effect of different units and scales\n\nVariables may have different units (e.g., dollars, percentages, counts).\n\nWithout standardization, variables with larger scales may dominate the model (especially in regression or distance-based models like KNN, SVM).\n\nTo compare variable importance\n\nIn regression, standardized coefficients allow you to compare which variable has a stronger effect on the outcome.\n\nTo improve model performance\n\nMany machine learning models (e.g., gradient descent-based, PCA, K-means) work better when input features are on similar scales.\n\nTo meet assumptions of some statistical tests\n\nSome models assume variables are normally distributed or centered around 0, especially in multivariate analysis.\n\nThere are two common methods for standardizing data: z-score standardization and min-max standardization\n\nZ-score Standardization (StandardScaler)\n\nTransforms data to have mean (\\mu) = 0 and standard deviation (\\sigma) = 1.z = \\frac{x - \\mu}{\\sigma}\n\nIn python, it is easy to standardize the data with the method fit_transform( ) from sklearn.\n\nfrom sklearn.preprocessing import StandardScaler\nimport seaborn as sns\n\ncrashes = sns.load_dataset('car_crashes')\nscaler = StandardScaler()\ncrash_standard = scaler.fit_transform(crashes.iloc[:, 0:-1]) # standar\nprint(crash_standard[1:10]) # print the first 10 rows\n\nMin-Max Normalization (0-1 Scaling)\n\nThis method scales data to the [0, 1] range.x' = \\frac{x - \\min(x)}{\\max(x) - \\min(x)}\n\nfrom sklearn.preprocessing import MinMaxScaler\nimport seaborn as sns\n\ncrashes = sns.load_dataset('car_crashes')\nscaler = MinMaxScaler()\ncrash_standard = scaler.fit_transform(crashes.iloc[:, 0:-1]) # standar\nprint(crash_standard[1:10]) # print the first 10 rows\n\nThere is no negative values after standarization for this method.\n\n","type":"content","url":"/statistics2#standardize-data","position":5},{"hierarchy":{"lvl1":"Python machine learning","lvl2":"Principle component analysis (PCA)"},"type":"lvl2","url":"/statistics2#principle-component-analysis-pca","position":6},{"hierarchy":{"lvl1":"Python machine learning","lvl2":"Principle component analysis (PCA)"},"content":"\n\nPrincipal component analysis (PCA) is a dimensionality reduction to simplify a large data set into a smaller set, while preserving their most important structures.\n\nIt represent a transformation of the original variables into a new set of uncorrelated variables through linear combinations. This transformation is structured such that the leading components account for the maximal possible information (reflected by the data variance) in the data, effectively compressing the key information into fewer dimensions.\n\nFor example, there are 10 variables in the original data set. We can use PCA to reduce the number of variables to 3 and keep 85% of the original information.\n\nimport seaborn as sns\n\ndata = sns.load_dataset(\"iris\")\ndata\n\nThere are 4 variables in addition to the last categorical variable. We use the class PCA from the libraray sklearn for reducing to 2 varaibles.\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\niris_standard = scaler.fit_transform(data.iloc[:, 0:-1])\npca = PCA(n_components=2)  # the number of principal components\npca.fit(iris_standard)  # fit the data by PCA\nprint(\n    f\"explained variance of each principal component: {pca.explained_variance_ratio_}\"\n)  # output the explained variance ratio\n\nprincipal_components = pca.fit_transform(iris_standard)\nprint(f\"principal components shown the first 10 rows:\\n {principal_components[0:10]}\")\n\nIt is recommended to standarizing the data before applying PCA.\n\nSpecify the number of principal components through the parameter n_components in PCA( ).\n\nFit the data by PCA through the method fit( ).\n\nUsually, the cumulated explained variance ratio of the specified principal components should be greather equal than 85%.\n\nIn this example, the cumluated explained variance ratiso is 0.729 + 0.228 = 0.954 > 0.85.\n\nGet the principal components (the values of the reduced variables) by the method fit_transform( ).\n\nNote\n\nPCA is generally used as an intermediate step in data analysis. It is often applied for dimensionality reduction before further tasks such as clustering, classification, or visualization.\n\n主成分分析的求解一般采用特征根分解，即求解原始数据协方差矩阵或相关系数矩阵最大特征根对应的特征向量，即为第一主成分，第二主成分为第二大特征根对应的特征向量，其他的主成分可以依次得出。主成分贡献率为对应特征根占所有特征根加和的比例。\n\n采用 python 主成分分析时，常用的包为 sklearn，其他一些包也能做（例如 matplotlib.mlab.PCA）。需要注意的是\n\n最好对原始数据进行标准化\n\nsklearn 计算主成分时使用的是协方差矩阵，而不是相关系数矩阵\n\nsklearn 中的标准化函数有：\n\n函数\n\n描述\n\nscale(X, axis=0, *)\n\n对数据 X 进行 z 标准化，参数 axis 调整对列或对行标准化\n\nStandardScaler()\n\nz 标准化，列标准化\n\nMinMaxScaler()\n\n最大最小标准化，列标准化\n\nMaxAbsScaler()\n\n最大绝对值标准化，列标准化\n\n... ...\n\n\n\n举例，下面一个统计数据：\n\n\n\n食品\n\n衣着\n\n居住\n\n家庭设备\n\n交通通讯\n\n文教娱乐\n\n医疗保健\n\n其他\n\n北  京\n\n1736\n\n379\n\n854\n\n327\n\n615\n\n797\n\n504\n\n103\n\n天  津\n\n1171\n\n257\n\n614\n\n117\n\n328\n\n329\n\n179\n\n40\n\n河  北\n\n888\n\n156\n\n399\n\n101\n\n222\n\n226\n\n135\n\n39\n\n山  西\n\n830\n\n202\n\n201\n\n69\n\n160\n\n280\n\n103\n\n33\n\n内蒙古\n\n1054\n\n150\n\n335\n\n84\n\n293\n\n309\n\n176\n\n44\n\n辽  宁\n\n1127\n\n221\n\n378\n\n100\n\n301\n\n377\n\n234\n\n68\n\n吉  林\n\n1003\n\n168\n\n257\n\n82\n\n285\n\n261\n\n194\n\n56\n\n黑龙江\n\n924\n\n184\n\n527\n\n74\n\n257\n\n277\n\n254\n\n49\n\n上  海\n\n2684\n\n366\n\n1320\n\n458\n\n748\n\n937\n\n562\n\n204\n\n江  苏\n\n1569\n\n191\n\n512\n\n168\n\n364\n\n479\n\n199\n\n85\n\n浙  江\n\n2061\n\n319\n\n914\n\n260\n\n618\n\n723\n\n416\n\n121\n\n安  徽\n\n1000\n\n117\n\n345\n\n106\n\n197\n\n257\n\n134\n\n41\n\n福  建\n\n1518\n\n187\n\n457\n\n154\n\n366\n\n357\n\n154\n\n100\n\n江  西\n\n1221\n\n125\n\n326\n\n96\n\n230\n\n276\n\n155\n\n56\n\n山  东\n\n1088\n\n160\n\n446\n\n137\n\n294\n\n377\n\n188\n\n46\n\n河  南\n\n859\n\n132\n\n318\n\n83\n\n160\n\n178\n\n123\n\n39\n\n湖  北\n\n1192\n\n125\n\n310\n\n110\n\n223\n\n272\n\n135\n\n62\n\n湖  南\n\n1433\n\n128\n\n307\n\n114\n\n219\n\n329\n\n168\n\n58\n\n广  东\n\n1789\n\n144\n\n530\n\n152\n\n412\n\n361\n\n204\n\n116\n\n广  西\n\n1187\n\n79\n\n380\n\n95\n\n214\n\n226\n\n123\n\n44\n\n海  南\n\n1135\n\n66\n\n146\n\n92\n\n178\n\n199\n\n93\n\n60\n\n重  庆\n\n1130\n\n96\n\n231\n\n96\n\n163\n\n250\n\n143\n\n33\n\n四  川\n\n1244\n\n116\n\n234\n\n102\n\n172\n\n225\n\n144\n\n36\n\n贵  州\n\n820\n\n80\n\n236\n\n62\n\n99\n\n161\n\n72\n\n24\n\n云  南\n\n976\n\n80\n\n226\n\n67\n\n100\n\n183\n\n122\n\n35\n\n西  藏\n\n1185\n\n182\n\n84\n\n81\n\n79\n\n28\n\n44\n\n39\n\n陕  西\n\n813\n\n124\n\n212\n\n84\n\n163\n\n297\n\n166\n\n38\n\n甘  肃\n\n859\n\n92\n\n241\n\n74\n\n155\n\n258\n\n114\n\n27\n\n青  海\n\n893\n\n156\n\n329\n\n84\n\n208\n\n110\n\n152\n\n43\n\n宁  夏\n\n923\n\n143\n\n346\n\n77\n\n178\n\n178\n\n199\n\n51\n\n新  疆\n\n804\n\n171\n\n333\n\n68\n\n183\n\n159\n\n169\n\n36\n\n主成分分析的 Python 代码为：\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import scale\nimport pandas as pd\nimport numpy as np\n\n# 下面前几行代码是为了运行 live code 而进行的设置，\n# 与本章的教学内容无关\nimport os\n\nif os.getcwd() == \"/home/jovyan\":\n    os.chdir(\"data-science/\")\n\n# 正文\ndf = pd.read_excel(\"datas/data-pca.xlsx\", index_col=0)  # 读取数据\ndata = scale(df.values)  # z标准化，标准化之后就自动根据协方差矩阵进行主成分分析了\n# data2 = np.corrcoef(np.transpose(data)) # 没有必要单独计算协方差阵或相关系数阵\npca = PCA(n_components=3)  # 可以通过参数 n_components 调整主成分个数\npca.fit(data)\nprint(\"特征根：\", pca.explained_variance_)  # 输出特征根\nprint()\nprint(\"主成分：\", pca.components_)  # 输出主成分\n\n","type":"content","url":"/statistics2#principle-component-analysis-pca","position":7},{"hierarchy":{"lvl1":"Python machine learning","lvl2":"Clustering"},"type":"lvl2","url":"/statistics2#clustering","position":8},{"hierarchy":{"lvl1":"Python machine learning","lvl2":"Clustering"},"content":"\n\nKmeans 是一种动态聚类方法，其基本思想是：首先随机选取 K 个点作为初始凝聚点，按照距离最近原则划分为 K 类；然后重新计算 K 个类的重心作为新的凝聚点，再按照距离最近原则重新分类；重复这一过程，直到重心不再变化为止。\n\n对上面的例子，进行 Kmeans 聚类并画图的代码为：\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")  # 忽略掉使用默写函数的一些警告信息\n\nimport pandas as pd\nfrom sklearn.cluster import KMeans\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\n# 下面前几行代码是为了运行 live code 而进行的设置，\n# 与本章的教学内容无关\nimport os\n\nif os.getcwd() == \"/home/jovyan\":\n    os.chdir(\"data-science/\")\n\n# 正文\n# 将上述数据放到 excel 里，并用 pandas 读取\ndf = pd.read_excel(\"datas/data-pca.xlsx\", index_col=0)\n\nscale_values = MinMaxScaler().fit_transform(df.values)  # 数据表转化预处理\n\nkmeans = KMeans(n_clusters=3).fit(scale_values)  # 分为 3 类, 参数 n_init= 'auto' 设置初始聚类的运行次数\nprint(kmeans.labels_)  # 输出判别结果列表\n\n# 具体输出判别结果\ncluster_1 = []\ncluster_2 = []\ncluster_3 = []\nfor i, j in enumerate(kmeans.labels_):\n    if j == 0:\n        cluster_1.append(df.index[i])\n    elif j == 1:\n        cluster_2.append(df.index[i])\n    else:\n        cluster_3.append(df.index[i])\nprint(\"类别1\")\nprint(cluster_1)\nprint(\"类别2\")\nprint(cluster_2)\nprint(\"类别3\")\nprint(cluster_3)\n\n# draw pictures by tsne, or pca, 利用主成分降为 2 维，并画图显示分类结果\n# from sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\ntsne = PCA(n_components=2).fit_transform(scale_values)  # tsne\ndf2 = pd.DataFrame(tsne)\ndf2[\"labels\"] = kmeans.labels_\n\ndf_1 = df2[df2[\"labels\"] == 0]\ndf_2 = df2[df2[\"labels\"] == 1]\ndf_3 = df2[df2[\"labels\"] == 2]\n\n# 画图\nplt.plot(df_1[0], df_1[1], \"bo\", df_2[0], df_2[1], \"r*\", df_3[0], df_3[1], \"gD\")\nplt.show()\n\n","type":"content","url":"/statistics2#clustering","position":9},{"hierarchy":{"lvl1":"Python machine learning","lvl2":"Artificial neural network"},"type":"lvl2","url":"/statistics2#artificial-neural-network","position":10},{"hierarchy":{"lvl1":"Python machine learning","lvl2":"Artificial neural network"},"content":"\n\n神经网络的目标是：找到一个能把一组输入最好地映射到其正确输出的函数。例如一个简单的分类任务，其中输入是动物的图像，正确的输出将是动物的名称。或者根据历史需求数据，预测未来一期的需求。神经网络的思想类似回归分析中经常用到的拟合，都用到了最小二乘的思想：数学意义上的决策目标是：选取一些参数（神经网络中每个输入的权重），使得拟合的输出与期望输出的误差平方和最小。\n\n下面是一个神经网络示意图（输入层有一些神经元，隐含层有一些神经元，输出层有一些神经元），输入信息经过正向传播到输出，计算实际输出与期望输出的误差后，在反向传播误差；重复这个过程，在传播过程中，不断减少误差，直到误差减少到一定程度终止。\n\n用 BP 神经网络预测 sklearn 包中自带的乳腺癌数据例子：\n\n# 测试一下癌症数据\nfrom sklearn import datasets\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import classification_report\n\ncancer = datasets.load_breast_cancer()\ncancer_data = cancer[\"data\"]\ncancer_target = cancer[\"target\"]\n\n# 将数据集划分为训练集，测试集\n(\n    cancer_data_train,\n    cancer_data_test,\n    cancer_target_train,\n    cancer_target_test,\n) = train_test_split(cancer_data, cancer_target, test_size=0.2)\n\n# 数据标准化\nstdScaler = StandardScaler().fit(cancer_data_train)\ncancer_trainStd = stdScaler.transform(cancer_data_train)\ncancer_testStd = stdScaler.transform(cancer_data_test)\n\n# 建立 BP 模型\nbpnn = MLPClassifier(\n    hidden_layer_sizes=(20, 10),  # 神经元隐含层的大小\n    max_iter=200,\n    solver=\"adam\",\n    random_state=45,\n)\nbpnn.fit(cancer_trainStd, cancer_target_train)\n\n# 预测\ny_pred = bpnn.predict(cancer_testStd)  # 返回预测结果\nprint(\"神经网络预测结果评价报告：\\n\", classification_report(cancer_target_test, y_pred))\n\n其他常见的机器学习方法，例如随机森林，支持向量机，梯度提升等，都可以在sklearn库中找到相应的函数。\n\n","type":"content","url":"/statistics2#artificial-neural-network","position":11},{"hierarchy":{"lvl1":"Python machine learning","lvl2":"练习"},"type":"lvl2","url":"/statistics2#id","position":12},{"hierarchy":{"lvl1":"Python machine learning","lvl2":"练习"},"content":"\n\n使用python 中的statsmodels库或sklearn库，编程实现《统计学》或《计量经济学》课程上的一些数据分析习题。\n\n\n\n Toogle google translation \n\n","type":"content","url":"/statistics2#id","position":13}]}